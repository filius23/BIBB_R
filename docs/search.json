[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R am BIBB",
    "section": "",
    "text": "Eine Einführung in R für Mitarbeitende am BIBB.\n\n\n\n\n\n\n\n\n\nDies das Begleitskript für die R-Kurse am BIBB.\nMelden Sie sich gerne bei Fragen oder Wünschen unter andreas.filser[at]uol.de\n\n\n\n\nKursinformationen\n\n\n\n\n   Montags und Dienstags\n   17.04 - 18.04. und 24.04. - 25.04.2023\n   8:30 – 15:30 Uhr\n   Webex"
  },
  {
    "objectID": "01_intro.html",
    "href": "01_intro.html",
    "title": "1  Einstieg in R",
    "section": "",
    "text": "Bei R handelt es sich um ein vollständig kostenloses Programm, das Sie unter CRAN herunterladen können. Ebenfalls kostenlos ist die Erweiterung RStudio, die Sie unter hier herunterladen können. RStudio erweitert R um eine deutlich informativere und ansprechendere Oberfläche, Hilfe und Auto-Vervollständigung beim Schreiben von Syntax und insgesamt eine verbesserte Nutzeroberfläche. Jedoch ist RStudio eine Erweiterung von R, sodass Sie beide Programme benötigen.\n\n\n\n\n\n\nNote\n\n\n\nInstallieren Sie zuerst R und dann RStudio, dann erkennt RStudio die installierte R-Version und die beiden Programme verbinden sich in der Regel automatisch. R ist dabei sozusagen der Motor, RStudio unser Cockpit. Wir könnten direkt mit R arbeiten, aber mit RStudio haben wir eine komfortablere Option und einen besseren Überblick.\n\n\n\n\n\n\n\n\n\n \n\n\nFigure 1.1: R und RStudio"
  },
  {
    "objectID": "01_intro.html#rstudio-einrichten",
    "href": "01_intro.html#rstudio-einrichten",
    "title": "1  Einstieg in R",
    "section": "1.2 RStudio einrichten",
    "text": "1.2 RStudio einrichten\nÖffnen Sie nach erfolgreicher Installation die Anwendung RStudio  und Sie sollten folgende Ansicht vor sich sehen:\n\n\n\n\nUm Probleme bei der künftigen Arbeit mit R zu vermeiden, deaktivieren Sie bitte das automatische Speichern und Laden des Workspace. Rufen Sie dazu das entsprechende Menü unter dem Reiter “Tools -> Global options” auf und deaktivieren Sie bitte “Restore .RData into workspace at startup” und setzen Sie “Save workspace to .RData on exit:” auf Never. RStudio speichert ansonsten alle geladenen Objekte wenn Sie die Sitzung beenden und lädt diese automatisch wenn Sie das Programm das nächste Mal öffnen. Dies führt erfahrungsgemäß zu Problemen.\n\n\n\n\nBestätigen Sie die Einstellungen mit “Apply” und schließen Sie das Fenster mit “OK”."
  },
  {
    "objectID": "01_intro.html#erste-schritte-in-r",
    "href": "01_intro.html#erste-schritte-in-r",
    "title": "1  Einstieg in R",
    "section": "1.3 Erste Schritte in R",
    "text": "1.3 Erste Schritte in R\nNach diesen grundlegenden Einstellungen können wir uns an die ersten Schritte in R machen. Öffnen Sie dazu zunächst ein Script, indem Sie auf das weiße Symbol links oben klicken oder drücken Sie gleichzeitig STRG/Command + Shift + N .\n\n\n\n\nEs öffnet sich ein viertes Fenster, sodass Sie nun folgende Ansicht vor sich haben sollten:\n\n\n\n\nDieser Scripteditor ist der Ort, an dem wir Befehle erstellen und anschließend durchführen werden. Der Scripteditor dient dabei als Sammlung aller durchzuführenden Befehle. Wir können diese Sammlungen speichern, um sie später wieder aufzurufen und vor allem können wir so Befehlssammlungen mit anderen teilen oder Skripte von anderen für uns selbst nutzen. Wir entwerfen also zunächst im Scripteditor eine Rechnung:\n\n\n\n\nUm diese nun auszuführen, klicken wir in die auszuführende Zeile, sodass der Cursor in dieser Zeile ist und drücken gleichzeitig STRG und Enter (Mac-User Command und Enter):\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1.2: Shortcuts für Berechnungen\n\n\nR gibt die Ergebnisse unten in der Console aus:\n\n\n\n\nDas funktioniert auch für mehrere Rechnungen auf einmal indem wir mehrere Zeilen markieren und dann wieder STRG und Enter (Mac-User Command und Enter) drücken:\n\n\n\n\nEingaben aus dem Script-Editor und Ergebnisse aus der Konsole werden in Zukunft so dargestellt:\n\n2+5\n\n[1] 7\n\n3-4\n\n[1] -1\n\n5*6\n\n[1] 30\n\n7/8\n\n[1] 0.875\n\n\nR beherrscht natürlich auch längere Berechnungen, zum Beispiel wird auch Punkt vor Strich beachtet:\n\n2+3*2\n\n[1] 8\n\n(2+3)*2\n\n[1] 10\n\n\nAuch weitere Operationen sind möglich:\n\n4^2 ## 4²\nsqrt(4) ## Wurzel \nexp(1) ## Exponentialfunktion (Eulersche Zahl)\nlog(5) ## Natürlicher Logarithmus\nlog(exp(5)) ## log und exp heben sich gegenseitig auf\n\nZahlenreihen können wir mit seq() oder : erstellen:\n\n2:6\n\n[1] 2 3 4 5 6\n\nseq(2,11,3)\n\n[1]  2  5  8 11\n\n\n\n1.3.1 Objekte erstellen\nBisher haben wir uns unsere Berechnungen immer direkt ausgeben lassen. Für umfangreichere Berechnungen - wir wollen ja ab dem nächsten Kapitel mit Datensätzen arbeiten - wollen wir aber die Zwischenschritte speichern.\nErgebnisse lassen sich mit einem <- unter einem beliebigen Namen als Objekt speichern. Dann wird R uns nicht das Ergebnis anzeigen, sondern den Befehl in der Konsole wiederholen:\n\nx <- 4/2\n\nIm Fenster “Environment” rechts oben sehen wir jetzt das abgelegte Objekt x:\n\n\n\n\nWir können es später wieder aufrufen:\n\nx\n\n[1] 2\n\n\nAußerdem können wir Objekte in Rechnungen weiter verwenden - wir setzen einfach x ein und erstellen zB. y:\n\ny <- x * 5\ny\n\n[1] 10\n\n\n\n\n\n\n\n\n1.3.2 Mehrere Werte ablegen\nMit c() lassen sich mehrere Werte unter einem Objekt ablegen und auch mit diesen lässt sich rechnen:\n\nx1 <- c(1,2,3)\nx1\n\n[1] 1 2 3\n\nx1* 2\n\n[1] 2 4 6\n\n\nMit length() können wir die Anzahl der abgelegten Werte nachsehen:\n\nlength(x1)\n\n[1] 3\n\n\n\ny1 <- c(10,11,9)\ny1\n\n[1] 10 11  9\n\ny1/x1\n\n[1] 10.0  5.5  3.0\n\n\n\n\n1.3.3 Werte löschen\nNatürlich können wir Objekte auch wieder löschen und zwar mit rm(). Wenn wir ein nicht existierendes Objekt aufrufen bekommen wir eine Fehlermeldung:\n\nrm(x1)\nx1\n\nError in eval(expr, envir, enclos): Objekt 'x1' nicht gefunden\n\n\nMit rm(list = ls()) können alle Objekte aus dem Environment gelöscht werden.\n\n\n1.3.4 Scripte speichern\nDas Script können wir speichern, um es später wieder aufzurufen.\n\n\n\n\nWichtig ist dabei, der gespeicherten Datei die Endung “.R” zu geben, also zum Beispiel “01_Script.R”.\n\n\n\n\n\n1.3.5 Kommentare\nNeben den eigentlichen Befehlen sind Kommentare ein zentraler Bestandteil einer Datenanalyse-Syntax. Nur so können künftige Nutzende (insbesondere wir selbst in 3 Wochen oder 2 Jahren) nachvollziehen was passiert. Kommentare in R können mit # eingefügt werden:\n\n2+ 5 # hier steht ein Kommentar\n\n[1] 7\n\n2+ # auch hier kann ein Kommentar stehen\n  5\n\n[1] 7\n\n\n\n( 2 + # ein\n    3) * # kommentar\n  2 # über mehrere Zeilen\n\n[1] 10\n\n\nTipp: Erstellen Sie sich am besten sofort einen Ordner, in dem Sie alle R Scripte und Datensätze aus dieser Veranstaltung gesammelt ablegen.\n\n\n1.3.6 Skripte strukturieren\n\n# Überschrift 1 ----\n\n## Abschnit 1.1 ----\n3+2*4\n3+2*3\n## Abschnit 1.2 ----\n3+2*sqrt(3)\n\n# Überschrift 2 ----\nx <- c(2,6,8,2,35)\ny <- seq(2,10,2)\n\ny/x"
  },
  {
    "objectID": "01_intro.html#übungen",
    "href": "01_intro.html#übungen",
    "title": "1  Einstieg in R",
    "section": "1.4 Übungen",
    "text": "1.4 Übungen\n\nLegen Sie die Anzahl der Studierenden an der Uni Oldenburg (15643) unter stud ab.\nLegen Sie die Anzahl der Professuren an der Uni Oldenburg (210) unter prof ab.\nBerechnen Sie die Anzahl der Studierenden pro Professur an der Uni Oldenburg indem Sie die Objekte stud und prof verwenden.\nLegen Sie das Ergebnis unter studprof ab und rufen Sie das das Objekt noch einmal auf!\nSehen Sie die erstellten Variablen im Environment-Fenster?\nLegen Sie die Studierendenzahlen der Uni Bremen (19173), Uni Vechta (5333) und Uni Oldenburg (15643) zusammen unter studs ab.\nLegen Sie die Zahl der Profs der Uni Bremen (322), Uni Vechta (67) und Uni Oldenburg (210) zusammen unter profs ab.\nBerechnen die Anzahl der Studierenden pro Professur für alle drei Universitäten.\nSie möchten zusätzlich die Zahl der Studierenden (14000) und Professuren (217) der Uni Osnabrück in studs und profs ablegen. Wie gehen Sie vor?\nBerechnen Sie für alle vier Universitäten das Verhältnis von Studierenden und Professuren!\nLöschen Sie das Objekt stud. Woran erkennen Sie, dass das funktioniert hat?\nLöschen Sie alle Objekte aus dem Environment. Woran erkennen Sie, dass das funktioniert hat?"
  },
  {
    "objectID": "02_intro.html",
    "href": "02_intro.html",
    "title": "2  Arbeiten mit Datensätzen in R",
    "section": "",
    "text": "(Spätes) Vorwort zu R und der Befehlsstruktur\nKlingt gut, oder?\nEin paar allgemeine Aspekte, in denen sich das Arbeiten mit R von dem mit einigen anderen Programmen unterscheidet:\nIn der ersten Session haben wir einige Schritte mit der Taschenrechnerfunktion in R unternommen. Die wirkliche Stärke von R ist aber die Verarbeitung von Daten - los geht’s."
  },
  {
    "objectID": "02_intro.html#datenstrukturen-in-r-data.frame",
    "href": "02_intro.html#datenstrukturen-in-r-data.frame",
    "title": "2  Arbeiten mit Datensätzen in R",
    "section": "2.1 Datenstrukturen in R: data.frame",
    "text": "2.1 Datenstrukturen in R: data.frame\nIm vorherigen Kapitel haben wir die Studierendenzahlen der Uni Bremen (19173), Uni Vechta (5333) und Uni Oldenburg (15643) zusammen unter studs abgelegt und mit den in profs abgelegten Professurenzahlen ins Verhältnis gesetzt. Das funktioniert soweit gut, allerdings ist es übersichtlicher, zusammengehörige Werte auch zusammen ablegen. Dafür gibt es in R data.frame. Wir können dazu die beiden Objekte in einem Datensatz ablegen, indem wir sie in data.frame eintragen und das neue Objekt unter dat1 ablegen. Wenn wir dat1 aufrufen sehen wir, dass die Werte zeilenweise zusammengefügt wurden:\n\nstuds <- c(19173,5333,15643)    # Studierendenzahlen unter \"studs\" ablegen \nprofs       <- c(322,67,210)    # Prof-Zahlen unter \"profs\" ablegen\ndat1_orig <- data.frame(studs, profs)\ndat1_orig\n\n  studs profs\n1 19173   322\n2  5333    67\n3 15643   210\n\n\n\ndat1 <- data.frame(studs = c(19173,5333,15643), \n                   profs = c(322,67,210),\n                   gegr  = c(1971,1830,1973)) # ohne zwischen-Objekte\ndat1    # zeigt den kompletten Datensatz an\n\n  studs profs gegr\n1 19173   322 1971\n2  5333    67 1830\n3 15643   210 1973\n\n\nIn der ersten Zeile stehen also die Werte der Uni Bremen, in der zweiten Zeile die Werte der Uni Vechta usw. Die Werte können wir dann mit datensatzname$variablenname aufrufen. So können wir die Spalte profs anzeigen lassen:\n\ndat1$profs \n\n[1] 322  67 210\n\n\nMit colnames()/names() können wir die Variablen-/Spaltennamen des Datensatzes anzeigen lassen, zudem können wir mit nrow und ncol die Zahl der Zeilen bzw. Spalten aufrufen:\n\ncolnames(dat1) ## Variablen-/Spaltennamen anzeigen\n\n[1] \"studs\" \"profs\" \"gegr\" \n\nnames(dat1) ## Variablen-/Spaltennamen anzeigen\n\n[1] \"studs\" \"profs\" \"gegr\" \n\nncol(dat1) ## Anzahl der Spalten/Variablen\n\n[1] 3\n\nnrow(dat1) ## Anzahl der Zeilen/Fälle\n\n[1] 3\n\n\nNeue zusätzliche Variablen können durch datensatzname$neuevariable in den Datensatz eingefügt werden:\n\ndat1$stu_prof <- dat1$studs/dat1$profs\n## dat1 hat also nun eine Spalte mehr:\nncol(dat1) \n\n[1] 4\n\ndat1\n\n  studs profs gegr stu_prof\n1 19173   322 1971 59.54348\n2  5333    67 1830 79.59701\n3 15643   210 1973 74.49048\n\n\nWir können auch ein oder mehrere Wörter in einer Variable ablegen, jedoch müssen Buchstaben/Wörter immer in \"\" gesetzt werden.\n\ndat1$uni <- c(\"Uni Bremen\",\"Uni Vechta\", \"Uni Oldenburg\")\ndat1\n\n  studs profs gegr stu_prof           uni\n1 19173   322 1971 59.54348    Uni Bremen\n2  5333    67 1830 79.59701    Uni Vechta\n3 15643   210 1973 74.49048 Uni Oldenburg\n\n\nMit View(dat1) öffnet sich zudem ein neues Fenster, in dem wir den gesamten Datensatz ansehen können:\n\nView(dat1)"
  },
  {
    "objectID": "02_intro.html#variablentypen",
    "href": "02_intro.html#variablentypen",
    "title": "2  Arbeiten mit Datensätzen in R",
    "section": "2.2 Variablentypen",
    "text": "2.2 Variablentypen\nDamit haben wir bisher zwei Variablentypen kennen gelernt: numeric (enthält Zahlen) und character (enthält Text oder Zahlen, die als Text verstanden werden sollen). Darüber hinaus gibt es noch weitere Typen, die besprechen wir wenn sie nötig sind, zB. gibt es factor-Variablen, die eine vorgegebene Sortierung und Werteuniversum umfassen oder logische Variablen. Vorerst fokussieren wir uns auf character und numeric Variablen. Mit class() kann die Art der Variable untersucht werden oder mit is.numeric() bzw. is.character() können wir abfragen ob eine Variable diesem Typ entspricht:\n\nclass(dat1$profs)\n\n[1] \"numeric\"\n\nclass(dat1$uni)\n\n[1] \"character\"\n\nis.numeric(dat1$profs)\n\n[1] TRUE\n\nis.character(dat1$profs)\n\n[1] FALSE\n\n\nMit as.character() bzw. as.numeric() können wir einen Typenwechsel erzwingen:\n\nas.character(dat1$profs) ## die \"\" zeigen an, dass die Variable als character definiert ist\n\n[1] \"322\" \"67\"  \"210\"\n\n\nDas ändert erstmal nichts an der Ausgangsvariable dat1$profs:\n\nclass(dat1$profs)\n\n[1] \"numeric\"\n\n\nWenn wir diese Umwandlung für dat1$profs behalten wollen, dann müssen wir die Variable überschreiben:\n\ndat1$profs <- as.character(dat1$profs)\ndat1$profs \n\n[1] \"322\" \"67\"  \"210\"\n\nclass(dat1$profs)\n\n[1] \"character\"\n\n\nMit character-Variablen kann nicht gerechnet werden, auch wenn sie Zahlen enthalten:\n\ndat1$profs / 2 \n\nError in dat1$profs/2: nicht-numerisches Argument für binären Operator\n\n\nWir können aber natürlich dat1$profs spontan mit as.numeric umwandeln, um mit den Zahlenwerten zu rechnen:\n\nas.numeric(dat1$profs)\n\n[1] 322  67 210\n\nas.numeric(dat1$profs) / 2\n\n[1] 161.0  33.5 105.0\n\n\nWenn wir Textvariablen in numerische Variablen umwandeln, bekommen wir NAs ausgegeben. NA steht in R für fehlende Werte:\n\nas.numeric(dat1$uni)\n\nWarning: NAs durch Umwandlung erzeugt\n\n\n[1] NA NA NA\n\n\nR weiß (verständlicherweise) also nicht, wie die Uni-Namen in Zahlen umgewandelt werden sollen.\n\n\n\n\n\n\nTip\n\n\n\nNicht selten ist ein Problem bei einer Berechnung auf den falschen Variablentypen zurückzuführen.\n\n\n\n2.2.1 Übung"
  },
  {
    "objectID": "02_intro.html#packages",
    "href": "02_intro.html#packages",
    "title": "2  Arbeiten mit Datensätzen in R",
    "section": "2.3 Pakete in R",
    "text": "2.3 Pakete in R\nIm nächsten Schritt möchten wir jetzt nur einige Zeilen (Fälle) und/oder Spalten (Variablen) auswählen. Dazu verwenden wir das Paket {dplyr}2.\nPakete sind Erweiterungen für R, die zusätzliche Funktionen beinhalten.  Pakete müssen einmalig installiert werden und dann vor der Verwendung in einer neuen Session (also nach jedem Neustart von R/RStudio) geladen werden. install.packages() leistet die Installation, mit library() werden die Pakete geladen:\n\ninstall.packages(\"Paket\") # auf eurem PC nur einmal nötig\nlibrary(Paket) # nach jedem Neustart nötig\n\nHäufig werden bei install.packages() nicht nur das angegebene Paket, sondern auch eine Reihe weiterer Pakete heruntergeladen, die sog. “dependencies”. Das sind Pakete, welche im Hintergrund verwendet werden, um die Funktionen des eigentlich gewünschten Pakets zu ermöglichen. Also nicht erschrecken, wenn die Installation etwas umfangreicher ausfällt.\nMit install.packages() schrauben wir sozusagen die Glühbirne in R, mit library() betätigen wir den Lichtschalter, sodass wir die Befehle aus dem Paket auch verwenden können. Mit jedem Neustart geht die Glühbirne wieder aus und wir müssen sie mit library() wieder aktivieren. Das hat aber den Vorteil, dass wir nicht alle Glühbirnen auf einmal anknipsen müssen, wenn wir R starten.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninstall.packages() im BIBB-Netzwerk\n\n\n\nAufgrund der VPN-Einstellungen im BIBB muss in R folgende Option gesetzt werden, damit Downloads möglich sind:\noptions(download.file.method = \"wininet\")\nDazu bieten sich zwei Möglichkeiten:\n\nnach jedem Neustart von RStudio vor install.packages() mit setzen:\n\n\noptions(download.file.method = \"wininet\")\ninstall.packages()\n\n\ndiese Option permanent “verankern”: wer den Befehl nicht zu Beginn jeden R-Scripts aufführen möchte, kann ihn in die Rprofile-Datei (Rprofile.site) mit globalen Einstellungen aufnehmen. Diese Datei liegt beim BIBB Arbeitsgerät unter folgendem Pfad: C:\\RforWindows_4_2_1\\etc Mehr zu RProfile\n\n\n\n\n\n\n\n\n\nPakete einmalig laden\n\n\n\n\n\nNeben library() gibt es auch die Möglichkeit, Funktionen aus Paketen mit :: aufzurufen:\n\npaket::function()\n\nDiese Option wird häufig verwendet, wenn lediglich eine Funktion aus einem Paket einmalig verwendet wird und oder um deutlich zu machen, aus welchem Paket die verwendete Funktion kommt. Das kann auch bei Problemen mit einem Befehl hilfreich sein: evtl. wurde ein weiteres Paket mit einem gleichnamigen Befehl geladen - dann wird der erste Befehl überschrieben (meist mit einer Warnung), die bespielweise so aussehen kann:\n\nDie folgenden Objekte sind maskiert von ‘package:dplyr’:\n\n    between, first, last\n\nDas folgende Objekt ist maskiert ‘package:purrr’:\n\n    transpose\n\nDas kann umgangen werden, wenn gewisse Pakte gar nicht vollständig geladen, sondern lediglich die nötigen Funktionen mit :: aufgerufen werden.\n\n\n\n\n\n\n\n\n\nWenn keine Internetverbindung besteht\n\n\n\n\n\nUnter R Packages können die benötigten Pakete heruntergeladen werden. Nachdem wir das Paket als .zip-Datei gespeichert haben, wir mit folgendem Befehl das Paket in der R-Umgebung installieren:\n\n# Installation von Paket \"XML\"\ninstall.packages(\"E:/XML_3.98-1.3.zip\", repos = NULL, type = \"source\")"
  },
  {
    "objectID": "02_intro.html#tidyverse",
    "href": "02_intro.html#tidyverse",
    "title": "2  Arbeiten mit Datensätzen in R",
    "section": "2.4 {tidyverse}",
    "text": "2.4 {tidyverse}\nWir werden in diesem Kurs vor allem mit Paketen aus dem {tidyverse} arbeiten. tidyverse ist eine Sammlung an Paketen, die übergreifende Syntaxlogik haben und so besonders gut miteinander harmonisieren und eine riesige Bandbreite an Anwendungsfällen abdecken. Mit\n\ninstall.packages(\"tidyverse\")\n\nwerden folgende Pakete installiert:\nbroom, conflicted, cli, dbplyr, dplyr, dtplyr, forcats, ggplot2, googledrive, googlesheets4, haven, hms, httr, jsonlite, lubridate, magrittr, modelr, pillar, purrr, ragg, readr, readxl, reprex, rlang, rstudioapi, rvest, stringr, tibble, tidyr, xml2, tidyverse\nWir werden einige im Laufe des Kurses kennen lernen. Das zunächst wichtigste ist {dplyr}, welches unter anderem die Auswahl von Fällen und Variablen erleichtert:\n\n\n\n\n\nDarstellung basierend auf dem {dplyr} Cheatsheet\n\n\n\n\n\ninstall.packages(\"tidyverse\") \n# installiert die komplette Paketsammlung des tidyverse"
  },
  {
    "objectID": "02_intro.html#zeilen-auswählen-mit-slice",
    "href": "02_intro.html#zeilen-auswählen-mit-slice",
    "title": "2  Arbeiten mit Datensätzen in R",
    "section": "2.5 Zeilen auswählen mit slice()",
    "text": "2.5 Zeilen auswählen mit slice()\n\nlibrary(tidyverse) # nach einmaligem install.packages(\"tidyverse\")\n\nEine erste Funktion aus dem {tidyverse} ist slice(), mit welcher wir Zeilen auswählen können:\n\nslice(dat1,1)\n\n  studs profs gegr stu_prof        uni\n1 19173   322 1971 59.54348 Uni Bremen\n\n2:3 # ergibt eine Zahlenfolge\n\n[1] 2 3\n\nslice(dat1,2:3)\n\n  studs profs gegr stu_prof           uni\n1  5333    67 1830 79.59701    Uni Vechta\n2 15643   210 1973 74.49048 Uni Oldenburg\n\nc(1,3) # Vektor mit Werten\n\n[1] 1 3\n\nslice(dat1,c(1,3))\n\n  studs profs gegr stu_prof           uni\n1 19173   322 1971 59.54348    Uni Bremen\n2 15643   210 1973 74.49048 Uni Oldenburg"
  },
  {
    "objectID": "02_intro.html#filter",
    "href": "02_intro.html#filter",
    "title": "2  Arbeiten mit Datensätzen in R",
    "section": "2.6 Beobachtungen auswählen mit filter()",
    "text": "2.6 Beobachtungen auswählen mit filter()\nNachdem wir zunächst das Paket für filter() installiert haben (das ist {dplyr}) müssen wir das Paket noch mit library() laden:\n\nfilter(dat1,uni == \"Uni Oldenburg\", studs > 1000)\n\n  studs profs gegr stu_prof           uni\n1 15643   210 1973 74.49048 Uni Oldenburg\n\n\nDie Auswahl ändert das Ausgangsobjekt dat1 aber nicht:\n\ndat1\n\n  studs profs gegr stu_prof           uni\n1 19173   322 1971 59.54348    Uni Bremen\n2  5333    67 1830 79.59701    Uni Vechta\n3 15643   210 1973 74.49048 Uni Oldenburg\n\n\nMöchten wir das Ergebnis unserer Auswahl mit filter() für weitere Schritte behalten, können wir unser Ergebnis in einem neuen data.frame-Objekt ablegen:\n\nueber_10tsd <- filter(dat1, studs > 10000)\nueber_10tsd\n\n  studs profs gegr stu_prof           uni\n1 19173   322 1971 59.54348    Uni Bremen\n2 15643   210 1973 74.49048 Uni Oldenburg\n\nclass(ueber_10tsd)\n\n[1] \"data.frame\"\n\n\n\n2.6.1 Auswahloperatoren\nR und {dplyr} stellen uns einige weitere Operatoren zur Auswahl von Zeilen zu Verfügung:\n\n<= und >=\n| oder\n%in% “eines von”\nbetween() ist eine Hilfsfunktion aus {dplyr} für Wertebereiche\n\n\nfilter(dat1, studs >= 10000)\nfilter(dat1, studs <= 10000)\nfilter(dat1,studs > 10000 | profs < 200) # mehr als 10.000 Studierende *oder* weniger als 200 Professuren\nfilter(dat1, gegr %in% c(1971,1830)) # gegründet 1971 oder 1830\nfilter(dat1, between(gegr,1971,1830)) # gegründet zwischen 1971 und 1830 (einschließlich)"
  },
  {
    "objectID": "02_intro.html#variablentypen-ii-logical",
    "href": "02_intro.html#variablentypen-ii-logical",
    "title": "2  Arbeiten mit Datensätzen in R",
    "section": "2.7 Variablentypen II: logical",
    "text": "2.7 Variablentypen II: logical\nDiese Auswahl basiert auf einem dritten Variablentyp: ‘logical’, also logische Werte mit TRUE oder FALSE. Wenn wir mit ==, > oder < eine Bedingung formulieren, dann erstellen wir eigentlich einen logischen Vektor in der selben Länge wie die Daten:\n\ndat1$studs > 10000 # ist die Studi-Zahl größer 10000?\n\n[1]  TRUE FALSE  TRUE\n\ndat1$more10k <-  dat1$studs > 10000 # ist die Studi-Zahl größer 10000?\n\n\ndat1\n\n  studs profs gegr stu_prof           uni more10k\n1 19173   322 1971 59.54348    Uni Bremen    TRUE\n2  5333    67 1830 79.59701    Uni Vechta   FALSE\n3 15643   210 1973 74.49048 Uni Oldenburg    TRUE\n\n\nWir könnten dann auch auf Basis dieser Variable filtern:\n\nfilter(dat1,more10k)\n\n  studs profs gegr stu_prof           uni more10k\n1 19173   322 1971 59.54348    Uni Bremen    TRUE\n2 15643   210 1973 74.49048 Uni Oldenburg    TRUE"
  },
  {
    "objectID": "02_intro.html#select",
    "href": "02_intro.html#select",
    "title": "2  Arbeiten mit Datensätzen in R",
    "section": "2.8 Variablen auswählen mit select()",
    "text": "2.8 Variablen auswählen mit select()\nMit select() enthält {dplyr} auch einen Befehl zu Auswahl von Spalten/Variablen:\n\ndat1\n\n  studs profs gegr stu_prof           uni more10k\n1 19173   322 1971 59.54348    Uni Bremen    TRUE\n2  5333    67 1830 79.59701    Uni Vechta   FALSE\n3 15643   210 1973 74.49048 Uni Oldenburg    TRUE\n\nselect(dat1, studs,profs)\n\n  studs profs\n1 19173   322\n2  5333    67\n3 15643   210\n\n\nWir können auch hier einige Operatoren verwenden: : um einen Bereich auszuwählen oder ! als “nicht”-Operator:\n\nselect(dat1, 1:3) # Spalte 1-3\n\n  studs profs gegr\n1 19173   322 1971\n2  5333    67 1830\n3 15643   210 1973\n\nselect(dat1, !profs) # alles außer profs\n\n  studs gegr stu_prof           uni more10k\n1 19173 1971 59.54348    Uni Bremen    TRUE\n2  5333 1830 79.59701    Uni Vechta   FALSE\n3 15643 1973 74.49048 Uni Oldenburg    TRUE\n\n\nAuch hier gilt: wenn wir die Veränderungen auch weiter verwenden wollen, müssen wir sie in einem neuen Objekt ablegen:\n\ndat_ohne_profs <- select(dat1, !profs) \ndat_ohne_profs\n\n  studs gegr stu_prof           uni more10k\n1 19173 1971 59.54348    Uni Bremen    TRUE\n2  5333 1830 79.59701    Uni Vechta   FALSE\n3 15643 1973 74.49048 Uni Oldenburg    TRUE\n\n\n…oder das alte überschreiben:\n\ndat1 <- select(dat1, !profs) # alles außer profs\n\n\n2.8.1 Hilfsfunktionen\nselect() hat außerdem einige Hilfsfunktionen, welche die Variablenauswahl auf Basis der Variablennamen einfacher machen.\n\nstarts_with(): Variablenname beginnt mit …, bspw. select(dat1,starts_with(\"p\"))\nends_with(): Variablenname endet mit …, bspw. select(dat1,ends_with(\"p\"))\nmatches(): Variablenauswahl mit einer regular expression, bspw. select(dat1,matches(\"_\")): alle Variablen mit _ im Namen.\nnum_range(): Variablen mit Zahlenbereiche: select(etb,num_range(\"F\",1:220))\nlast_col(): Letzte Variable, für die 4.letzte Variable bspw. last_col(4)\nany_of() um eine Auswahl auf Basis eines character-Vektors zu treffen\n\n\n\nCode\n# Spalten eines `data.frame`s auf Basis der `colnames` eines data.frames auswählen möchten:\ncol_auswahl <- colnames(dat1_orig)\ncol_auswahl\nselect(dat1, any_of(col_auswahl) )\n\n\n# Oder wir wollen alle Variablen, die mit \"s\" beginnen:\nselect(dat1,starts_with(\"s\"))\nselect(dat1,matches(\"^s\")) # gleiches Ergebnis mit regex\nselect(dat1,matches(\"s$\")) # alle Spalten, die mit s enden\n\n\nEs gibt noch einige weitere Hilfsfunktionen, für eine vollständige Auflistung ?select_helpers.\n\n\n2.8.2 Übung"
  },
  {
    "objectID": "02_intro.html#pipe",
    "href": "02_intro.html#pipe",
    "title": "2  Arbeiten mit Datensätzen in R",
    "section": "2.9 Arbeiten mit der Pipe: filter() und select() kombinieren",
    "text": "2.9 Arbeiten mit der Pipe: filter() und select() kombinieren\nWenn wir jetzt aber einige Zeilen und einige Spalten auswählen möchten, dann können wir filter() und select() kombinieren:\n\nselect(filter(dat1,studs < 10000),uni)\n\n         uni\n1 Uni Vechta\n\n\nDiese Befehlsschachtel können wir mit der sog. Pipe %>% auflösen. %>% steht einfach für “und dann”. Die Pipe kommt aus dem Paket {magrittr}, welches wiederum Teil des tidyverse ist und automatisch mit {dplyr} geladen wird.\n\nfilter(dat1,studs < 10000) %>% select(uni)\n\n         uni\n1 Uni Vechta\n\n\nHäufig wird die Pipe dann so verwendet, dass zu Beginn lediglich der zu bearbeitende Datensatz steht und sich dann die Schritte anschließen:\n\ndat1 %>% filter(.,studs < 10000) %>% select(.,uni)\n\n         uni\n1 Uni Vechta\n\n\nDer Punkt . steht jeweils für das Ergebnis des vorherigen Schritts. Hier also:\n\nRufe dat1 auf und dann (%>%)\nWähle nur Zeilen aus in denen studs < 10000 und dann (%>%)\nBehalte nur die Spalte uni\n\nDan Punkt können wir auch weglassen:\n\ndat1 %>% filter(studs < 10000) %>% select(uni)\n\n         uni\n1 Uni Vechta\n\n\n\n\n\n\n\n\nTip\n\n\n\n%>% kann mit STRG+SHIFT+m (cmd+shift+m für Mac) eingefügt werden."
  },
  {
    "objectID": "02_intro.html#variablentyp-iii-factor---eigene-reihenfolgen-festlegen",
    "href": "02_intro.html#variablentyp-iii-factor---eigene-reihenfolgen-festlegen",
    "title": "2  Arbeiten mit Datensätzen in R",
    "section": "2.10 Variablentyp III: factor - eigene Reihenfolgen festlegen",
    "text": "2.10 Variablentyp III: factor - eigene Reihenfolgen festlegen\nEin weitere häufige Aufgabe in der Datenanalyse ist das Sortieren von Datensätzen. Dazu haben wir arrange() zur Verfügung:\n\ndat1 %>% arrange(studs)\n\n  studs profs gegr stu_prof           uni more10k\n1  5333    67 1830 79.59701    Uni Vechta   FALSE\n2 15643   210 1973 74.49048 Uni Oldenburg    TRUE\n3 19173   322 1971 59.54348    Uni Bremen    TRUE\n\n\nDas funktioniert auch für string-Variablen:\n\ndat1 %>% arrange(uni)\n\n  studs profs gegr stu_prof           uni more10k\n1 19173   322 1971 59.54348    Uni Bremen    TRUE\n2 15643   210 1973 74.49048 Uni Oldenburg    TRUE\n3  5333    67 1830 79.59701    Uni Vechta   FALSE\n\n\nWas aber, wenn wir eine fixe Ordnung vergeben möchten, die nicht der numerischen oder alphabetischen Ordnung entspricht? Hier bspw. wenn wir die Unis in folgende Ordnung bringen möchten: 1) Uni Oldenburg, 2) Uni Bremen und 3) Uni Vechta. Dabei hilft uns ein dritter Variablentyp: factor.\nMit dem Argument levels = können wir eine Reihenfolge festlegen:\n\nfactor(dat1$uni, levels = c(\"Uni Oldenburg\", \"Uni Bremen\", \"Uni Vechta\"))\n\n[1] Uni Bremen    Uni Vechta    Uni Oldenburg\nLevels: Uni Oldenburg Uni Bremen Uni Vechta\n\ndat1$uni_fct <- factor(dat1$uni, \n                       levels = c(\"Uni Oldenburg\", \"Uni Bremen\", \"Uni Vechta\"))\n\nWenn wir nun nach uni_fct sortieren, dann wird die Reihenfolge der levels berücksichtigt:\n\nclass(dat1$uni_fct)\n\n[1] \"factor\"\n\ndat1 %>% arrange(uni_fct)\n\n  studs profs gegr stu_prof           uni more10k       uni_fct\n1 15643   210 1973 74.49048 Uni Oldenburg    TRUE Uni Oldenburg\n2 19173   322 1971 59.54348    Uni Bremen    TRUE    Uni Bremen\n3  5333    67 1830 79.59701    Uni Vechta   FALSE    Uni Vechta\n\n\nMit desc() können wir in umgekehrter Reihenfolge sortieren:\n\ndat1 %>% arrange(desc(uni_fct))\n\n  studs profs gegr stu_prof           uni more10k       uni_fct\n1  5333    67 1830 79.59701    Uni Vechta   FALSE    Uni Vechta\n2 19173   322 1971 59.54348    Uni Bremen    TRUE    Uni Bremen\n3 15643   210 1973 74.49048 Uni Oldenburg    TRUE Uni Oldenburg\n\n\nDas mag für den Moment relativ trivial erscheinen, ist aber später sehr praktisch um in Grafiken Variablen in eine gewisse Ordnung zu bringen oder in Regressionsmodellen die Referenzkategorie festzulegen.\nNatürlich können wir auch nach mehreren Variablen sortieren, dazu fügen wir einfach weitere in arrange() ein:\n\ndat1 %>% arrange(desc(uni_fct), gegr, studs) \n\n  studs profs gegr stu_prof           uni more10k       uni_fct\n1  5333    67 1830 79.59701    Uni Vechta   FALSE    Uni Vechta\n2 19173   322 1971 59.54348    Uni Bremen    TRUE    Uni Bremen\n3 15643   210 1973 74.49048 Uni Oldenburg    TRUE Uni Oldenburg\n\n\n(Macht in diesem Beispiel aber wenig Sinn)\n\n2.10.1 Übung"
  },
  {
    "objectID": "02_intro.html#import",
    "href": "02_intro.html#import",
    "title": "2  Arbeiten mit Datensätzen in R",
    "section": "2.11 Datensätze einlesen",
    "text": "2.11 Datensätze einlesen\nIn der Regel werden wir aber Datensätze verwenden, deren Werte bereits in einer Datei gespeichert sind und die wir lediglich einlesen müssen. Dafür gibt es unzählige Möglichkeiten.\nWir werden hier vor allem den Import von csv-Dateien verwenden. csv 3 bezeichnet ein verbreitetes Dateiformat zur Speicherung oder zum Austausch einfach strukturierter Daten. Wesentlich für unsere Zwecke hier ist, dass in csv-Dateien die Spalten eines Datensatzes mit einem Trennzeichen gekennzeichnet sind. Verbreitete Trennzeichen sind Komma, Doppelpunkt oder Semikolon. Für alle weiteren Dateien, die wir im Lauf dieser Veranstaltung verwenden werden, ist das Semikolon als Trennzeichen gesetzt. Unser Datensatz dat1 sieht im csv-Format so aus:\n\n\n\n\nIn diesem Seminar werden wir mit Daten aus BIBB/BAuA-Erwerbstätigenbefragung 2018 arbeiten. Die BIBB/BAuA ist eine Repräsentativbefragung von in Deutschland zu Arbeit und Beruf im Wandel und Erwerb und Verwertung beruflicher Qualifikation. Nun wollen wir also eine csv-Datei einlesen, zunächst eine reduzierte Version der ETB 2018.\nUm den Datensatz nun in R zu importieren, müssen wir R mitteilen unter welchem Dateipfad der Datensatz zu finden ist. Der Dateipfad ergibt sich aus der Ordnerstruktur Ihres Gerätes, so würde der Dateipfad im hier dargestellten Fall “D:/Kurse/R-Kurs/” lauten:\nNatürlich hängt der Dateipfad aber ganz davon ab, wo Sie den Datensatz gespeichert haben:\n\n\n\n\n\n\n\n\n\nUm den Pfad des Ordners herauszufinden, klicken Sie bei Windows in die obere Adresszeile im Explorerfenster.\n\n\n\n\n\n\n\n\n\n\nIn iOS (Mac) finden Sie den Pfad, indem Sie einmal mit der rechten Maustaste auf die Datei klicken und dann die ALT-Taste gedrückt halten. Dann sollte die Option “…als Pfadname kopieren” erscheinen. Youtube Anleitung\n\nDiesen Dateipfad müssen wir also R mitteilen.\n\n2.11.1 Projekt einrichten\nGrundsätzlich lohnt es sich, in RStudio Projekte einzurichten. Projekte sind .Rproj-Dateien , die automatisch Arbeitsverzeichnis auf den Ort setzen, an dem sie gespeichert sind. Das erleichtert das kollaborative Arbeiten: egal wer und auf welchem Gerät gerade an einem Projekt arbeitet - durch die Projektdatei sind alle Pfade immer relativ zum Projektverzeichnis. Im weiteren können auch Versionkontrolle via git, bspw. github und weitere Funktionen in der Projektdatei hinterlegt werden und so für alle Nutzenden gleich gesetzt werden. Außerdem bleiben die zuletzt geöffneten Scripte geöffnet, was ein Arbeiten an mehreren Projekten erleichtert.\n\n\n\n\n\n\n\n\n\nMit getwd() lässt sich überprüfen, ob das funktioniert hat:\n\ngetwd()\n\n\n\n[1] \"D:/Kurse/R-Kurs\"\n\n\n\n\n\n\n\n\n\n\n\nAlternativ könnten wir auch mit folgendem Befehl ein .Rproj - Projekt erstellen (hier ein Beispiel für den Aufruf eines Pakets mit ::):\n\nrstudioapi::initializeProject(path = \"D:/Kurse/R-Kurs\")\n\n\n\n\n\n\n2.11.2 Der Einlesebefehl\nJetzt können wir den eigentlichen Einlesebefehl read.table verwenden. Für den Pfad können wir nach file = lediglich die Anführungszeichen angeben und innerhalb dieser die Tab-Taste drücken. Dann bekommen wir alle Unterverzeichnisse und Tabellen im Projektordner angezeigt.4\n\netb <- read.table(file = \"./data/BIBBBAuA_2018_small.csv\", sep = \";\", header = T)\n\nDer Einlesevorgang besteht aus zwei Teilen: zuerst geben wir mit etb den Objektnamen an, unter dem R den Datensatz ablegt. Nach dem <- steht dann der eigentliche Befehl read.table(), der wiederum mehrere Optionen enthält. Als erstes geben wir den genauen Datensatznamen an - inklusive der Dateiendung. Darüber hinaus teilen wir R mit sep mit, dass ; als Trennzeichen gesetzt wurde und mit header = T (T steht für TRUE) teilen wir R zudem mit, dass die erste Zeile aus dem Datensatz als Spaltennamen verwendet werden soll.\n\nLeider nutzen Windows-Systeme \\ in den Dateipfaden - das führt in R zu Problemen. Daher müssen Dateipfade immer mit / oder alternativ mit \\\\ angegeben werden. RStudio kann zumindest etwas unterstützen, dem mit der STRG + F die Suchen & Ersetzen Funktion verwendet wird.\n\nWürden hier jetzt einfach etb eintippen bekämen wir den kompletten Datensatz angezeigt. Für einen Überblick können wir head verwenden:\n\nhead(etb)\n\n  intnr az S1 S3 S2_j zpalter Stib Bula m1202 F209 F209_01\n1   260 80  1  8 1976      41    4   11     4    1      NA\n2   361 30  2  5 1966      51    2   11     2    1      NA\n3   491 40  1  7 1968      49    1   11     4    2       1\n4   690 40  2  8 1954      63    3   11     4    1      NA\n5   919 39  2  7 1976      41    2   11     2    1      NA\n6  1041 40  1  5 1960      57    2   11     2    2       2\n\n\nMit nrow und ncol können wir kontrollieren, ob das geklappt hat. Der Datensatz sollte 20012 Zeilen und 11 Spalten haben:\n\nnrow(etb)\n\n[1] 20012\n\nncol(etb)\n\n[1] 11\n\n\nNatürlich können wir wie oben auch aus diesem, viel größeren, Datensatz Zeilen und Spalten auswählen. Zum Beispiel können wir die Befragten auswählen, die vor 1940 geboren sind und diese unter senior ablegen:\n\nsenior <- etb %>% filter(S2_j < 1940)\n\nMöchten wir die genauen Altersangaben der Befragten aus senior sehen, können wir die entsprechende Spalte mit senior$age aufrufen:\n\nsenior$zpalter\n\n [1] 78 83 78 81 81 78 81 80 82 81 79 79 81 78 87\n\n\nAußerdem hat senior natürlich deutlich weniger Zeilen als etb:\n\nnrow(senior)\n\n[1] 15\n\n\nWie wir beim Überblick gesehen haben, gibt es aber noch deutlich mehr Variablen in der ETB als zpalter und nicht alle haben so aussagekräftige Namen - z.B. gkpol. Um diese Variablennamen und auch die Bedeutung der Ausprägungen zu verstehen brauchen wir das Codebuch. Außerdem können wir auf die attributes() einer Variable zurückgreifen - mehr zu labels später.\n\n\n2.11.3 Übung"
  },
  {
    "objectID": "02_intro.html#überblick-einlesen-und-exportieren",
    "href": "02_intro.html#überblick-einlesen-und-exportieren",
    "title": "2  Arbeiten mit Datensätzen in R",
    "section": "2.12 Überblick: Einlesen und Exportieren",
    "text": "2.12 Überblick: Einlesen und Exportieren\n\n2.12.1 Datensätze einlesen\n\nÜberblickCode\n\n\n\n\n\n\n \n  \n    Dateityp \n    R Funktion \n    R Paket \n    Anmerkung \n  \n \n\n  \n    .csv \n    read.table() \n    - \n    mit `sep = \";\"` Trennzeichen angeben \n  \n  \n    .Rdata (R format) \n    readRDS \n    - \n     \n  \n  \n    große .csv \n    vroom() \n    {vroom} \n    mit `delim = \";\"` Trennzeichen angeben \n  \n  \n    .dta (Stata) \n    read_dta() \n    {haven} \n     \n  \n  \n    .dat (SPSS) \n    read_spss() \n    {haven} \n     \n  \n  \n    .xlsx (Excel) \n    read_xlsx() \n    {readxl} \n    mit `sheet = 1` Tabellenblatt angeben (funktioniert auch mit Namen) \n  \n\n\n\n\n\n\n\n\n# csv Datei\ndat1 <- read.table(file = \"Dateiname.csv\",sep = \";\")\n# Rdata\ndat1 <- readRDS(file = \"Dateiname.Rdata\")\n# große csv\nlibrary(vroom)\ndat1 <- vroom(file = \"Dateiname.csv\",delim = \";\")\n# Stata dta\nlibrary(haven)\ndat1 <- read_dta(file = \"Dateiname.dta\")\n# SPSS sav\ndat1 <- read_sav(file = \"Dateiname.sav\")\n# Excel\ndat1 <- read_xlsx(path = \"Dateiname.xlsx\", sheet = \"1\")\ndat1 <- read_xlsx(path = \"Dateiname.xlsx\", sheet = \"Tabellenblatt1\")\n\n\n\n\n\n\n2.12.2 Datensätze exportieren\n\nÜberblickCode\n\n\n\n\n\n\n \n  \n    Dateityp \n    R Funktion \n    R Paket \n    Anmerkung \n  \n \n\n  \n    .Rdata (R format) \n    saveRDS() \n    - \n    alle Variableneigenschaften bleiben erhalten \n  \n  \n    .csv \n    write.table() \n    - \n    mit `sep = \";\"` Trennzeichen angebenmit row.names= F Zeilennummerierung unterdrücken \n  \n  \n    .dta (Stata) \n    write_dta() \n    {haven} \n     \n  \n  \n    .dat (SPSS) \n    write_spss() \n    {haven} \n     \n  \n  \n    .xlsx (Excel) \n    write.xlsx() \n    {xlsx} \n    mit `sheetName` ggf. Tabellenblattname angeben \n  \n\n\n\n\n\n\n\n\n# Rdata\nsaveRDS(dat1,file = \"Dateiname.Rdata\")\n# csv\nwrite.table(dat1,file = \"Dateiname.csv\",sep = \";\",row.names = F)\n# dta\nlibrary(haven)\nwrite_dta(dat1,path = \"Dateiname.dta\")\n# sav\nlibrary(haven)\nwrite_sav(dat1,path = \"Dateiname.sav\")\n# xlsx\nlibrary(xlsx)\nwrite.xlsx(dat1,file = \"Dateiname.xlsx\", sheetName = \"Tabellenblatt 1\")\n\n\n\n\n\n\n2.12.3 Objekte exportieren\nWir können aber auch einzelne oder mehrere Objekte exportieren und später wieder einlesen:\n\nsave(studs, file = \"./data/stud_vektor.RData\")\nrm(studs)\nload(file = \"./data/stud_vektor.RData\") # studs wieder mit selbem Namen zurück im environment\n\nMehrere Objekte:\n\nsave(studs,profs, file = \"./data/meine_vektoren.RData\")\nrm(studs,profs)\nload(file = \"./data/meine_vektoren.RData\") # studs & profs mit selbem Namen zurück im environment\n\n\n\n\n\n\n\n\n\n\n\nDer Begriff speichern kann in R bisweilen zu Missverständnissen führen: Ist gemeint, einen Datensatz o.ä. (1) auf der Festplatte als .csv, .dta, .sav für andere Programme zugänglich abzulegen oder lediglich die Ergebnisse intern in R unter einem Objektnamen abzulegen? Ich vermeide daher das Wort speichern und spreche entweder von exportieren (im Fall 1 - in eine Datei schreiben) oder ablegen (Fall 2 - Ergebnisse/Werte innerhalb von R in einem Objekt abzulegen)"
  },
  {
    "objectID": "02_intro.html#hilfe-zu-paketen-und-funktionen",
    "href": "02_intro.html#hilfe-zu-paketen-und-funktionen",
    "title": "2  Arbeiten mit Datensätzen in R",
    "section": "2.13 Hilfe zu Paketen und Funktionen",
    "text": "2.13 Hilfe zu Paketen und Funktionen\nR Pakete kommen (häufig) mit sehr ausführlichen Hilfeseiten, die entweder direkt aus RStudio abgerufen werden können:\n\n# Hilfe zu Paketen\nvignette(\"dplyr\")\nvignette(package = \"dplyr\")\nvignette(\"rowwise\")\nhelp(\"dplyr\")\nhelp(package = \"dplyr\")\n\n\n# Hilfe zu Funktionen\n?select()\n\nAlternativ führt aber Google auch zum Ziel, bspw. R dplyr select()\nOder auf CRAN (woher auch install.packages() die Pakete bezieht):\n\n\n\n\n\nCRAN-Seite für {dplyr}"
  },
  {
    "objectID": "02_intro.html#übungen",
    "href": "02_intro.html#übungen",
    "title": "2  Arbeiten mit Datensätzen in R",
    "section": "2.14 Übungen",
    "text": "2.14 Übungen\n\n2.14.1 Übung 1\n\nErstellen Sie den Datensatz mit den Studierenden- & Prof-Zahlen wie gezeigt:\n\n\ndat2 <- data.frame(studs = c(14954,47269 ,23659,9415 ,38079), \n                   profs = c(250,553,438 ,150,636),\n                   prom_recht = c(FALSE,TRUE,TRUE,TRUE,FALSE),\n                   gegr  = c(1971,1870,1457,1818,1995))\n\n\nSehen Sie den dat2 in Ihrem Environment?\nLassen Sie sich dat2 in der Console ausgeben.\nFügen Sie die Namen der Unis als neue Spalte in den Datensatz ein. Diese sind in dieser Reihenfolge:\n\n\nc(\"FH Aachen\",\"RWTH Aachen\",\"Uni Freiburg\",\"Uni Bonn\",\"FH Bonn-Rhein-Sieg\")\n\n\nLassen Sie sich dat2 anzeigen - in der Console oder mit View()\nBerechnen Sie das Verhältnis Studierende pro Professur und legen Sie die Ergebnisse in einer neuen Variable an. Sehen Sie sich das Ergebnis an.\n\nZurück nach oben\n\n\n2.14.2 Übung 2\n\nInstallieren Sie die Pakete des tidyverse mit install.packages(\"tidyverse\")\nVerwenden Sie wieder den data.frame dat2 aus Übung 1\nNutzen Sie filter, um sich nur die Unis mit unter 10000 Studierenden anzeigen zu lassen. (Denken Sie daran, {tidyverse} zu installieren und mit library() zu laden)\nLassen Sie sich nur die dritte Zeile von dat2 anzeigen.\nLassen Sie sich nur die Spalte gegr anzeigen.\nLassen Sie sich nur Zeilen der Hochschulen mit Promotionsrecht (prom_recht) anzeigen.\n\nZurück nach oben\n\n\n2.14.3 Übung 3\n\nVerwenden Sie weiterhin den Datensatz aus Übung 1 & 2.\nLassen Sie sich nur Hochschulen anzeigen, die 1971, 1457 oder 1995 gegründet wurden - und für diese Fälle nur den Namen und das Gründungsjahr.\nSortieren Sie den Datensatz entsprechend dieser Reihenfolge. (Legen Sie dazu eine factor-Variable an, welche die entsprechende Reihenfolge festlegt.)\n\n\nc(\"RWTH Aachen\",\"Uni Freiburg\",\"Uni Bonn\",\"FH Aachen\",\"FH Bonn-Rhein-Sieg\")\n\nZurück nach oben\n\n\n2.14.4 Übung 4\n\nErstellen Sie in Ihrem Verzeichnis für diesen Kurs ein R-Projekt\nLegen Sie die Erwerbstätigenbefragung in Ihrem Verzeichnis im Unterordner data ab.\nLesen Sie den Datensatz BIBBBAuA_2018_small.csv wie oben gezeigt in R ein und legen Sie den Datensatz unter dem Objektnamen etb_small ab.\nNutzen Sie head() und View(), um sich einen Überblick über den Datensatz zu verschaffen.\nWie viele Befragte (Zeilen) enthält der Datensatz?\nLassen Sie sich die Variablennamen von etb_small mit names() anzeigen!\nWie können Sie sich die Zeile anzeigen lassen, welche den/die Befragte*n mit der intnr 2781 enthält?\nWie alt ist der/die Befragte mit der intnr 2781?\nErstellen Sie eine neue Variable mit dem Alter der Befragten im Jahr 2022! (Das Geburtsjahr ist in der Variable S2_j abgelegt.)\nWählen Sie alle Befragten aus, die nach 1960 geboren wurden legen Sie diese Auswahl unter nach_1960 ab.\nWie viele Spalten hat nach_1960? Wie viele Zeilen?\n\nZurück nach oben"
  },
  {
    "objectID": "02_intro.html#anhang",
    "href": "02_intro.html#anhang",
    "title": "2  Arbeiten mit Datensätzen in R",
    "section": "2.15 Anhang",
    "text": "2.15 Anhang\n\n2.15.1 Alternativen zu R-Projekten\nNeben dem Einrichten eines Projekts können wir den Pfad auch mit setwd() setzen oder direkt in read.table() angeben. Das hat allerdings den Nachteil, dass diese Strategie nicht auf andere Rechner übertragbar ist: wenn jemand anderes die .Rproj-Datei öffnet, wird R automatisch die Pfade relativ zum Speicherort der Datei setzen. Das gilt auch wenn wir das Verzeichnis verschieben auf unserem Gerät - R wird automatisch das Arbeitsverzeichnis auf den neuen Speicherort setzen.\nZum Setzen des Arbeitsverzeichnis mit setwd() setzen wir in die Klammern den Pfad des Ordners ein. Wichtig dabei ist dass Sie ggf. alle \\ durch /ersetzen müssen:\n\nsetwd(\"D:/Kurse/R_BIBB\")\n\nMit getwd() lässt sich überprüfen, ob das funktioniert hat:\n\ngetwd()\n\nHier sollte der mit setwd() gesetzte Pfad erscheinen.\nAlternativ können wir auch in read.table() den vollen Pfad angeben:\n\netb <- read.table(\"C:/Kurse/R_BIBB/data/BIBBBAuA_2018_small.csv\", sep = \";\", header = T, stringsAsFactors = F)\n\n\n\n2.15.2 Zeilen & Spaltenauswahl ohne {dplyr}\nNatürlich kann auch base R (also R ohne Erweiterungen wie {dplyr} Datensätze filtern usw.), dazu wird [ ] verwendet:\n\ndat1[1,1] # erste Zeile, erste Spalte\n\n[1] 19173\n\ndat1[1,]  # erste Zeile, alle Spalten\n\n  studs profs gegr stu_prof        uni more10k    uni_fct\n1 19173   322 1971 59.54348 Uni Bremen    TRUE Uni Bremen\n\ndat1[,1]  # alle Zeilen, erste Spalte (entspricht hier dat1$studs)\n\n[1] 19173  5333 15643\n\ndat1[,\"studs\"] # alle Zeilen, Spalte mit Namen studs -> achtung: \"\"\n\n[1] 19173  5333 15643\n\n\nNatürlich können wir auch mehrere Zeilen oder Spalten auswählen. Dafür müssen wir wieder auf c( ) zurückgreifen:\n\ndat1[c(1,2),]  ## 1. & 2. Zeile, alle Spalten\ndat1[,c(1,3)]  ## alle Zeilen, 1. & 3. Spalte (entspricht dat1$studs & dat1$stu_prof)\ndat1[,c(\"studs\",\"uni\")] ## alle Zeilen, Spalten mit Namen studs und uni\n\nIn diese eckigen Klammern können wir auch Bedingungen schreiben, um so Auswahlen aus dat1 zu treffen.\n\ndat1 # vollständiger Datensatz\n\n  studs profs gegr stu_prof           uni more10k       uni_fct\n1 19173   322 1971 59.54348    Uni Bremen    TRUE    Uni Bremen\n2  5333    67 1830 79.59701    Uni Vechta   FALSE    Uni Vechta\n3 15643   210 1973 74.49048 Uni Oldenburg    TRUE Uni Oldenburg\n\ndat1[dat1$uni == \"Uni Oldenburg\", ] # Zeilen in denen uni gleich \"Uni Oldenburg\", alle Spalten\n\n  studs profs gegr stu_prof           uni more10k       uni_fct\n3 15643   210 1973 74.49048 Uni Oldenburg    TRUE Uni Oldenburg\n\ndat1$studs[dat1$uni == \"Uni Oldenburg\" ] # Nur Studi-Zahl nachsehen: kein Komma \n\n[1] 15643\n\n\nDas funktioniert soweit wie gewünscht und wir können das Ganze jetzt erweitern:\n\ndat1[dat1$uni == \"Uni Oldenburg\" & dat1$studs > 10000, ] # & bedeutet UND\n\nWir können auch hier einen ODER-Operator verwenden:\n\ndat1[dat1$uni == \"Uni Oldenburg\" | dat1$studs > 10000, ]\n\n\n\n2.15.3 select() vs $\nWenn wir mit select() eine spezifische Variable auswählen, wird trotzdem die Datenstruktur als data.frame() erhalten, während die Auswahl dat1$variablenname die Spalte als Vektor (also Wertereihe) ausgibt:\n\ndat1$studs\n\n[1] 19173  5333 15643\n\nclass(dat1$studs)\n\n[1] \"numeric\"\n\ndat1$studs/ 20\n\n[1] 958.65 266.65 782.15\n\n\nselect() erhält die Werte als Spalte eines data.frame:\n\ndat1 %>% select(studs)\n\n  studs\n1 19173\n2  5333\n3 15643\n\ndat1 %>% select(studs) %>% class()\n\n[1] \"data.frame\"\n\ndat1 %>% select(studs)/20 \n\n   studs\n1 958.65\n2 266.65\n3 782.15"
  },
  {
    "objectID": "03_desc.html",
    "href": "03_desc.html",
    "title": "3  Einen Überblick erhalten",
    "section": "",
    "text": "Nachdem wir Datensätze importiert haben, wollen wir nun einen Überblick erhalten. Jede statistische Auswertung startet mit einer Beschreibung der Variablen. In dieser Session werden wir sehen, wie wir uns mit Tabellen einen Überblick über die Informationen in einem Datensatz verschaffen können. Wir werden auch in dieser Session mit dem ETB2018 arbeiten. Wir starten also mit dem Einlesen der Daten:"
  },
  {
    "objectID": "03_desc.html#häufigkeitsauszählungen",
    "href": "03_desc.html#häufigkeitsauszählungen",
    "title": "3  Einen Überblick erhalten",
    "section": "3.1 Häufigkeitsauszählungen",
    "text": "3.1 Häufigkeitsauszählungen\nUns stehen (mindestens) drei Befehle zur Verfügung, um eine Häufigkeitsauszählung zu erstellen:\n\ntable()\nxtabs()\ncount() aus {dplyr}\n\nEinfachster Befehl für die Auszählung von Häufigkeiten ist der table() Befehl. Beispielsweise mit der Variable m1202 zur Ausbildung der Befragten.\n\ntable(etb18$m1202)\n\n\n  -1    1    2    3    4 \n  45 1091 9297 1725 7854 \n\n\nDie Syntax für xtabs() ist etwas anders, aber hier bekommen wir die Variablennamen nochmal angezeigt - der wesentliche Output ist aber der gleiche:\n\nxtabs(~m1202,data=etb18)\n\nm1202\n  -1    1    2    3    4 \n  45 1091 9297 1725 7854 \n\n\nWir bekommen hier die absoluten Häufigkeiten angezeigt. In der ersten Zeile werden die verschiedenen Ausprägungen aufgelistet, in der zweiten Zeile stehen dann die Häufigkeiten.\nAllerdings werden sowohl für table() als auch xabs() die labels in der Ausgabe erstmal ignoriert. Mit val_labels() aus dem Paket {labelled} können wir die Labels aus dem Datensatz abrufen. - bspw. steht 1 dafür, dass der*die Befragte die keine Berufsabschluss besitzt:\n\n\nCode\ninstall.packages(\"labelled\") # nur einmal nötig\nlibrary(labelled)\nval_labels(etb18$m1202)\n\n\n\n\n                                            keine Angabe \n                                                      -1 \n                                    Ohne Berufsabschluss \n                                                       1 \nduale o. schulische Berufsausbildung/einf.,mittl. Beamte \n                                                       2 \nAufstiegsfortbildung (Meister, Techniker, kfm. AFB u.ä.) \n                                                       3 \n        Fachhochschule, Universität/ geh., höhere Beamte \n                                                       4 \n\n\n\n\n\n1091 Befragte haben keinen Berufsabschluss, 1725 Befragte haben Aufstiegsfortbildung usw. (Zu labels und die Arbeit mit value labels in R später mehr)\nMit count() aus {dplyr} bekommen wir die labels direkt angezeigt, auch hier verwenden wir wieder die Schreibweise mit der Pipe %>%:\n\netb18 %>% count(m1202)\n\n# A tibble: 5 × 2\n  m1202                                                             n\n  <dbl+lbl>                                                     <int>\n1 -1 [keine Angabe]                                                45\n2  1 [Ohne Berufsabschluss]                                      1091\n3  2 [duale o. schulische Berufsausbildung/einf.,mittl. Beamte]  9297\n4  3 [Aufstiegsfortbildung (Meister, Techniker, kfm. AFB u.ä.)]  1725\n5  4 [Fachhochschule, Universität/ geh., höhere Beamte]          7854\n\n\nWir können auch Tabellen unter einem frei wählbaren Namen ablegen und später wieder aufrufen:\n\nt1 <- xtabs(~m1202,etb18)\nt2 <- etb18 %>% count(m1202)\n\nWir sehen hier, dass die Tabelle mit xtabs() eine neue Objektform ist, ein table. Mit count() wird hingegen ein data.frame erstellt.\n\nclass(t1)\n\n[1] \"xtabs\" \"table\"\n\nclass(t2)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\""
  },
  {
    "objectID": "03_desc.html#andere-tabellenwerte",
    "href": "03_desc.html#andere-tabellenwerte",
    "title": "3  Einen Überblick erhalten",
    "section": "3.2 Andere Tabellenwerte",
    "text": "3.2 Andere Tabellenwerte\nMit Hilfe weiterer Funktionen können wir die Häufigkeitstabellen jeweils anpassen:\n\nprop.table(): relative Werte/Anteile\n\n\nxtabs(~m1202,data=etb18) %>% prop.table(.) \n\nm1202\n         -1           1           2           3           4 \n0.002248651 0.054517290 0.464571257 0.086198281 0.392464521 \n\n\n0.225% aller Befragten haben keine Berufsausbildung.\n\ncumsum(): kumulierte Werte\n\n\nxtabs(~m1202,data=etb18) %>% cumsum(.)\n\n   -1     1     2     3     4 \n   45  1136 10433 12158 20012 \n\n\n\n\n\n1136 Befragte haben eine duale Berufsausbildung oder keine Berufsausbildung.\n\nprop.table() mit cumsum(): kumulierte relative Häufigkeiten\n\n\nxtabs(~m1202,data=etb18) %>% prop.table() %>% cumsum()\n\n         -1           1           2           3           4 \n0.002248651 0.056765940 0.521337198 0.607535479 1.000000000 \n\n\n\n\n\n5.677% aller Befragten haben eine duale Berufsausbildung oder keine Berufsausbildung."
  },
  {
    "objectID": "03_desc.html#kontingenztabellen",
    "href": "03_desc.html#kontingenztabellen",
    "title": "3  Einen Überblick erhalten",
    "section": "3.3 Kontingenztabellen",
    "text": "3.3 Kontingenztabellen\nAus Kontingenztabellen erfahren wir, wie häufig Merkmalskombinationen auftreten. Auch für Kontingenztabellen können wir table() verwenden. Zum Beispiel können wir uns eine Tabelle anzeigen lassen, die uns die Häufigkeiten des Familienstatus getrennt nach Geschlechtern zeigt:\n\ntable(etb18$S1, etb18$m1202)\n\n   \n      -1    1    2    3    4\n  1   21  594 4371 1073 4015\n  2   24  497 4926  652 3839\n\n\n\nxtabs(~S1+m1202, data = etb18)\n\n   m1202\nS1    -1    1    2    3    4\n  1   21  594 4371 1073 4015\n  2   24  497 4926  652 3839\n\n\nWir erkennen aus dieser Tabelle beispielsweise, dass 4926 Befragte weiblich (S1=2) und ohne Berufsabschluss (m1202 = 5) sind.\nHier ist xtabs() informativer als table(). Hier werden die Spalten und Zeilen beschriftet. Der Übersichtlichkeit halber verwende ich meistens xtabs(), alle Operationen sind aber genauso auch mit table() möglich.\n\n3.3.1 Übung"
  },
  {
    "objectID": "03_desc.html#NA03",
    "href": "03_desc.html#NA03",
    "title": "3  Einen Überblick erhalten",
    "section": "3.4 Fehlende Werte in R: NA",
    "text": "3.4 Fehlende Werte in R: NA\nUm die Werte mit -1 auch in R als fehlende Angabe zu kennzeichnen, müssen wir sie in etb18 auf NA setzen. Dazu rufen wir etb18$m1202 auf und filtern mit [] nur die Werte für m1202 gleich -1 heraus. Im vorherigen Kapitel haben wir kennengelernt, dass wir so spezifische Werte aufrufen können:\n\netb18$m1202[etb18$m1202 == -1] # nur m1202 = -1 aufrufen\n\n<labelled<double>[45]>: Höchster Ausbildungsabschluss\n [1] -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n[26] -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n\nLabels:\n value                                                    label\n    -1                                             keine Angabe\n     1                                     Ohne Berufsabschluss\n     2 duale o. schulische Berufsausbildung/einf.,mittl. Beamte\n     3 Aufstiegsfortbildung (Meister, Techniker, kfm. AFB u.ä.)\n     4         Fachhochschule, Universität/ geh., höhere Beamte\n\n\n(Hier bekommen wir nochmal die Labels ausgespuckt, was etwas suboptimal für die Übersichtlichkeit ist.)\nWenn wir daran mit <- einen neuen Wert angeben, werden die aufgerufenen Werte damit überschrieben - hier überschreiben wir also alle Werte für m1202 == -1 mit NA:\n\netb18$m1202[etb18$m1202 == -1]  <- NA\n\nNA ist in der R der Code für fehlende Angaben, sie werden dann in xtabs() nicht aufgeführt:\n\nxtabs(~m1202,data=etb18)\n\nm1202\n   1    2    3    4 \n1091 9297 1725 7854 \n\n\nWir können aber mit der Option addNA = TRUE die Auszählung von NA explizit anfordern:\n\nxtabs(~m1202,data=etb18,addNA = T)\n\nm1202\n   1    2    3    4 <NA> \n1091 9297 1725 7854   45 \n\n\nIn count() wird NA auch mit ausgezählt:\n\netb18 %>% count(m1202)\n\n# A tibble: 5 × 2\n  m1202                                                             n\n  <dbl+lbl>                                                     <int>\n1  1 [Ohne Berufsabschluss]                                      1091\n2  2 [duale o. schulische Berufsausbildung/einf.,mittl. Beamte]  9297\n3  3 [Aufstiegsfortbildung (Meister, Techniker, kfm. AFB u.ä.)]  1725\n4  4 [Fachhochschule, Universität/ geh., höhere Beamte]          7854\n5 NA                                                               45\n\n\nMöchten wir das umgehen, nehmen wir wieder filter() zu Hilfe - mit is.na() können wir NA identifizieren. Durch Voranstellen von ! können wir damit anfordern, dass alle nicht-NA-Werte mit TRUE behalten werden:\n\netb18 %>% filter(!is.na(m1202)) %>% count(m1202)\n\n# A tibble: 4 × 2\n  m1202                                                            n\n  <dbl+lbl>                                                    <int>\n1 1 [Ohne Berufsabschluss]                                      1091\n2 2 [duale o. schulische Berufsausbildung/einf.,mittl. Beamte]  9297\n3 3 [Aufstiegsfortbildung (Meister, Techniker, kfm. AFB u.ä.)]  1725\n4 4 [Fachhochschule, Universität/ geh., höhere Beamte]          7854\n\n\nMehr zu fehlenden Werten findet sich beispielsweise im The missing book von Nicholas Tierney & Allison Horst.\n\n3.4.1 Übung"
  },
  {
    "objectID": "03_desc.html#mehrere-kennzahlen-in-einer-tabelle",
    "href": "03_desc.html#mehrere-kennzahlen-in-einer-tabelle",
    "title": "3  Einen Überblick erhalten",
    "section": "3.5 Mehrere Kennzahlen in einer Tabelle",
    "text": "3.5 Mehrere Kennzahlen in einer Tabelle\nAus Stata kennen viele sicherlich folgende Ansicht mit tab m1202:\n\n\n          Höchster Ausbildungsabschluss |      Freq.     Percent        Cum.\n----------------------------------------+-----------------------------------\n                   Ohne Berufsabschluss |      1,091        5.46        5.46\nduale o. schulische Berufsausbildung/ei |      9,297       46.56       52.03\nAufstiegsfortbildung (Meister, Technike |      1,725        8.64       60.67\nFachhochschule, Universität/ geh., höhe |      7,854       39.33      100.00\n----------------------------------------+-----------------------------------\n                                  Total |     19,967      100.00\n\n\nIn R hat ein table() oder xtabs() immer nur eine Art von Kennzahlen. Da wir aber mit count() die Auszählungen als data.frame() erhalten, können wir die relativen und kumulierten Häufigkeiten einfach als neue Variablen anfügen. Dabei hilft uns mutate(): mit mutate(neu_variable = ) können wir neue Variablen in einen data.frame() hinzufügen:\n\n\n\n\n\n\n\n\n\nmutate() entspricht also dat1$var <- ...., das wir im vorherigen Kapitel kennen gelernt hatten. Allerdings können wir mit mutate() einfacher in einer Pipe-Kette arbeiten (und außerdem einige weitere Operationen einfacher erledigen - dazu später mehr).\nUm also eine neue Spalte pctin unseren data.frame mit den Auszählungen einzufügen gehen wir wie folgt vor:\n\netb18 %>% \n   count(m1202) # ausgangsbefehl\n\n# A tibble: 5 × 2\n  m1202                                                             n\n  <dbl+lbl>                                                     <int>\n1  1 [Ohne Berufsabschluss]                                      1091\n2  2 [duale o. schulische Berufsausbildung/einf.,mittl. Beamte]  9297\n3  3 [Aufstiegsfortbildung (Meister, Techniker, kfm. AFB u.ä.)]  1725\n4  4 [Fachhochschule, Universität/ geh., höhere Beamte]          7854\n5 NA                                                               45\n\netb18 %>% \n   count(m1202) %>% \n   mutate(pct= prop.table(n)*100) # erweitert um pct\n\n# A tibble: 5 × 3\n  m1202                                                             n    pct\n  <dbl+lbl>                                                     <int>  <dbl>\n1  1 [Ohne Berufsabschluss]                                      1091  5.45 \n2  2 [duale o. schulische Berufsausbildung/einf.,mittl. Beamte]  9297 46.5  \n3  3 [Aufstiegsfortbildung (Meister, Techniker, kfm. AFB u.ä.)]  1725  8.62 \n4  4 [Fachhochschule, Universität/ geh., höhere Beamte]          7854 39.2  \n5 NA                                                               45  0.225\n\n\n\netb18 %>% \n   count(m1202) %>% \n   mutate(pct= prop.table(n)*100,\n          Cum = cumsum(pct)) \n\n# A tibble: 5 × 4\n  m1202                                                          n    pct    Cum\n  <dbl+lbl>                                                  <int>  <dbl>  <dbl>\n1  1 [Ohne Berufsabschluss]                                   1091  5.45    5.45\n2  2 [duale o. schulische Berufsausbildung/einf.,mittl. Bea…  9297 46.5    51.9 \n3  3 [Aufstiegsfortbildung (Meister, Techniker, kfm. AFB u.…  1725  8.62   60.5 \n4  4 [Fachhochschule, Universität/ geh., höhere Beamte]       7854 39.2    99.8 \n5 NA                                                            45  0.225 100   \n\n\nDer Punkt . steht jeweils für das Ergebnis des vorherigen Schritts. Hier also:\n\nErstelle die Häufigkeitstablle für m1202 und dann (%>%)\nBerechne aus n die relativen Häufigkeiten und dann (%>%)\nBerechne dafür die kumulierten Werte basierend auf pct und dann (%>%)\nRunde das Ergebnis auf 3 Nachkommastellen\n\nEtwas störend ist aber noch das NA, die für fehlende Angaben steht und nicht berücksichtigt werden soll. Das können wir einfach !is.na() in filter() ausschließen:\n\netb18 %>% \n  filter(!is.na(m1202)) %>% \n   count(m1202) %>% \n   mutate(pct= prop.table(n)*100,\n          Cum = cumsum(pct)) \n\n# A tibble: 4 × 4\n  m1202                                                           n   pct    Cum\n  <dbl+lbl>                                                   <int> <dbl>  <dbl>\n1 1 [Ohne Berufsabschluss]                                     1091  5.46   5.46\n2 2 [duale o. schulische Berufsausbildung/einf.,mittl. Beamt…  9297 46.6   52.0 \n3 3 [Aufstiegsfortbildung (Meister, Techniker, kfm. AFB u.ä.…  1725  8.64  60.7 \n4 4 [Fachhochschule, Universität/ geh., höhere Beamte]         7854 39.3  100"
  },
  {
    "objectID": "03_desc.html#crosscount",
    "href": "03_desc.html#crosscount",
    "title": "3  Einen Überblick erhalten",
    "section": "3.6 Kontingenztabellen mit count()",
    "text": "3.6 Kontingenztabellen mit count()\nFür eine Kontingenztabelle mit count() geben wir einfach die interessierenden Variablen in count() an. Das Ergebnis wird immer im “long shape” Format ausgegeben:\n\netb18 %>% \n  filter(!is.na(m1202)) %>% \n   count(m1202,S1)\n\n# A tibble: 8 × 3\n  m1202                                                        S1              n\n  <dbl+lbl>                                                    <dbl+lbl>   <int>\n1 1 [Ohne Berufsabschluss]                                     1 [männlic…   594\n2 1 [Ohne Berufsabschluss]                                     2 [weiblic…   497\n3 2 [duale o. schulische Berufsausbildung/einf.,mittl. Beamte] 1 [männlic…  4371\n4 2 [duale o. schulische Berufsausbildung/einf.,mittl. Beamte] 2 [weiblic…  4926\n5 3 [Aufstiegsfortbildung (Meister, Techniker, kfm. AFB u.ä.)] 1 [männlic…  1073\n6 3 [Aufstiegsfortbildung (Meister, Techniker, kfm. AFB u.ä.)] 2 [weiblic…   652\n7 4 [Fachhochschule, Universität/ geh., höhere Beamte]         1 [männlic…  4015\n8 4 [Fachhochschule, Universität/ geh., höhere Beamte]         2 [weiblic…  3839\n\n\nAuch hier können wir wie oben die relativen und kumulierten relativen Häufigkeiten anfügen:\n\netb18 %>% \n  filter(!is.na(m1202)) %>% \n  count(m1202,S1) %>% \n  mutate(pct= prop.table(n)*100) \n\n# A tibble: 8 × 4\n  m1202                                                      S1          n   pct\n  <dbl+lbl>                                                  <dbl+l> <int> <dbl>\n1 1 [Ohne Berufsabschluss]                                   1 [män…   594  2.97\n2 1 [Ohne Berufsabschluss]                                   2 [wei…   497  2.49\n3 2 [duale o. schulische Berufsausbildung/einf.,mittl. Beam… 1 [män…  4371 21.9 \n4 2 [duale o. schulische Berufsausbildung/einf.,mittl. Beam… 2 [wei…  4926 24.7 \n5 3 [Aufstiegsfortbildung (Meister, Techniker, kfm. AFB u.ä… 1 [män…  1073  5.37\n6 3 [Aufstiegsfortbildung (Meister, Techniker, kfm. AFB u.ä… 2 [wei…   652  3.27\n7 4 [Fachhochschule, Universität/ geh., höhere Beamte]       1 [män…  4015 20.1 \n8 4 [Fachhochschule, Universität/ geh., höhere Beamte]       2 [wei…  3839 19.2 \n\n\nWas aber wenn wir jetzt die Anteile innerhalb von Männern und Frauen möchten? Hier hilft uns group_by() weiter:\n\netb18 %>% \n   filter(!is.na(m1202)) %>% \n   count(m1202,S1) %>% \n   group_by(S1) %>% \n   mutate(pct_gender = prop.table(n)) \n\n# A tibble: 8 × 4\n# Groups:   S1 [2]\n  m1202                                                    S1          n pct_g…¹\n  <dbl+lbl>                                                <dbl+l> <int>   <dbl>\n1 1 [Ohne Berufsabschluss]                                 1 [män…   594  0.0591\n2 1 [Ohne Berufsabschluss]                                 2 [wei…   497  0.0501\n3 2 [duale o. schulische Berufsausbildung/einf.,mittl. Be… 1 [män…  4371  0.435 \n4 2 [duale o. schulische Berufsausbildung/einf.,mittl. Be… 2 [wei…  4926  0.497 \n5 3 [Aufstiegsfortbildung (Meister, Techniker, kfm. AFB u… 1 [män…  1073  0.107 \n6 3 [Aufstiegsfortbildung (Meister, Techniker, kfm. AFB u… 2 [wei…   652  0.0658\n7 4 [Fachhochschule, Universität/ geh., höhere Beamte]     1 [män…  4015  0.399 \n8 4 [Fachhochschule, Universität/ geh., höhere Beamte]     2 [wei…  3839  0.387 \n# … with abbreviated variable name ¹​pct_gender\n\n\n49.7% der Befragten Frauen haben eine duale oder schule Berufsausbildung.\nWir können dann auch mit einem angehängten filter() nur die beiden Zeilen m1202 == 2 ausgeben lassen:\n\netb18 %>% \n  filter(!is.na(m1202)) %>% \n   count(m1202,S1) %>% \n   group_by(S1) %>% \n   mutate(pct_gender = prop.table(n)) %>% \n  filter(m1202 == 2)\n\n# A tibble: 2 × 4\n# Groups:   S1 [2]\n  m1202                                                    S1          n pct_g…¹\n  <dbl+lbl>                                                <dbl+l> <int>   <dbl>\n1 2 [duale o. schulische Berufsausbildung/einf.,mittl. Be… 1 [män…  4371   0.435\n2 2 [duale o. schulische Berufsausbildung/einf.,mittl. Be… 2 [wei…  4926   0.497\n# … with abbreviated variable name ¹​pct_gender\n\n\n…wir können diese Ausgaben natürlich immer auch ablegen:\n\ntab_aus_gender <- \n      etb18 %>% \n        filter(!is.na(m1202)) %>% \n         count(m1202,S1) %>% \n         group_by(S1) %>% \n         mutate(pct_gender = prop.table(n))\nclass(tab_aus_gender)\n\n[1] \"grouped_df\" \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n…und dann wieder weiterverwenden\n\ntab_aus_gender %>%  filter(m1202 == 3)\n\n# A tibble: 2 × 4\n# Groups:   S1 [2]\n  m1202                                                    S1          n pct_g…¹\n  <dbl+lbl>                                                <dbl+l> <int>   <dbl>\n1 3 [Aufstiegsfortbildung (Meister, Techniker, kfm. AFB u… 1 [män…  1073  0.107 \n2 3 [Aufstiegsfortbildung (Meister, Techniker, kfm. AFB u… 2 [wei…   652  0.0658\n# … with abbreviated variable name ¹​pct_gender\n\n\n\n3.6.1 Übung\n\n\n\n\n\n\nTip\n\n\n\nBei langen Tabellen werden nicht alle Werte ausgegeben, sondern nur die ersten Zeilen. Um hier alle Werte zu bekommen, hilft print(n=Inf):\n\netb18 %>% count(Bula,S1) # wird abgeschnitten\netb18 %>% count(Bula,S1) %>% print(n=Inf) # alle Werte werden gezeigt"
  },
  {
    "objectID": "03_desc.html#lage--konzentrationsmaße",
    "href": "03_desc.html#lage--konzentrationsmaße",
    "title": "3  Einen Überblick erhalten",
    "section": "3.7 Lage- & Konzentrationsmaße",
    "text": "3.7 Lage- & Konzentrationsmaße\nLagemaße sind statische Kennzahlen zur Beschreibung von metrischen Variablen, wie beispielsweise das arithmetische Mittel oder der Median. Einen Überblick bietet summary():\n\nsummary(etb18$F518_SUF)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      1    2200    3500   19811    6000   99999 \n\n\nAllerdings gibt es im Datensatz keine Befragten mit einem Bruttoverdienst von 99999 EUR. 99999 ist der Zahlencode keine Angabe , 99998 für weiß nicht. Um aussagekräftige Werte zu bekommen, müssen wir diese Werte mit NA überschreiben:\n\netb18$F518_SUF[etb18$F518_SUF %in% 99998:99999] <- NA # missings überschreiben\n\n\nsummary(etb18$F518_SUF)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n      1    2000    3000    3532    4200   72000    3377 \n\n\nWir können aber auch bestimmte Kennzahlen anfordern sehen uns die Bruttoverdienste der Befragten zu beschreiben:\n\nMinimum und Maximum: min(), max()\narithm. Mittel: mean()\nMedian: median()\nQuantile: quantile()\nVarianz: var()\nStandardabweichung: sd()\nGini-Koeffizient: Gini aus dem Paket {ineq}\n\nWenn eine Variable NA enthält, müssen diese explizit ignoriert werden - ansonsten wird nur NA ausgegeben:\n\nmean(etb18$F518_SUF)\n\n[1] NA\n\n\nDeshalb müssen wir die Option na.rm = T angeben:\n\nmean(etb18$F518_SUF,na.rm = T)\n\n[1] 3532.109\n\n\nEin Quantil einer Verteilung trennt die Daten so in zwei Teile, dass x% der Daten darunter und 100-x% darüber liegen. Mit quantile()wir durch Angabe in der Option probs = beliebige Quantilgrenzen anfordern, zB. für die 40%-Quantilgrenze:\n\nquantile(etb18$F518_SUF,probs = .4, na.rm = T)\n\n 40% \n2550 \n\n\nDen Gini-Koeffizienten können wir mit Gini() aus dem Paket ineq berechnen:\n\ninstall.packages(\"ineq\") # einmal installieren\n\n\nlibrary(ineq) # ineq laden\nGini(etb18$F518_SUF)\n\n[1] 0.3543509\n\n\n\n3.7.1 Kennzahlentabelle mit summarise\nMit Hilfe von summarise() aus {dplyr} können wir ein eigenes summary() bauen:\n\netb18 %>% summarise(Minimum = min(F518_SUF,na.rm = T),\n                    Median = median(F518_SUF,na.rm = T),\n                    Mittelwert = mean(F518_SUF,na.rm = T),\n                    Maximum = max(F518_SUF,na.rm = T),\n                    Gini = Gini(F518_SUF))\n\n# A tibble: 1 × 5\n  Minimum   Median Mittelwert Maximum    Gini\n  <dbl+lbl>  <dbl>      <dbl> <dbl+lbl> <dbl>\n1 1           3000      3532. 72000     0.354\n\n\nDer Vorteil des Ganzen wird im nächsten Schritt klarer.\n\n\n3.7.2 Lage- und Streuungsmaße vergleichen\nHäufig werden diese Kennzahlen erst im Vergleich richtig spannend, dafür hilft uns das group_by() Argument und summarise():\n\n\n\n\netb18 %>% \n  group_by(Bula) %>% \n  summarise(mean_inc = mean(F518_SUF, na.rm = T) )\n\n# A tibble: 16 × 2\n   Bula                        mean_inc\n   <dbl+lbl>                      <dbl>\n 1  1 [Schleswig-Holstein]        3495.\n 2  2 [Hamburg]                   3837.\n 3  3 [Niedersachsen]             3350.\n 4  4 [Bremen]                    3767.\n 5  5 [Nordrhein-Westfalen]       3673.\n 6  6 [Hessen]                    3860.\n 7  7 [Rheinland-Pfalz]           3859.\n 8  8 [Baden-Württemberg]         3691.\n 9  9 [Bayern]                    3634.\n10 10 [Saarland]                  3510.\n11 11 [Berlin]                    3528.\n12 12 [Brandenburg]               2960.\n13 13 [Mecklenburg-Vorpommern]    3034.\n14 14 [Sachsen]                   2897.\n15 15 [Sachsen-Anhalt]            2757.\n16 16 [Thüringen]                 2835.\n\netb18 %>% \n  group_by(Bula) %>% \n  summarise(mean_inc = mean(F518_SUF, na.rm = T),\n            median_inc = median(F518_SUF, na.rm = T))\n\n# A tibble: 16 × 3\n   Bula                        mean_inc median_inc\n   <dbl+lbl>                      <dbl>      <dbl>\n 1  1 [Schleswig-Holstein]        3495.       2900\n 2  2 [Hamburg]                   3837.       3100\n 3  3 [Niedersachsen]             3350.       3000\n 4  4 [Bremen]                    3767.       3300\n 5  5 [Nordrhein-Westfalen]       3673.       3200\n 6  6 [Hessen]                    3860.       3300\n 7  7 [Rheinland-Pfalz]           3859.       3000\n 8  8 [Baden-Württemberg]         3691.       3100\n 9  9 [Bayern]                    3634.       3000\n10 10 [Saarland]                  3510.       3000\n11 11 [Berlin]                    3528.       2900\n12 12 [Brandenburg]               2960.       2700\n13 13 [Mecklenburg-Vorpommern]    3034.       2600\n14 14 [Sachsen]                   2897.       2500\n15 15 [Sachsen-Anhalt]            2757.       2400\n16 16 [Thüringen]                 2835.       2500\n\netb18 %>% \n  filter(Bula %in% c(3,5)) %>% \n  group_by(Bula) %>% \n  summarise(mean_inc = mean(F518_SUF, na.rm = T) )\n\n# A tibble: 2 × 2\n  Bula                    mean_inc\n  <dbl+lbl>                  <dbl>\n1 3 [Niedersachsen]          3350.\n2 5 [Nordrhein-Westfalen]    3673.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.7.3 Übung"
  },
  {
    "objectID": "03_desc.html#übungen",
    "href": "03_desc.html#übungen",
    "title": "3  Einen Überblick erhalten",
    "section": "3.8 Übungen",
    "text": "3.8 Übungen\n\nAlle Übungen beziehen sich auf die Erwerbstätigenbefragung:\n\netb18 <- read_dta(\"./data/BIBBBAuA_2018_suf1.0.dta\")\n\nAbschnitt zum Einlesen\n\n3.8.1 Übung 1\nWir interessieren uns für die Variable gkpol, welche die Größe der Wohngemeinde der Befragten enthält:\n\n\n\n\n\n\n  \n  \n    \n      label\n      value\n    \n  \n  \n    unter 2.000 Einwohner\n1\n    2.000 bis unter 5.000 Einwohner\n2\n    5.000 bis unter 20.000 Einwohner\n3\n    20.000 bis unter 50.000 Einwohner\n4\n    50.000 bis unter 100.000 Einwohner\n5\n    100.000 bis unter 500.000 Einwohner\n6\n    500.000 und mehr Einwohner\n7\n  \n  \n  \n\n\n\n\n\nLassen Sie sich eine Tabelle mit den absoluten Häufigkeiten anzeigen, nutzen Sie dafür sowohl table(), xtabs() als auch count() (Denken Sie daran, {tidyverse} zu laden für count()).\nLassen Sie sich der relativen Häufigkeiten (Anteile) ausgeben (nutzen sie entweder table() oder xtabs())\nErstellen Sie eine Kontingenztabelle, indem Sie neben gkpol auch das Geschlecht S1 (2 = Frauen, 1 = Männer) mit einbeziehen\nWie viel Prozent der Befragten sind Frauen, die in einer Gemeinde mit unter 2000 Einwohnern leben? Berechnen Sie die relativen Häufigkeiten.\n\nZurück nach oben\n\n\n3.8.2 Übung 2\nWir interessieren uns für die Variable S3. Die Variable S3 erfasst den höchsten allgemeinen Schulabschluss der Befragten. Erstellen Sie mit Hilfe von count() eine Tabelle mit absoluten, relativen und kumulierten relativen Häufigkeiten.\n\nErstellen Sie zunächst eine Auszählung mit count() und fügen Sie dann die relativen und kumulierten relativen Häufigkeiten hinzu.\nProfi-Aufgabe: Ersetzen Sie ggf. Werte mit NA und lassen Sie sich die Tabelle erneut ausgeben. Siehe hier\n\nZurück nach oben\n\n\n3.8.3 Übung 3\n\nErstellen Sie eine vollständige Häufigkeitstabelle für die Variable gkpol und das Geschlecht (S1)\n\nVerwenden Sie die Befehle aus Übung 2- was müssen Sie anpassen, um die Tabelle für gkpol\nErweitern Sie jetzt die Auszählung um S1\nBerechnen Sie die Anteile von gkpol innerhalb von Männern und Frauen.\nWie viel Prozent der Frauen leben in einer Gemeinde mit unter 2000 Einwohnern?\n\nProfi-Aufgabe: Wie viel Prozent der Befragten, die in einer Gemeinde mit unter 2000 Einwohnern leben, sind Frauen? (S1 = 2, gkpol = 1)\n\n\nZurück nach oben\n\n\n3.8.4 Übung 4\nBeschreiben Sie das Alter der Befragten (zpalter) mit summary und erstellen Sie selbst einen Überblick mit Hilfe von summarise(), der einen Vergleich des Befragtenalters nach Gemeindegrößen erlaubt.\n\nÜberschreiben Sie zunächst die Missings mit NA:\n\n\netb18$zpalter[etb18$zpalter>100] <- NA\n\n\nErstellen Sie einen Überblick mit summary()\nErstellen Sie einen Überblick mit dem Minimum, Median, arith. Mittel, Varianz und Maximum der Alterswerte mit Hilfe von summarise()\nErweitern Sie diesen Überblick dann so, dass sie einen Vergleich der Kennzahlen für die verschieden gkpol-Kategorien ausgegeben bekommen.\n\nZurück nach oben"
  },
  {
    "objectID": "03_desc.html#hinweise",
    "href": "03_desc.html#hinweise",
    "title": "3  Einen Überblick erhalten",
    "section": "3.9 Hinweise",
    "text": "3.9 Hinweise\n\n3.9.1 Runden mit round()\nErläuterung: Sie können mit round(x , 3) Werte auf eine gewisse Zahl von Ziffern runden. Die zweite Zahl in der Klammer (nach dem Komma) gibt an, wieviele Dezimalstellen wir möchten:\n\nround(21.12121123,digits = 3)\n\n[1] 21.121\n\nround(21.12121123,digits = 5)\n\n[1] 21.12121\n\nround(21.12121123,digits = 0)\n\n[1] 21\n\n\nWir können also die relativen Häufigkeiten runden und so die Tabelle von oben übersichtlicher machen:\n\nxtabs(~S1+m1202, data = etb18) %>% \n  prop.table(.,margin = 1) %>% \n  round(.,3)\n\n   m1202\nS1      1     2     3     4\n  1 0.059 0.435 0.107 0.399\n  2 0.050 0.497 0.066 0.387\n\n\n\n\n3.9.2 Wie kann ich mir in R automatisch die häufigste/seltenste Ausprägung ausgeben lassen?\n\nt4 <- table(etb18$zpalter)\nt4[which(t4 == max(t4))] # Modus\n\n 54 \n790 \n\n\n54 ist mit 790 Befragten die häufigste Ausprägung.\n\n\n3.9.3 Gini-Koeffizient\nZur Beschreibung der Verteilung von Einkommens- und Vermögensdaten wird häufig der Gini-Koeffizient verwendet. Der Gini-Koeffizient beruht auf der Fläche zwischen der Lorenzkurve und der Gleichverteilung. Auf der x-Achse werden die kumulierten Perzentile der Befragten abgetragen, auf der y-Achse die Perzentile des HH-Einkommens:"
  },
  {
    "objectID": "04_viz.html",
    "href": "04_viz.html",
    "title": "4  Visualisierung mit {ggplot2}",
    "section": "",
    "text": "Neben Kennzahlen/Tabellen können/sollten Verteilungen auch visualisiert werden. Dafür bietet {ggplot2} eine riesige Auswahl an Möglichkeiten.\n{ggplot2} ist Teil des {tidyverse}, d.h. wir können entweder nur {ggplot2} oder die gesamte {tidyverse}-Sammlung laden:\nZunächst sehen wir uns den Weg zu einem Scatterplot an:\nDatengrundlage für unsere Graphik ist die ETB18 mit den Angaben zur Arbeitszeit sowie dem Geschlecht und Alter der Befragten:\nUm die Grafik nicht zu groß zu machen, verwenden wir nur die ersten 100 Beobachtungen:"
  },
  {
    "objectID": "04_viz.html#ggplot2-und-die-grammar-of-graphics",
    "href": "04_viz.html#ggplot2-und-die-grammar-of-graphics",
    "title": "4  Visualisierung mit {ggplot2}",
    "section": "4.1 ggplot2 und die grammar of graphics",
    "text": "4.1 ggplot2 und die grammar of graphics\nggplot2 ist die Umsetzung des Konzepts der “layered grammar of graphics” in R. Die Idee dieses Visualisierungssystems ist es, Datenvisualisierung in Parameter zu unterteilen: der zugrundeliegende Datensatz, die darzustellenden Variablen, die Wahl der darzustellenden Formen, das Koordinatensystem, Skalen und statistische Transformationen. Ein Standardbefehl in ggplot2 sieht ungefähr so aus:\n\nggplot(data = datensatz, aes(x = var1, y = var2, color = var3)) +\n  geom_point() +\n  labs(title= \"Titel\", subtitle = \"Untertitel\") +\n  theme_minimal()\n\nWir rufen also zunächst mit ggplot() eine Darstellung auf. In den weiteren Argumenten werden dann weitere Aspekte festgelegt:\n\nMit data = geben wir den data.frame an, den wir darstellen möchten\nDie Aesthetics aes() legen fest, welche Variablen dargestellt werden sollen: hier also var1 auf der x-Achse, var2 auf der y-Achse und var3 soll die Farbgebung festlegen\nDie Layers geom_.. geben die Art der Darstellung an, zB. geom_point() für Punkt- und geom_bar() für Säulendiagramme.\nMit labs können wir Beschriftungen angeben, zB. einen Titel vergeben oder die Achsenbeschriftungen anpassen\nDie Themes theme_... legen das Design der Graphik fest, zB. schwarz/weiße Achsen- und Hintergrundfarben mit theme_bw()\n\nWir arbeiten uns also jetzt durch die einzelnen layer/Schichten der Grafik:\n\n4.1.1 data =\nIn data = geben die den data.frame an, aus dem die darzustellenden Informationen kommen. Wir starten unseren ggplot also mit:\n\nggplot(data = etb18_small)\n\n\n\n\n\n\n\n\n\n\n4.1.2 aes\nDiese Werte wollen wir also in einem Scatterplot darstellen, sodass das Alter auf der x-Achse und auf der y-Achse die Wochenarbeitszeit abgetragen ist:\n\nggplot(data = etb18_small, aes(x = zpalter, y = az))\n\n\n\n\n\n\n\n\n\n\n4.1.3 geom\nWenn wir nur diese Angaben machen, bekommen wir lediglich ein leeres Koordinatensystem - warum? Weil wir noch nicht angegeben haben, welche Form der Darstellung wir gerne möchten. Dazu muss wir ein geom_ angeben, für Säulendiagramme ist das geom_col(), diese hängen wir an den ggplot-Befehl mit + an:\n\nggplot(data = etb18_small, aes(x = zpalter, y = az)) + geom_point()\n\n\n\n\n\n\n\n\nMit color = können wir den Punkten auch eine andere Farbe geben:\n\nggplot(data = etb18_small, aes(x = zpalter, y = az)) + geom_point(color = \"orange\")\n\n\n\n\n\n\n\n\n\n\n4.1.4 aes() Teil II\nDas sieht soweit schon ganz gut aus, allerdings werden die Punkte noch nicht getrennt nach Geschlecht dargestellt. Dazu müssen wir die Geschlechtsangabe (S1) in aes() angeben. Neben den Achsen werden in aes() nämlich auch die Variablen für das Aussehen der geom_s angeben - das kann neben der Farbe auch die Form, Größe oder Transparenz sein. Hier ein Überblick\nDas Geschlecht soll die Färbung der Punkte vorgeben, diese können wir in aes mit color angeben:\n\n# ergibt einen Fehler aufgrund der Labels:\nggplot(data = etb18_small, aes(x = zpalter, y = az, color = S1 )) + \n  geom_point()\n\nError in UseMethod(\"rescale\"): nicht anwendbare Methode für 'rescale' auf Objekt der Klasse \"c('haven_labelled', 'vctrs_vctr', 'double')\" angewendet\n\n\nEine numerische Variable für color = ergibt einen Farbverlauf, eine factor/character-Variable ergibt eine diskrete Farbskala:\n\nggplot(data = etb18_small, aes(x = zpalter, y = az, color = as.numeric(S1))) + \n  geom_point()\nggplot(data = etb18_small, aes(x = zpalter, y = az, color = as.factor(S1))) + \n  geom_point()\nggplot(data = etb18_small, aes(x = zpalter, y = az, color = as.character(S1))) + \n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAußerdem können wir mit scale_color_manual1 selbst Farben angeben, eine Liste möglicher Farben findet sich hier.\n\nggplot(data = etb18_small, aes(x = zpalter, y = az, color = as.factor(S1))) + \n  geom_point() + \n  scale_color_manual(values = c(\"lightskyblue4\",\"navy\"))\n\n\n\n\n\n\n\n\n\n\n4.1.5 Beschriftungen\nWir können mit den Optionen breaks und labels zudem auch die Beschriftung der Legende bearbeiten. Dazu geben wir zunächst in breaks die Ausprägungen der Variable Geschlecht an und dann in der gleichen Reihenfolge die zu vergebenden Labels:\n\nggplot(data = etb18_small, aes(x = zpalter, y = az, color = as.factor(S1))) + \n  geom_point() + \n  scale_color_manual(values = c(\"lightskyblue4\",\"navy\"),\n                    breaks = c(1,2), labels = c(\"Männer\", \"Frauen\") )\n\n\n\n\n\n\n\n\nAbschließend passen wir dann noch mit labs die Beschriftungen an, dabei haben wir folgende Optionen:\n\ntitle: Überschrift für die Graphik\nsubtitle: Unterzeile zur Überschrift\ncaption: Anmerkung unterhalb der Graphik\nx: x-Achsenbeschriftung\ny: y-Achsenbeschriftung\nfill: Beschriftung für die Legende, wenn fill in aes() angegeben wurde\ncolor: Beschriftung für die Legende, wenn color in aes() angegeben wurde\n\n\nggplot(data = etb18_small, aes(x = zpalter, y = az, color = as.factor(S1))) + \n  geom_point() + \n  scale_color_manual(values = c(\"lightskyblue4\",\"navy\"),\n                    breaks = c(1,2), labels = c(\"Männer\", \"Frauen\") ) +\n  labs(color = \"Geschlecht\", y = \"Arbeitszeit/Woche\",\n       x = \"Alter\",\n       title = \"Arbeitszeit und Alter\",\n       subtitle = \"Nach Geschlecht\",\n       caption = \"Quelle: ETB 2018\"\n       ) \n\n\n\n\n\n\n\n\nAußerdem können wir mit theme_ ein anderes Design auswählen, zB. mit theme_minimal() einen weißen Hintergrund mit grauen Markierungslinien (weitere Beispiele in den Hinweisen unter Themes)"
  },
  {
    "objectID": "04_viz.html#plots-als-objekte",
    "href": "04_viz.html#plots-als-objekte",
    "title": "4  Visualisierung mit {ggplot2}",
    "section": "4.3 Plots als Objekte",
    "text": "4.3 Plots als Objekte\nAußerdem kann ein ggplot auch ein Objekt sein:\n\np1 <- ggplot(data = etb18_small, aes(x = zpalter, y = az, color = factor(S1))) + \n  geom_point(size = 2) \n\np1 + scale_color_manual(values = c(\"lightskyblue3\",\"navy\"),\n                    breaks = c(1,2), labels = c(\"Männer\", \"Frauen\") ) \np1 + scale_color_manual(values = c(\"lightskyblue4\",\"orange\"),\n                    breaks = c(1,2), labels = c(\"Männer\", \"Frauen\") )"
  },
  {
    "objectID": "04_viz.html#kombination-aus-allem",
    "href": "04_viz.html#kombination-aus-allem",
    "title": "4  Visualisierung mit {ggplot2}",
    "section": "4.2 Kombination aus allem",
    "text": "4.2 Kombination aus allem\n\netb18_small$m1202[etb18_small$m1202<0] <- NA\nggplot(data = etb18_small, aes(x = zpalter, y = az, \n                               color = as.factor(S1),\n                               shape = as.factor(m1202))) + \n  geom_point(size = 2) + \n  scale_color_manual(values = c(\"lightskyblue3\",\"navy\"),\n                    breaks = c(1,2), labels = c(\"Männer\", \"Frauen\") ) +\n  scale_shape_manual(values = c(15:18),breaks = c(1:4), \n                     labels = c(\"ohne Aus\", \"duale Ausb.\",\"Aufstiegsfortb.\",\"FH/Uni\")) +\n  labs(color = \"Geschlecht\", \n       shape = \"Ausbildung\",\n       fill = \"Geschlecht\",\n       y = \"Arbeitszeit/Woche\",\n       x = \"Alter\",\n       title = \"Arbeitszeit und Alter\",\n       subtitle = \"Nach Geschlecht\",\n       caption = \"Quelle: ETB 2018\"\n       ) \n\n\n\n\n\n\n\n\nÜbersicht zu shapes"
  },
  {
    "objectID": "04_viz.html#ggsave",
    "href": "04_viz.html#ggsave",
    "title": "4  Visualisierung mit {ggplot2}",
    "section": "4.4 ggsave()",
    "text": "4.4 ggsave()\nUm eine Grafik dann zu speichern, steht uns ggsave() zur Verfügung. Wenn wir nichts anderes angeben, wird automatisch die gerade offene Grafik2 gespeichert. Besser ist es aber explizit zu sein:\n\nplot_objekt1 <- ggplot(data = etb18_small, aes(x = zpalter, y = az, \n                               color = factor(S1),\n                               shape = factor(m1202))) + \n  geom_point(size = 2) + \n  scale_color_manual(values = c(\"lightskyblue3\",\"navy\"),\n                    breaks = c(1,2), labels = c(\"Männer\", \"Frauen\") ) +\n  scale_shape_manual(values = c(15:18),breaks = c(1:4), \n                     labels = c(\"ohne Aus\", \"duale Ausb.\",\"Aufstiegsfortb.\",\"FH/Uni\")) +\n  labs(color = \"Geschlecht\",shape = \"Ausbildung\", fill = \"Geschlecht\",\n       y = \"Arbeitszeit/Woche\",x = \"Alter\",\n       title = \"Arbeitszeit und Alter\", subtitle = \"Nach Geschlecht\",caption = \"Quelle: ETB 2018\") \n\n\nggsave(plot = plot_objekt1,filename = \"./grafik/plot1.png\",\n       dpi = 800, # auflösung\n       # width = 9, height = 7, # falls angepasst werden soll\n       )\n\nDie richtige Kombination aus Auflösung, Textgröße und Gesamtgröße des Plots zu finden hat einige Fallstricke. Hier mehr dazu.\n\n4.4.1 Übung"
  },
  {
    "objectID": "04_viz.html#labels-übernehmen",
    "href": "04_viz.html#labels-übernehmen",
    "title": "4  Visualisierung mit {ggplot2}",
    "section": "4.5 Labels übernehmen",
    "text": "4.5 Labels übernehmen\nWenn(!) die labels und Variablenformate passen, dann hilft uns easy_labs() aus {ggeasy} weiter:\n\ninstall.packages(\"ggeasy\")\n\n\nlibrary(ggeasy)\netb18_small$S1 <- factor(etb18_small$S1)\nggplot(data = etb18_small, aes(x = zpalter, \n                               y = az)) + \n  geom_point(size = 2) + \n  easy_labs()"
  },
  {
    "objectID": "04_viz.html#verteilungen-visualisieren",
    "href": "04_viz.html#verteilungen-visualisieren",
    "title": "4  Visualisierung mit {ggplot2}",
    "section": "4.4 Verteilungen visualisieren",
    "text": "4.4 Verteilungen visualisieren\n\n4.4.1 Boxplot\nDefinition der Bestandteile eines Boxplots:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMit der folgenden Syntax können wir mit ggplot2 einen Boxplot erstellen. Da wir nur eine Variable betrachten, müssen wir lediglich y = oder x = angeben - je nachdem ob die Box vertikal oder horizontal orientiert sein soll.\n\nggplot(data = etb18_small, aes(y = az)) + geom_boxplot()\n\n\n\n\n\n\n\n\nSo können wir einen Boxplot erstellen, der die Werte für Männer und Frauen getrennt darstellt:\n\nggplot(data = etb18_small, aes(y = az, x = factor(S1))) + geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n4.4.2 Histogram\nEbenso können Verteilungen mit einem Histogramm beschrieben werden:\n\nggplot(data = etb18_small, aes(x = az)) + \n  geom_histogram()  \n\n\n\n\n\n\n\n\nWenn wir hier die Farbe ändern möchten, dann ist fill = anstelle von color = die richtige Option:\n\nggplot(data = etb18_small, aes(x = az)) + \n  geom_histogram(fill = \"sienna1\")  \n\n\n\n\n\n\n\n\nMöchten wir das Histogramm nach Geschlecht aufsplitten, können wir auch hier wieder fill als Aesthetic angeben. Mit position = position_dodge() können wir die Balken nebeneinander stellen lassen:\n\nggplot(data = etb18_small, aes(x = az, fill = factor(S1))) + \n  geom_histogram() \nggplot(data = etb18_small, aes(x = az, fill = factor(S1))) + \n  geom_histogram(position = position_dodge()) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAuch hier funktionieren natürlich wieder die scale_...manual Befehle, allerdings hier als scale_fill_manual anstelle scale_color_manual von oben:\n\nggplot(data = etb18_small, aes(x = az, fill = factor(S1))) + \n  geom_histogram(position = position_dodge()) +\n  scale_fill_manual(values = c(\"sienna1\",\"dodgerblue4\"),\n                    breaks = 1:2, labels = c(\"Männer\",\"Frauen\")) +\n  labs(fill = \"Geschlecht\")\nggplot(data = etb18, aes(x = az)) + \n  geom_histogram(aes(fill = factor(S1)), color = \"grey50\",position = position_dodge()) + \n  scale_fill_viridis_d(option = \"E\",labels = c(\"Männer\",\"Frauen\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWir können das ganze auch als Density-Plot darstellen geom_density(), hier empfiehlt es sich aber mit alpha = die Deckkraft herunterzusetzen:\n\nggplot(data = etb18, aes(x = az,fill = factor(S1))) + \n  geom_density(alpha = .5) + \n  scale_fill_manual(values = c(\"sienna1\",\"dodgerblue4\"),\n                    breaks = 1:2, labels = c(\"Männer\",\"Frauen\")) +\n  labs(fill = \"Geschlecht\") \n\n\n\n\n\n\n\n\n\n\n4.4.3 Übung"
  },
  {
    "objectID": "04_viz.html#kategoriale-merkmale",
    "href": "04_viz.html#kategoriale-merkmale",
    "title": "4  Visualisierung mit {ggplot2}",
    "section": "4.5 Kategoriale Merkmale",
    "text": "4.5 Kategoriale Merkmale\nIm Folgenden sehen wir uns eine Möglichkeit an, die Kontingenztabelle aus Kapitel 2 zu visualisieren:\n\netb18$m1202[etb18$m1202<0] <- NA # missings ausschließen\netb18 %>% \n  count(S1,m1202) %>% \n  filter(!is.na(m1202))\n\n# A tibble: 8 × 3\n  S1           m1202                                                           n\n  <dbl+lbl>    <dbl+lbl>                                                   <int>\n1 1 [männlich] 1 [Ohne Berufsabschluss]                                      594\n2 1 [männlich] 2 [duale o. schulische Berufsausbildung/einf.,mittl. Beamt…  4371\n3 1 [männlich] 3 [Aufstiegsfortbildung (Meister, Techniker, kfm. AFB u.ä.…  1073\n4 1 [männlich] 4 [Fachhochschule, Universität/ geh., höhere Beamte]         4015\n5 2 [weiblich] 1 [Ohne Berufsabschluss]                                      497\n6 2 [weiblich] 2 [duale o. schulische Berufsausbildung/einf.,mittl. Beamt…  4926\n7 2 [weiblich] 3 [Aufstiegsfortbildung (Meister, Techniker, kfm. AFB u.ä.…   652\n8 2 [weiblich] 4 [Fachhochschule, Universität/ geh., höhere Beamte]         3839\n\n\nDa wir mit count() einen data.frame erhalten, können wir diesen direkt in ggplot() schicken und mit geom_col() Säulen darstellen:\n\netb18 %>% \n  count(S1,m1202) %>% \n  filter(!is.na(m1202)) %>% \n  ggplot(data = ., aes(x = m1202, y = n, fill = factor(S1))) +\n  geom_col(position=position_dodge()) \n\n\n\n\n\n\n\n\nWie kommen wir jetzt an die relativen Häufigkeiten? Wir erweitern einfach die Pipeline vor ggplot() um den prop.table()-Befehl aus Kapitel 2. Mit scale_y_continuous(labels = scales::label_percent(accuracy = 1)) können wir außerdem die y-Achse in Prozentwerten angezeigen lassen:\n\netb18 %>% \n  filter(!is.na(m1202)) %>% \n  count(S1,m1202) %>% \n  group_by(S1) %>% \n  mutate(pct_gender = prop.table(n)) %>% \n  ggplot(data = ., aes(x = m1202, y = pct_gender, fill = factor(S1))) +\n  geom_col(position=position_dodge()) \netb18 %>% \n  filter(!is.na(m1202)) %>% \n  count(S1,m1202) %>% \n  group_by(S1) %>% \n  mutate(pct_gender = prop.table(n)) %>% \n  ggplot(data = ., aes(x = m1202, y = pct_gender, fill = factor(S1))) +\n  geom_col(position=position_dodge())  +\n  scale_y_continuous(labels = scales::label_percent(accuracy = 1)) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAuch diese Grafiken können wir dann wieder mit scale_... anpassen und mit labs() ausführlich labeln - alle Optionen sind konsistent über alle Darstellungsformen hinweg:\n\netb18 %>% \n  filter(!is.na(m1202)) %>% \n  count(S1,m1202) %>% \n  group_by(S1) %>% \n  mutate(pct_gender = prop.table(n)) %>% \n  ggplot(data = ., aes(x = m1202, y = pct_gender, fill = factor(S1))) +\n  geom_col(position=position_dodge())  +\n  scale_y_continuous(labels = scales::label_percent(accuracy = 1))  + \n  scale_fill_manual(values = c(\"navajowhite\",\"navy\"),\n                    breaks = c(1,2), labels = c(\"Männer\", \"Frauen\")) +\n  scale_x_continuous(breaks = 1:4 , labels = c(\"ohne Ausb.\", \"duale Ausb.\",\"Aufstiegsfortb.\",\"FH/Uni\")) +\n  scale_y_continuous(labels = scales::label_percent(accuracy = 1)) +\n  labs(title = \"Ausbildungsabschlüsse nach Geschlecht\",\n       subtitle = \"Relative Häufigkeiten\",\n       caption = \"Quelle: ETB 2018\",\n       x = \"Ausbildung\",\n       y = \"Relative Häufigkeit\",\n       fill = \"Geschlecht\" ) \n\n\n\n\n\n\n\n\n\n4.5.1 Übung"
  },
  {
    "objectID": "04_viz.html#übungen",
    "href": "04_viz.html#übungen",
    "title": "4  Visualisierung mit {ggplot2}",
    "section": "4.6 Übungen",
    "text": "4.6 Übungen\nNutzen Sie für alle Aufgaben die ersten 150 Beobachtungen (etb18_small), um den Plot einfach zu halten. Denken Sie daran die fehlenden Werte mit filter() auszuschließen, Sie können dazu diesen Befehl verwenden:\n\netb18 <-\n  haven::read_dta(\"./data/BIBBBAuA_2018_suf1.0.dta\",\n    col_select = c(\"h1216d\", \"S2_j\", \"S1\", \"m1202\", \"F518_SUF\", \"nt\", \"gkpol\")\n    )\netb18_small <-\n  etb18 %>% filter(S2_j < 9999, h1216d > 0, F518_SUF < 99998) %>% slice(1:150)\n\n\n4.6.1 Übung 1\n\nErstellen Sie einen Scatterplot für die Variablen Geburtsjahr (S2_j, x-Achse) und Dauer der Ausbildung (h1216d, y-Achse).\nLegen Sie die Farbe so fest, dass Männer und Frauen unterschiedliche Farben gekennzeichnet werden (S1)\nVerändern Sie die Farben auf goldenrod1 und dodgerblue4 fest (oder eine beliebige andere)\nBeschriften Sie die Achsen und Legende!\n\nZurück nach oben\n\n\n4.6.2 Übung 2\n\nErstellen Sie einen Boxplot für die Verteilung des Einkommens (F518_SUF).\nPassen Sie diesen Boxplot so an, dass die Einkommensverteilungen für Männer und Frauen getrennt dargestellt werden. (Profi-Knobelfrage: wie können Sie die Boxen nach S1 einfärben?)\nErstellen Sie ein Histogramm, ebenfalls für die Einkommensverteilung und mit getrennten Farben für Männer und Frauen.\nWas passiert wenn Sie für das Histogramm statt color = anstelle von fill = verwenden?\nVerändern Sie die Farben der Balken mit Hilfe von scale_fill_manual oder scale_fill_brewer oder scale_fill_viridis (Siehe Abschnitte Farben und ColorBreweR und viridis unter “weitere Optionen”)\nÄndern Sie die Darstellung in einen density-Plot\n\nZurück nach oben\n\n\n4.6.3 Übung 3\n\nErstellen Sie ein Säulen-Diagramm für die Größenklasse des Wohnorts der Befragten (gkpol)\nErstellen Sie ein Säulen-Diagramm für die Größenklasse des Wohnorts der Befragten (gkpol) getrennt nach der Variable nt - färben Sie die Säulen nach nt. Die Variable nt erfasst, ob die Befragten einer Nebentätigkeit nachgehen (1 = ja/ 0 = nein).\n\nKleine Hilfe: das sind die Labels für gkpol 1-7:\n\n\nc(\"<2k\", \"2k bis <5k\", \"5k bis <20k\", \"20k bis <50k\", \"50k bis <100k\", \n\"100k bis <500k\", \"500k und mehr\")\n\n\n\n\nCode\nscale_x_continuous(breaks = 1:7,\n                   labels = c(\"<2k\", \"2k bis <5k\", \"5k bis <20k\", \"20k bis <50k\", \n                              \"50k bis <100k\", \"100k bis <500k\", \"500k und mehr\"))\n\n\nZurück nach oben"
  },
  {
    "objectID": "04_viz.html#weitere-optionen-für-ggplot2",
    "href": "04_viz.html#weitere-optionen-für-ggplot2",
    "title": "4  Visualisierung mit {ggplot2}",
    "section": "4.7 Weitere Optionen für ggplot2",
    "text": "4.7 Weitere Optionen für ggplot2\n\n4.7.1 Aesthetics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.7.2 themes\nMit sog. themes können wir das layout der Grafik verändern. Weitere Themes sind zB: theme_light(), theme_classic() ider theme_void(), eine Liste findet sich hier. Außerdem bietet das Paket {ggthemes} (install.packages('ggthemes')) eine große Auswahl.\n\nggplot(data = etb18_small, aes(x = zpalter, y = az, color = factor(S1))) + \n  geom_point(size = 2) + \n  theme_minimal()\n\nggplot(data = etb18_small, aes(x = zpalter, y = az, color = factor(S1))) + \n  geom_point(size = 2) +\n  theme_dark()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.7.3 Farben\n\np1 <- ggplot(data = etb18_small, aes(x = zpalter, y = az, color = factor(S1))) + \n  geom_point(size = 3) \n\nNeben den im Beispiel verwendeten Farben für fill können natürlich auch noch unzählige weitere Farben in scale_fill_manual und scale_color_manual verwendet werden:\n\nHier findet sich eine Übersicht mit allen Farbnamen, die verstanden werden\nAlternativ können auch sog. HEX-Codes angeben werden, die bspw. mit dem Adobe Color Wheel oder Color Hex erstellt werden können.\n\n\np1 +  scale_color_manual(values = c(\"dodgerblue4\",\"sienna1\"),\n                    breaks = c(1,2), labels = c(\"Männer\", \"Frauen\") )\np1 +  scale_color_manual(values = c(\"#005b96\",\"#6497b1\"),\n                    breaks = c(1,2), labels = c(\"Männer\", \"Frauen\") )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.7.3.1 ColorBreweR\nAlternativ zur manuellen Auswahl der Farben mit scale_fill_manual und scale_color_manual können mit scale_fill_brewer() auch vorgegebene Farbpaletten des colorbrewer verwendet werden. Dazu muss lediglich scale_fill_brewer() anstelle von scale_fill_manual angeben werden und statt values eine der Paletten - eine Übersicht findet sich hier. Die Farbpaletten von ColorBreweR sind alle in ggplot2 integriert.\n\np1 +\n  scale_color_brewer(palette = \"RdYlBu\",\n                    breaks = c(1,2), labels = c(\"Männer\", \"Frauen\") ) \n\n\n\n\n\n\n\n\n\n\n4.7.3.2 viridis\nAnalog dazu gibt es auch die {viridis}-Paletten, welche durchgängig “colorblind-safe” und ebenfalls in {ggplot2} integriert sind. Allerdings ist hier zu beachten, dass für Farbauswahlen basierend auf einer kategorialen Variable scale_color_viridis_d() zu verwenden ist. Soll die Farbe entlang einer numerischen/metrischen Variable bestimmt werden, dann ist scale_color_viridis_c() zu verwenden. Außerdem kann mit begin und end die Breite der Farbskala angepasst werden:\n\np1 +\n  scale_color_viridis_d(option=\"magma\",\n                    breaks = c(1,2), labels = c(\"Männer\", \"Frauen\") ) \np1 +\n  scale_color_viridis_d(option=\"magma\",begin = .65,end = .85,\n                    breaks = c(1,2), labels = c(\"Männer\", \"Frauen\") ) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.7.3.3 Weitere Farbpaletten\nDarüber hinaus gibt es unzählige Pakete, die ebenfalls scale_color_ und scale_fill_-Funktionen bieten: Hier noch zwei Beispiele mit {scico} und {MetBrewer}, welches Farben aus Bildern im Metropolitan Museum of Art enthält:\n\ninstall.packages('scico')\ninstall.packages(\"MetBrewer\")\n\n{scico} Farbpaletten\n\n\n\n\n\n\n\n\n\n{MetBrewer} Farbpaletten\n\n\n\n\n\n\n\n\n\n\nlibrary(scico)\np1 +\n  scale_color_scico_d(palette = \"oslo\",begin = .5,end = .8,\n                    breaks = c(1,2), labels = c(\"Männer\", \"Frauen\") ) \nlibrary(MetBrewer)\np1 +\n  scale_color_met_d(name = \"Kandinsky\",\n                    breaks = c(1,2), labels = c(\"Männer\", \"Frauen\") ) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVergleichbare Pakete gibt es auch für\n\n{DutchMasters} - Farbpaletten aus Bildern niederländischer Maler\n{wesanderson} - Farbpaletten basierend auf verschiedenen Filmen von Wes Anderson (The Grand Budapest Hotel usw.)\n{ochRe} - Farbpaletten “inspired by Australian art, landscapes and wildlife”\n{paletteer} bietet eine riesige Auswahl verschiedenster Farbpaletten\n\n\n\n\n4.7.4 Shapes\n\n\n\n\n\n\n\n\n\nZusätzlicher Überblick\n\n\n4.7.5 Linetypes\n\n\n\n\n\n\n\n\n\nÜbersicht zu Shapes und Linetypes im R Cookbook"
  },
  {
    "objectID": "04_viz.html#linksammlung",
    "href": "04_viz.html#linksammlung",
    "title": "4  Visualisierung mit {ggplot2}",
    "section": "4.8 Linksammlung",
    "text": "4.8 Linksammlung\n\nFrom Data to Viz bietet einen Entscheidungsbaum für verschiedene Zusammenhänge und Deskriptionen mit Beispiel-Syntax\n\n\n\n\n\n\n\n\n\n\n\nSchriftgröße und -farbe anpassen: Hier findet sich eine gute Übersicht, wie die Schriftgröße und -farbe in {ggplot2} angepasst werden kann.\nDas Graph Kapitel des R Cookbooks ist eine hervorragende Quelle für alle möglichen Optionen und eine grundlegende Übersicht - bspw. zur Anpassung der Legende, Linien- und Punktvarianten oder den Achsen\nDie R Graph Gallery ist noch etwas umfangreicher und bietet noch weitere Visualisierungsideen\nFür alle, die mehr zu gelungenen (und schönen) Datenvisualisierungen mit {ggplot2} erfahren möchten, ist das Tutorial von Cédric Scherer ein hervorragender Einstieg. Dieser Workshop eignet sich sehr gut für eine Vertiefung.\nDieser Workshop bietet weitere Einblicke wie Datenvisualisierungen mit {ggplot2} schöner gestaltet werden können.\nEine Liste von Erweiterungen für ggplot2\nDas Buch zu {ggplot2}"
  },
  {
    "objectID": "05_data_wrangle1.html",
    "href": "05_data_wrangle1.html",
    "title": "5  Data Wrangling I: Labels",
    "section": "",
    "text": "library(tidyverse)\netb18_kap5 <- haven::read_dta(\"./data/BIBBBAuA_2018_suf1.0.dta\",\n                               col_select = c(\"intnr\", \"S1\", \"m1202\", \"Bula\",\"F411_01\")) %>% \n  filter(F411_01<9)"
  },
  {
    "objectID": "05_data_wrangle1.html#labels-aus-anderen-programmen-in-r",
    "href": "05_data_wrangle1.html#labels-aus-anderen-programmen-in-r",
    "title": "5  Data Wrangling I: Labels",
    "section": "5.1 Labels aus anderen Programmen in R",
    "text": "5.1 Labels aus anderen Programmen in R\nWenn wir bspw. die Ansicht mit View() öffnen oder eine Auszählung mit count() erstellen, werden uns labels angezeigt:\n\nView(etb18_kap5)\netb18_kap5 %>% count(S1)\n\nDiese sind als attributes() Variablen zugeordnet:\n\nattributes(etb18_kap5$S1)\n\n$label\n[1] \"Geschlecht\"\n\n$format.stata\n[1] \"%8.0g\"\n\n$labels\nmännlich weiblich \n       1        2 \n\n$class\n[1] \"haven_labelled\" \"vctrs_vctr\"     \"double\"        \n\n\n…leider machen die attributes() immer wieder Probleme:\n\nlibrary(ggplot2)\nlibrary(ggeasy)\n\netb18_kap5 %>% \n  count(S1) %>% \n  ggplot(.,aes(x=S1,y=n, fill = S1)) +\n  geom_col() + \n  easy_labs()\n\nDon't know how to automatically pick scale for object of type\n<haven_labelled/vctrs_vctr/double>. Defaulting to continuous.\nDon't know how to automatically pick scale for object of type\n<haven_labelled/vctrs_vctr/double>. Defaulting to continuous.\n\n\nError in UseMethod(\"rescale\"): nicht anwendbare Methode für 'rescale' auf Objekt der Klasse \"c('haven_labelled', 'vctrs_vctr', 'double')\" angewendet"
  },
  {
    "objectID": "05_data_wrangle1.html#factor-und-labels",
    "href": "05_data_wrangle1.html#factor-und-labels",
    "title": "5  Data Wrangling I: Labels",
    "section": "5.2 factor und Labels",
    "text": "5.2 factor und Labels\nR verfügt über einen speziellen Variablentypen namens factor, um mit kategorialen Daten umzugehen. factor Variablen sind besonders hilfreich, wenn wir Grafiken erstellen wollen oder statistische Analysen durchführen.\nIn den beiden vorherigen Kapiteln haben wir schon gesehen, dass Labels in R immer etwas extra Aufwand bedeuten. In Grafiken mussten wir mit breaks = c(1,2), labels = c(\"Männer\", \"Frauen\") die Labels extra erstellen. Auch in den Auszählungen waren die Labels nur mit count() aufrufbar.\nIn vielen Programmen wie Stata oder SPSS werden die labels häufig durch die Operationen “mitgeschleift” und dann ausgegeben. Das ist in R nicht der Fall. Stattdesssen können wir mit Hilfe des Variablentyps factor Labels vergeben. Das Vorgehen mag für alle, die schon lange mit Stata oder SPSS gearbeitet haben, etwas ungewöhnlich sein - ist aber in der Praxis sehr hilfreich, wenn man sich den entsprechenden Workflow angewöhnt hat.\nfactors stellen kategoriale Daten dar. Sie werden als Zahlen in Verbindung mit Bezeichnungen gespeichert und haben dazu eine festgelegte Ordnung. Einmal erstellt, können factors nur einen vordefinierten Satz von Werten enthalten, die als levels bezeichnet werden. Standardmäßig sortiert R die Ebenen immer in alphabetischer Reihenfolge.\nWir beginnen nochmal “ganz von vorne” und zwar mit einem data.frame aus count():\n\ntab_dat1 <- etb18_kap5 %>% count(m1202)\ntab_dat1\n\n# A tibble: 5 × 2\n  m1202                                                             n\n  <dbl+lbl>                                                     <int>\n1 -1 [keine Angabe]                                                44\n2  1 [Ohne Berufsabschluss]                                      1089\n3  2 [duale o. schulische Berufsausbildung/einf.,mittl. Beamte]  9294\n4  3 [Aufstiegsfortbildung (Meister, Techniker, kfm. AFB u.ä.)]  1725\n5  4 [Fachhochschule, Universität/ geh., höhere Beamte]          7851\n\n\nDabei soll educ die verschiedenen Ausbildungsniveaus entsprechend der Codierung von m1202 repräsentieren:\n\n\n\n\n \n  \n    value \n    label \n  \n \n\n  \n    1 \n    Ohne Berufsabschluss \n  \n  \n    2 \n    duale o. schulische Berufsausbildung/einf.,mittl. Beamte \n  \n  \n    3 \n    Aufstiegsfortbildung (Meister, Techniker, kfm. AFB u.ä.) \n  \n  \n    4 \n    Fachhochschule, Universität/ geh., höhere Beamte \n  \n\n\n\n\n\nWie können wir diese jetzt hinterlegen?\nSo könnten wir einfach eine educ_chr-Spalte hinzufügen:\n\ntab_dat1$m1202_chr <- c(\"k.A.\",\"ohne Abs.\", \"dual/schul.\", \"Aufstiegsfortb.\", \"FH/Uni\")\ntab_dat1\n\n# A tibble: 5 × 3\n  m1202                                                             n m1202_chr \n  <dbl+lbl>                                                     <int> <chr>     \n1 -1 [keine Angabe]                                                44 k.A.      \n2  1 [Ohne Berufsabschluss]                                      1089 ohne Abs. \n3  2 [duale o. schulische Berufsausbildung/einf.,mittl. Beamte]  9294 dual/schu…\n4  3 [Aufstiegsfortbildung (Meister, Techniker, kfm. AFB u.ä.)]  1725 Aufstiegs…\n5  4 [Fachhochschule, Universität/ geh., höhere Beamte]          7851 FH/Uni    \n\n\nMit factor() können wir levels und labels angeben - die labels werden dann der Reihenfolge nach den Zahlen aus levels zugewiesen. Außerdem wird aus allen nicht angegebenen levels automatisch NA:\n\ntab_dat1$m1202_fct <- factor(tab_dat1$m1202, \n                        levels = c(1,2,3,4), \n                        labels = c(\"ohne Abs.\", \"dual/schul.\", \"Aufstiegsfortb.\", \"FH/Uni\"))\ntab_dat1\n\n# A tibble: 5 × 4\n  m1202                                                        n m1202…¹ m1202…²\n  <dbl+lbl>                                                <int> <chr>   <fct>  \n1 -1 [keine Angabe]                                           44 k.A.    <NA>   \n2  1 [Ohne Berufsabschluss]                                 1089 ohne A… ohne A…\n3  2 [duale o. schulische Berufsausbildung/einf.,mittl. B…  9294 dual/s… dual/s…\n4  3 [Aufstiegsfortbildung (Meister, Techniker, kfm. AFB …  1725 Aufsti… Aufsti…\n5  4 [Fachhochschule, Universität/ geh., höhere Beamte]     7851 FH/Uni  FH/Uni \n# … with abbreviated variable names ¹​m1202_chr, ²​m1202_fct\n\n\nWarum ist das besser als einfach ein character? Weil eine Reihenfolge festgelegt wird:\n\nlevels(tab_dat1$m1202_fct)\n\n[1] \"ohne Abs.\"       \"dual/schul.\"     \"Aufstiegsfortb.\" \"FH/Uni\"         \n\n\nWenn wir dann tab_dat1 in einen ggplot pipen, dann werden die Werte der Reihenfolge der levels entsprechend auf der x-Achse sortiert:\n\n\n\n\ntab_dat1 %>% \n  ggplot(data = ., aes(x = m1202_chr, y = n)) +\n  geom_col(position=position_dodge(), fill = \"mediumturquoise\")\ntab_dat1 %>% \n  ggplot(data = ., aes(x = m1202_fct, y = n)) +\n  geom_col(position=position_dodge(), fill = \"steelblue4\") \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlogbeitrag zu labels in R"
  },
  {
    "objectID": "05_data_wrangle1.html#übung",
    "href": "05_data_wrangle1.html#übung",
    "title": "5  Data Wrangling I: Labels",
    "section": "5.3 Übung",
    "text": "5.3 Übung\n\netb18_ue5 <- haven::read_dta(\"./data/BIBBBAuA_2018_suf1.0.dta\",\n                               col_select = c(\"intnr\", \"S1\", \"m1202\", \"Bula\",\"F411_01\")) %>% \n  filter(F411_01<9)\n\nBearbeiten Sie die labels dieses Diagramms:\nF411_01: Wie häufig kommt es vor, dass Sie unter starkem Termin- oder Leistungsdruck arbeiten?\n\n\n\n\n \n  \n    value \n    label \n  \n \n\n  \n    1 \n    häufig \n  \n  \n    2 \n    manchmal \n  \n  \n    3 \n    selten \n  \n  \n    4 \n    nie \n  \n\n\n\n\n\n\n\nCode\netb18_ue5 %>% \n  count(F411_01) %>%\n  ggplot(data = ., aes(x = F411_01, y = n)) +\n  geom_col(fill = \"steelblue3\")\n\n\n\n\n\n\nErstellen Sie dafür zunächst einen data.frame mit der Auszählung durch count() und legen diese als Objekt ab.\nErstellen Sie einen factor() Variable mit den den gewünschten Beschriftungen mit Hilfe von labels =. (Sie können die Labels der Variable F411_01 mit attributes(etb18_kap5$F411_01)$labels nachsehen.)\nVerwenden Sie die gelabelten Variablen für die Grafik."
  },
  {
    "objectID": "05_data_wrangle1.html#anhang",
    "href": "05_data_wrangle1.html#anhang",
    "title": "5  Data Wrangling I: Labels",
    "section": "5.4 Anhang",
    "text": "5.4 Anhang\n\n5.4.1 Labels löschen mit zap_... aus {haven}\nHäufig führen die Label-attributes() zu Problemen in der weiteren Verarbeitung. Mit haven::zap_labels() können wir die Value labels aus einem Datensatz köschen mit haven::zap_label() können wir die Variable labels entfernen.\n\netb18_kap5\n\n# A tibble: 20,003 × 5\n   intnr Bula        S1           F411_01      m1202                            \n   <dbl> <dbl+lbl>   <dbl+lbl>    <dbl+lbl>    <dbl+lbl>                        \n 1   260 11 [Berlin] 1 [männlich] 1 [häufig]   4 [Fachhochschule, Universität/ …\n 2   361 11 [Berlin] 2 [weiblich] 2 [manchmal] 2 [duale o. schulische Berufsaus…\n 3   491 11 [Berlin] 1 [männlich] 2 [manchmal] 4 [Fachhochschule, Universität/ …\n 4   690 11 [Berlin] 2 [weiblich] 2 [manchmal] 4 [Fachhochschule, Universität/ …\n 5   919 11 [Berlin] 2 [weiblich] 2 [manchmal] 2 [duale o. schulische Berufsaus…\n 6  1041 11 [Berlin] 1 [männlich] 1 [häufig]   2 [duale o. schulische Berufsaus…\n 7  1077 11 [Berlin] 1 [männlich] 2 [manchmal] 4 [Fachhochschule, Universität/ …\n 8  1306 11 [Berlin] 2 [weiblich] 3 [selten]   2 [duale o. schulische Berufsaus…\n 9  1357 11 [Berlin] 2 [weiblich] 1 [häufig]   4 [Fachhochschule, Universität/ …\n10  1488 11 [Berlin] 2 [weiblich] 1 [häufig]   4 [Fachhochschule, Universität/ …\n# … with 19,993 more rows\n\netb18_kap5 %>% \n  haven::zap_labels() # value labels raus\n\n# A tibble: 20,003 × 5\n   intnr  Bula    S1 F411_01 m1202\n   <dbl> <dbl> <dbl>   <dbl> <dbl>\n 1   260    11     1       1     4\n 2   361    11     2       2     2\n 3   491    11     1       2     4\n 4   690    11     2       2     4\n 5   919    11     2       2     2\n 6  1041    11     1       1     2\n 7  1077    11     1       2     4\n 8  1306    11     2       3     2\n 9  1357    11     2       1     4\n10  1488    11     2       1     4\n# … with 19,993 more rows\n\n\n\n\n5.4.2 as_factor() in {haven}\nIn {haven} findet sich die Funktion as_factor1, mit der wir aus Labels einen factor erstellen können.\n\nlibrary(labelled)\ntab_dat2 <- etb18_kap5 %>% count(Bula)\ntab_dat2$Bula_fct <- as_factor(tab_dat2$Bula)\ntab_dat2\n\n# A tibble: 16 × 3\n   Bula                            n Bula_fct              \n   <dbl+lbl>                   <int> <fct>                 \n 1  1 [Schleswig-Holstein]       687 Schleswig-Holstein    \n 2  2 [Hamburg]                  553 Hamburg               \n 3  3 [Niedersachsen]           1863 Niedersachsen         \n 4  4 [Bremen]                   172 Bremen                \n 5  5 [Nordrhein-Westfalen]     3661 Nordrhein-Westfalen   \n 6  6 [Hessen]                  1404 Hessen                \n 7  7 [Rheinland-Pfalz]          851 Rheinland-Pfalz       \n 8  8 [Baden-Württemberg]       2402 Baden-Württemberg     \n 9  9 [Bayern]                  4049 Bayern                \n10 10 [Saarland]                 207 Saarland              \n11 11 [Berlin]                  1198 Berlin                \n12 12 [Brandenburg]              589 Brandenburg           \n13 13 [Mecklenburg-Vorpommern]   358 Mecklenburg-Vorpommern\n14 14 [Sachsen]                 1003 Sachsen               \n15 15 [Sachsen-Anhalt]           500 Sachsen-Anhalt        \n16 16 [Thüringen]                506 Thüringen             \n\n\nDas können wir dann in den Plot pipen: \n\ntab_dat2 %>% \n  ggplot(data = ., aes(y = Bula_fct, x = n)) +\n  geom_col(position=position_dodge(), fill = \"sienna1\")\n\n\n\n\n\n\n5.4.3 factor Variablen bearbeiten mit {forcats}\n{forcats} ist Teil des {tidyverse}. Mit fct_recode() können wir die levels verändern:\n\ntab_dat2$Bula_fct2 <- fct_recode(tab_dat2$Bula_fct,\n  NRW = \"Nordrhein-Westfalen\",\n  `M V` = \"Mecklenburg-Vorpommern\", # bei Leerzeichen `` um die Wörter\n  )\ntab_dat2 %>% print(n=Inf)\n\n# A tibble: 16 × 4\n   Bula                            n Bula_fct               Bula_fct2         \n   <dbl+lbl>                   <int> <fct>                  <fct>             \n 1  1 [Schleswig-Holstein]       687 Schleswig-Holstein     Schleswig-Holstein\n 2  2 [Hamburg]                  553 Hamburg                Hamburg           \n 3  3 [Niedersachsen]           1863 Niedersachsen          Niedersachsen     \n 4  4 [Bremen]                   172 Bremen                 Bremen            \n 5  5 [Nordrhein-Westfalen]     3661 Nordrhein-Westfalen    NRW               \n 6  6 [Hessen]                  1404 Hessen                 Hessen            \n 7  7 [Rheinland-Pfalz]          851 Rheinland-Pfalz        Rheinland-Pfalz   \n 8  8 [Baden-Württemberg]       2402 Baden-Württemberg      Baden-Württemberg \n 9  9 [Bayern]                  4049 Bayern                 Bayern            \n10 10 [Saarland]                 207 Saarland               Saarland          \n11 11 [Berlin]                  1198 Berlin                 Berlin            \n12 12 [Brandenburg]              589 Brandenburg            Brandenburg       \n13 13 [Mecklenburg-Vorpommern]   358 Mecklenburg-Vorpommern M V               \n14 14 [Sachsen]                 1003 Sachsen                Sachsen           \n15 15 [Sachsen-Anhalt]           500 Sachsen-Anhalt         Sachsen-Anhalt    \n16 16 [Thüringen]                506 Thüringen              Thüringen         \n\n\nWeitere fct_....() Funktionen aus {forcats}, einen Überblick gibt das Cheatsheet.\nEine sehr praktische Funktion ist fct_reorder(), mit dieser können wir die levels nach Häufigkeit (aus tab_dat1$n) sortieren:\n\ntab_dat2$Bula_fct3 <- fct_reorder(tab_dat2$Bula_fct2,tab_dat2$n)\nlevels(tab_dat2$Bula_fct2)\n\n [1] \"Schleswig-Holstein\" \"Hamburg\"            \"Niedersachsen\"     \n [4] \"Bremen\"             \"NRW\"                \"Hessen\"            \n [7] \"Rheinland-Pfalz\"    \"Baden-Württemberg\"  \"Bayern\"            \n[10] \"Saarland\"           \"Berlin\"             \"Brandenburg\"       \n[13] \"M V\"                \"Sachsen\"            \"Sachsen-Anhalt\"    \n[16] \"Thüringen\"         \n\nlevels(tab_dat2$Bula_fct3)\n\n [1] \"Bremen\"             \"Saarland\"           \"M V\"               \n [4] \"Sachsen-Anhalt\"     \"Thüringen\"          \"Hamburg\"           \n [7] \"Brandenburg\"        \"Schleswig-Holstein\" \"Rheinland-Pfalz\"   \n[10] \"Sachsen\"            \"Berlin\"             \"Hessen\"            \n[13] \"Niedersachsen\"      \"Baden-Württemberg\"  \"NRW\"               \n[16] \"Bayern\"            \n\n\n\n\n\n\ntab_dat2 %>% \n  ggplot(data = ., aes(y = Bula_fct2, x = n)) +\n  geom_col(position=position_dodge(), fill = \"turquoise2\")\ntab_dat2 %>% \n  ggplot(data = ., aes(y = Bula_fct3, x = n)) +\n  geom_col(position=position_dodge(), fill = \"turquoise3\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.4.4 Labels selbst erstellen und ranspielen\nEin alternativer Weg geht über einen kleinen Label-data.frame und left_join() (mehr zu left_join() später.)\n\ntab_ausb2 <- etb18_kap5 %>% count(m1202)\ntab_ausb2\n\n# A tibble: 5 × 2\n  m1202                                                             n\n  <dbl+lbl>                                                     <int>\n1 -1 [keine Angabe]                                                44\n2  1 [Ohne Berufsabschluss]                                      1089\n3  2 [duale o. schulische Berufsausbildung/einf.,mittl. Beamte]  9294\n4  3 [Aufstiegsfortbildung (Meister, Techniker, kfm. AFB u.ä.)]  1725\n5  4 [Fachhochschule, Universität/ geh., höhere Beamte]          7851\n\n\n\nlab_df <- data.frame(m1202=1:4)\nlab_df\n\n  m1202\n1     1\n2     2\n3     3\n4     4\n\nlab_df$m1202_lab <- factor(lab_df$m1202,levels = 1:4,\n                           labels = c(\"ohne Abs.\", \"dual/schul.\", \"Aufstiegsfortb.\", \"FH/Uni\"))\nlab_df\n\n  m1202       m1202_lab\n1     1       ohne Abs.\n2     2     dual/schul.\n3     3 Aufstiegsfortb.\n4     4          FH/Uni\n\n\n\ntab_ausb2 %>% \n  left_join(lab_df,by = \"m1202\")\n\n# A tibble: 5 × 3\n  m1202                                                             n m1202_lab \n  <dbl+lbl>                                                     <int> <fct>     \n1 -1 [keine Angabe]                                                44 <NA>      \n2  1 [Ohne Berufsabschluss]                                      1089 ohne Abs. \n3  2 [duale o. schulische Berufsausbildung/einf.,mittl. Beamte]  9294 dual/schu…\n4  3 [Aufstiegsfortbildung (Meister, Techniker, kfm. AFB u.ä.)]  1725 Aufstiegs…\n5  4 [Fachhochschule, Universität/ geh., höhere Beamte]          7851 FH/Uni    \n\n\n\ntab_ausb2 %>% \n  left_join(lab_df,by = \"m1202\") %>% \n  ggplot(data = ., aes(x = m1202_lab, y = n)) +\n  geom_col(position=position_dodge(), fill = \"turquoise3\")\n\n\n\n\n\n\n5.4.5 Labels in R erstellen und nach bspw. Stata exportieren\nWenn wir aber beispielsweise einen Datensatz für Stata labeln wollen, hilft uns wieder {labelled}:\n\nlibrary(labelled)\n\n\netb18_kap5$S1_num2 <- as.numeric(etb18_kap5$S1)\nattributes(etb18_kap5$S1_num2)\n\nNULL\n\nval_labels(etb18_kap5$S1_num2) <- c(\"Mann\"=1,\"Frau\"=2)\nattributes(etb18_kap5$S1_num2)\n\n$labels\nMann Frau \n   1    2 \n\n$class\n[1] \"haven_labelled\" \"vctrs_vctr\"     \"double\"        \n\netb18_kap5 %>% count(S1_num2)\n\n# A tibble: 2 × 2\n  S1_num2       n\n  <dbl+lbl> <int>\n1 1 [Mann]  10068\n2 2 [Frau]   9935\n\n\n\netb18_kap5 %>% \n  select(S1_num2) %>% \n  haven::write_dta(.,path = \"./data/etb18_kap5.dta\")\n\n…in Stata:\n\nuse \"./data/etb18_kap5.dta\" \ntab S1_num2\n\n    S1_num2 |      Freq.     Percent        Cum.\n------------+-----------------------------------\n       Mann |     10,068       50.33       50.33\n       Frau |      9,935       49.67      100.00\n------------+-----------------------------------\n      Total |     20,003      100.00\n\n\nMehr zu labels in {labelled}."
  },
  {
    "objectID": "06_data_wrangle2.html",
    "href": "06_data_wrangle2.html",
    "title": "6  Data Wrangling II",
    "section": "",
    "text": "library(tidyverse)\nWir gehen nochmal zurück zum Uni-Datensatz vom Anfang:\nMit bind_rows() aus {dplyr} können wir die beiden data.frames zusammensetzen:\nEs gibt auch bind_cols() um Datensätze spaltenweise zusammenzufügen. Möglichkeiten, Datensätzen auf Basis einer oder mehrer Identifikationsvariablen zu “mergen” lernen wir auch noch später kennen."
  },
  {
    "objectID": "06_data_wrangle2.html#var",
    "href": "06_data_wrangle2.html#var",
    "title": "6  Data Wrangling II",
    "section": "6.1 Variablen erstellen",
    "text": "6.1 Variablen erstellen\nNun sehen wir uns die Möglichkeiten, Variablen zu erstellen, nochmal etwas genauer an. Grundsätzlich gibt es zwei Arten, Variablen in einen data.frame hinzuzufügen:\n\n6.1.1 base R: ...$newvar <-\n\ndat3$studs_to_mean  <- dat3$studs - mean(dat3$studs)\ndat3\n\n  studs profs gegr prom_recht                uni studs_to_mean\n1 19173   322 1971       TRUE         Uni Bremen     -2517.625\n2  5333    67 1830       TRUE         Uni Vechta    -16357.625\n3 15643   210 1973       TRUE      Uni Oldenburg     -6047.625\n4 14954   250 1971      FALSE          FH Aachen     -6736.625\n5 47269   553 1870       TRUE        RWTH Aachen     25578.375\n6 23659   438 1457       TRUE       Uni Freiburg      1968.375\n7  9415   150 1818       TRUE           Uni Bonn    -12275.625\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg     16388.375\n\n\nMit <- NULL können Variablen auch gelöscht werden:\n\ndat3$studs_to_mean  <-  NULL\ndat3\n\n  studs profs gegr prom_recht                uni\n1 19173   322 1971       TRUE         Uni Bremen\n2  5333    67 1830       TRUE         Uni Vechta\n3 15643   210 1973       TRUE      Uni Oldenburg\n4 14954   250 1971      FALSE          FH Aachen\n5 47269   553 1870       TRUE        RWTH Aachen\n6 23659   438 1457       TRUE       Uni Freiburg\n7  9415   150 1818       TRUE           Uni Bonn\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg\n\n\n\n\n6.1.2 {dplyr}: mutate(neue_var= )\nWir hatten die Variante aus {dplyr} ({tidyverse}) bereits in Kapitel 3 kurz kennen gelernt. Die grundsätzliche Struktur ist immer datensatz %>% mutate(neue_var = ....):\n\ndat3 %>% mutate(studs_to_mean = studs-mean(studs))\n\n  studs profs gegr prom_recht                uni studs_to_mean\n1 19173   322 1971       TRUE         Uni Bremen     -2517.625\n2  5333    67 1830       TRUE         Uni Vechta    -16357.625\n3 15643   210 1973       TRUE      Uni Oldenburg     -6047.625\n4 14954   250 1971      FALSE          FH Aachen     -6736.625\n5 47269   553 1870       TRUE        RWTH Aachen     25578.375\n6 23659   438 1457       TRUE       Uni Freiburg      1968.375\n7  9415   150 1818       TRUE           Uni Bonn    -12275.625\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg     16388.375\n\n\nWir können auch mehrere Variablen innerhalb eines mutate()-Befehls erstellen:\n\ndat3 %>% mutate(studs_to_mean = studs-mean(studs),\n                profs_to_mean = profs-mean(profs))\n\n  studs profs gegr prom_recht                uni studs_to_mean profs_to_mean\n1 19173   322 1971       TRUE         Uni Bremen     -2517.625         -6.25\n2  5333    67 1830       TRUE         Uni Vechta    -16357.625       -261.25\n3 15643   210 1973       TRUE      Uni Oldenburg     -6047.625       -118.25\n4 14954   250 1971      FALSE          FH Aachen     -6736.625        -78.25\n5 47269   553 1870       TRUE        RWTH Aachen     25578.375        224.75\n6 23659   438 1457       TRUE       Uni Freiburg      1968.375        109.75\n7  9415   150 1818       TRUE           Uni Bonn    -12275.625       -178.25\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg     16388.375        307.75\n\n\nOder Variablen können innerhalb von mutate() weiterverwendet werden:\n\ndat3 %>% mutate(rel_to_mean = studs-mean(studs),\n                above_mean = rel_to_mean > 0)\n\n  studs profs gegr prom_recht                uni rel_to_mean above_mean\n1 19173   322 1971       TRUE         Uni Bremen   -2517.625      FALSE\n2  5333    67 1830       TRUE         Uni Vechta  -16357.625      FALSE\n3 15643   210 1973       TRUE      Uni Oldenburg   -6047.625      FALSE\n4 14954   250 1971      FALSE          FH Aachen   -6736.625      FALSE\n5 47269   553 1870       TRUE        RWTH Aachen   25578.375       TRUE\n6 23659   438 1457       TRUE       Uni Freiburg    1968.375       TRUE\n7  9415   150 1818       TRUE           Uni Bonn  -12275.625      FALSE\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg   16388.375       TRUE\n\n\nDer Ausgangsdatensatz bleibt aber unverändert:\n\ndat3\n\n  studs profs gegr prom_recht                uni\n1 19173   322 1971       TRUE         Uni Bremen\n2  5333    67 1830       TRUE         Uni Vechta\n3 15643   210 1973       TRUE      Uni Oldenburg\n4 14954   250 1971      FALSE          FH Aachen\n5 47269   553 1870       TRUE        RWTH Aachen\n6 23659   438 1457       TRUE       Uni Freiburg\n7  9415   150 1818       TRUE           Uni Bonn\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg\n\n\nWenn wir die Ergebnisse behalten wollen, müssen wir das Ergebnis in einem Objekt ablegen:\n\ndat4 <-\n  dat3 %>% \n  mutate(rel_to_mean = studs-mean(studs),\n         above_mean = rel_to_mean > 0)\n\ndat4\n\n  studs profs gegr prom_recht                uni rel_to_mean above_mean\n1 19173   322 1971       TRUE         Uni Bremen   -2517.625      FALSE\n2  5333    67 1830       TRUE         Uni Vechta  -16357.625      FALSE\n3 15643   210 1973       TRUE      Uni Oldenburg   -6047.625      FALSE\n4 14954   250 1971      FALSE          FH Aachen   -6736.625      FALSE\n5 47269   553 1870       TRUE        RWTH Aachen   25578.375       TRUE\n6 23659   438 1457       TRUE       Uni Freiburg    1968.375       TRUE\n7  9415   150 1818       TRUE           Uni Bonn  -12275.625      FALSE\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg   16388.375       TRUE\n\n\n\n\n\n\n\n\nDummy-Variablen erstellen mit as.numeric()\n\n\n\nWenn wir logische Variablen mit as.numeric() in numerische Variablen umformatieren erhalten wir eine Dummy-Codierung:\n\ndat4$above_mean \n\n[1] FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE  TRUE\n\nas.numeric(dat4$above_mean )\n\n[1] 0 0 0 0 1 1 0 1\n\ndat3 %>% \n  mutate(rel_to_mean = studs-mean(studs),\n         above_mean = as.numeric(rel_to_mean > 0) )\n\n  studs profs gegr prom_recht                uni rel_to_mean above_mean\n1 19173   322 1971       TRUE         Uni Bremen   -2517.625          0\n2  5333    67 1830       TRUE         Uni Vechta  -16357.625          0\n3 15643   210 1973       TRUE      Uni Oldenburg   -6047.625          0\n4 14954   250 1971      FALSE          FH Aachen   -6736.625          0\n5 47269   553 1870       TRUE        RWTH Aachen   25578.375          1\n6 23659   438 1457       TRUE       Uni Freiburg    1968.375          1\n7  9415   150 1818       TRUE           Uni Bonn  -12275.625          0\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg   16388.375          1\n\n\n\n\n\n\n6.1.3 Übung"
  },
  {
    "objectID": "06_data_wrangle2.html#group_by",
    "href": "06_data_wrangle2.html#group_by",
    "title": "6  Data Wrangling II",
    "section": "6.2 Gruppierung mit group_by() & .by=",
    "text": "6.2 Gruppierung mit group_by() & .by=\nDie wirkliche Stärke von mutate() kommt aber erst zum Tragen, wenn wir es mit weiteren {dplyr}-Funktionen kombinieren. Eine häufige Aufgabe in der Datenaufbereitung sind gruppierte Werte.\nWir machen unseren Beispieldatensatz noch etwas kleiner:\n\ndat5 <- dat3 %>% \n  select(-uni,-gegr) # nur dass alles zu sehen ist\n\nWenn wir einen Datensatz mit group_by() entlang den Werten einer Variablen gruppieren, dann werden alle weiteren mutate() Berechnungen nur innerhalb dieser Gruppen ausgeführt:\n\ndat5 %>%\n  mutate(m_studs = mean(studs),\n         m_profs = mean(profs)) %>% \n  group_by(prom_recht) %>%\n  mutate(m_studs2 = mean(studs),\n         m_profs2 = mean(profs))\n\n# A tibble: 8 × 7\n# Groups:   prom_recht [2]\n  studs profs prom_recht m_studs m_profs m_studs2 m_profs2\n  <dbl> <dbl> <lgl>        <dbl>   <dbl>    <dbl>    <dbl>\n1 19173   322 TRUE        21691.    328.   20082       290\n2  5333    67 TRUE        21691.    328.   20082       290\n3 15643   210 TRUE        21691.    328.   20082       290\n4 14954   250 FALSE       21691.    328.   26516.      443\n5 47269   553 TRUE        21691.    328.   20082       290\n6 23659   438 TRUE        21691.    328.   20082       290\n7  9415   150 TRUE        21691.    328.   20082       290\n8 38079   636 FALSE       21691.    328.   26516.      443\n\n\nVerwenden wir group_by(), können (sollten!) wir mit ungroup() die Gruppierung wieder aufheben, sobald wir sie nicht mehr benötigen:\n\ndat5 %>%\n  mutate(m_studs = mean(studs),\n         m_profs = mean(profs)) %>% \n  group_by(prom_recht) %>%\n  mutate(m_studs2 = mean(studs)) %>% \n  ungroup() %>% \n  mutate(m_profs2 = mean(profs))\n\n\n\n  studs profs prom_recht  m_studs m_profs m_studs2 m_profs2\n1 19173   322       TRUE 21690.62  328.25  20082.0   328.25\n2  5333    67       TRUE 21690.62  328.25  20082.0   328.25\n3 15643   210       TRUE 21690.62  328.25  20082.0   328.25\n4 14954   250      FALSE 21690.62  328.25  26516.5   328.25\n5 47269   553       TRUE 21690.62  328.25  20082.0   328.25\n6 23659   438       TRUE 21690.62  328.25  20082.0   328.25\n7  9415   150       TRUE 21690.62  328.25  20082.0   328.25\n8 38079   636      FALSE 21690.62  328.25  26516.5   328.25\n\n\nSeit {dplyr}-Version 1.1.1 können wir direkt in mutate() mit dem Argument .by= eine Gruppierung angeben. Diese Gruppierung .by= gilt dabei nur für die unmittelbaren Berechnungen innerhalb mutate() - wir sparen uns das ungroup().\n\ndat5 %>%\n  mutate(m_studs = mean(studs),\n         m_profs = mean(profs)) %>% \n  mutate(m_studs2 = mean(studs),\n         .by = prom_recht) %>% \n  mutate(m_profs2 = mean(profs))\n\n  studs profs prom_recht  m_studs m_profs m_studs2 m_profs2\n1 19173   322       TRUE 21690.62  328.25  20082.0   328.25\n2  5333    67       TRUE 21690.62  328.25  20082.0   328.25\n3 15643   210       TRUE 21690.62  328.25  20082.0   328.25\n4 14954   250      FALSE 21690.62  328.25  26516.5   328.25\n5 47269   553       TRUE 21690.62  328.25  20082.0   328.25\n6 23659   438       TRUE 21690.62  328.25  20082.0   328.25\n7  9415   150       TRUE 21690.62  328.25  20082.0   328.25\n8 38079   636      FALSE 21690.62  328.25  26516.5   328.25\n\n\nMit summarise() statt mutate() erhalten wir eine Übersicht:\n\ndat5 %>%\n  summarise(m_studs = mean(studs),.by = prom_recht)\n\n  prom_recht m_studs\n1       TRUE 20082.0\n2      FALSE 26516.5\n\n\n\n6.2.1 Übung"
  },
  {
    "objectID": "06_data_wrangle2.html#across",
    "href": "06_data_wrangle2.html#across",
    "title": "6  Data Wrangling II",
    "section": "6.3 across(): Mehrere Variablen bearbeiten",
    "text": "6.3 across(): Mehrere Variablen bearbeiten\nEine sehr vielseitige Erweiterung für mutate() und summarise() ist across(). Hier mit können wir eine Funktion auf mehrere Spalten gleichzeitig anwenden, ohne uns zu wiederholen:\n\ndat3 %>%\n  summarise(studs = mean(studs),\n            profs = mean(profs))\n\n     studs  profs\n1 21690.62 328.25\n\n\nHier ist across() deutlich kürzer - für die Variablenauswahl können wir die ?select_helpers verwenden - z.B. matches():\n\ndat3 %>%\n  summarise(across(.cols = matches(\"studs|profs\"),.fns = ~mean(.x)))\n\n     studs  profs\n1 21690.62 328.25\n\n\nNatürlich ist das auch kombinierbar mit group_by():\n\ndat3 %>%\n  group_by(prom_recht) %>%\n  summarise(across(matches(\"studs|profs\"), ~mean(.x)))\n\n# A tibble: 2 × 3\n  prom_recht  studs profs\n  <lgl>       <dbl> <dbl>\n1 FALSE      26516.   443\n2 TRUE       20082    290\n\n\nWir können auch mehrere Funktionen durchführen, dafür müssen wir sie in einer list() angeben:\n\ndat3 %>%\n  group_by(prom_recht) %>%\n  summarise(across(matches(\"studs|profs\"), list(mean = ~mean(.x), sd = ~sd(.x))))\n\n# A tibble: 2 × 5\n  prom_recht studs_mean studs_sd profs_mean profs_sd\n  <lgl>           <dbl>    <dbl>      <dbl>    <dbl>\n1 FALSE          26516.   16352.        443     273.\n2 TRUE           20082    14858.        290     183.\n\n\nDiese list()auch vorab ablegen und dann verwenden:\n\nwert_liste <- list(mean = ~mean(.x), sd = ~sd(.x), max = ~max(.x,na.rm = T))\n\ndat3 %>%\n  group_by(prom_recht) %>%\n  summarise(across(matches(\"studs|profs\"), wert_liste))\n\n# A tibble: 2 × 7\n  prom_recht studs_mean studs_sd studs_max profs_mean profs_sd profs_max\n  <lgl>           <dbl>    <dbl>     <dbl>      <dbl>    <dbl>     <dbl>\n1 FALSE          26516.   16352.     38079        443     273.       636\n2 TRUE           20082    14858.     47269        290     183.       553\n\n\nMit dem .names()-Argument können wir auch die Benennung der Spalten steuern. {.fn} steht dabei als Platzhalter für die angewendete Funktion, {.col} für den Namen der bearbeiteten Variable.\n\ndat3 %>%\n  group_by(prom_recht) %>%\n  summarise(across(matches(\"studs|profs\"), \n                   list(mean = ~mean(.x), sd = ~sd(.x)),\n                   .names = \"{.fn}_{.col}\"))\n\n# A tibble: 2 × 5\n  prom_recht mean_studs sd_studs mean_profs sd_profs\n  <lgl>           <dbl>    <dbl>      <dbl>    <dbl>\n1 FALSE          26516.   16352.        443     273.\n2 TRUE           20082    14858.        290     183.\n\n\n…eine sehr praktische Hilfsfunktion aus {dplyr} ist n() - so erhalten wir die Fallzahlen. Allerdings werden so auch ggf. Zeilen mit NA mitgezählt, sodass wir für die Zähler alle nicht-NA Zeilen eine anderen Lösung brauchen, bspw. sum(!is.na(.x)) - also die Summe der “is not NA”==TRUE:\n\ndat3 %>%\n  group_by(prom_recht) %>%\n  summarise(across(matches(\"studs|profs\"), \n                   list(mean = ~mean(.x), sd = ~sd(.x), n = ~n(), notNA = ~sum(!is.na(.x))),\n                   .names = \"{.fn}_{.col}\"))\n\n# A tibble: 2 × 9\n  prom_recht mean_studs sd_studs n_studs notNA…¹ mean_…² sd_pr…³ n_profs notNA…⁴\n  <lgl>           <dbl>    <dbl>   <int>   <int>   <dbl>   <dbl>   <int>   <int>\n1 FALSE          26516.   16352.       2       2     443    273.       2       2\n2 TRUE           20082    14858.       6       6     290    183.       6       6\n# … with abbreviated variable names ¹​notNA_studs, ²​mean_profs, ³​sd_profs,\n#   ⁴​notNA_profs\n\n\nAlle gezeigten Funktionen funktionieren natürlich auch mit mutate():\n\ndat3 %>%\n  mutate(across(matches(\"studs|profs\"), ~mean(.x), .names = \"m_{.col}\"))\n\n  studs profs gegr prom_recht                uni  m_studs m_profs\n1 19173   322 1971       TRUE         Uni Bremen 21690.62  328.25\n2  5333    67 1830       TRUE         Uni Vechta 21690.62  328.25\n3 15643   210 1973       TRUE      Uni Oldenburg 21690.62  328.25\n4 14954   250 1971      FALSE          FH Aachen 21690.62  328.25\n5 47269   553 1870       TRUE        RWTH Aachen 21690.62  328.25\n6 23659   438 1457       TRUE       Uni Freiburg 21690.62  328.25\n7  9415   150 1818       TRUE           Uni Bonn 21690.62  328.25\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg 21690.62  328.25\n\n\nMehr Beispiele in der Hilfe zu across\n\n6.3.1 Übung"
  },
  {
    "objectID": "06_data_wrangle2.html#eigene-funktionen",
    "href": "06_data_wrangle2.html#eigene-funktionen",
    "title": "6  Data Wrangling II",
    "section": "6.4 Eigene Funktionen",
    "text": "6.4 Eigene Funktionen\nWoher kommt aber die ~1 in across()? Dazu sehen wir uns einmal die Grundlagen von Funktionen in R an.\nDazu sehen wir uns drei Zufriedensheitsvariablen für die Befragten aus den Zeilen 12-16 an:\n\n\n\n\n\n\n  \n  \n    \n      var\n      .\n      1\n      2\n      3\n      4\n      7/8/9\n    \n  \n  \n    F1450_04\nWie zufrieden sind Sie mit dem Betriebsklima?\nsehr zufrieden\nzufrieden\nweniger zufrieden\nnicht zufrieden\nt.n.z./k.A.\n    F1450_05\nWie zufrieden sind Sie mit Ihrem direkten Vorgesetzen?\nsehr zufrieden\nzufrieden\nweniger zufrieden\nnicht zufrieden\nt.n.z./k.A.\n    F1450_06\nWie zufrieden sind Sie mit Art und Inhalt der Tätigkeit?\nsehr zufrieden\nzufrieden\nweniger zufrieden\nnicht zufrieden\nt.n.z./k.A.\n  \n  \n  \n\n\n\n\n\netb18 <- haven::read_dta(\"./data/BIBBBAuA_2018_suf1.0.dta\")\n\nsat_small <- \n  etb18 %>% \n    select(F1450_04,F1450_05,F1450_06) %>% \n    slice(12:16) %>% \n    haven::zap_labels() %>% haven::zap_label() # labels entfernen\nsat_small\n\n# A tibble: 5 × 3\n  F1450_04 F1450_05 F1450_06\n     <dbl>    <dbl>    <dbl>\n1        3        3        2\n2        2        2        1\n3        2        2        1\n4        2        2        2\n5        1        2        2\n\n\n\n\n\nHäufig wollen wir mehrere Variablen mit der gleichen Operation bearbeiten. Oben haben wir gesehen wie sich das mit across() für existierende Funktionen erledigen lässt. Was aber, wenn wir eine Berechnung durchführen wollen, die nicht einfach die Anwendung von mean(), sd() o.ä. ist?\n\nsat_small %>% \n  mutate(dmean_F1450_04 = F1450_04 - mean(F1450_04,na.rm = T),\n         dmean_F1450_05 = F1450_05 - mean(F1450_05,na.rm = T))\n\n# A tibble: 5 × 5\n  F1450_04 F1450_05 F1450_06 dmean_F1450_04 dmean_F1450_05\n     <dbl>    <dbl>    <dbl>          <dbl>          <dbl>\n1        3        3        2              1          0.8  \n2        2        2        1              0         -0.200\n3        2        2        1              0         -0.200\n4        2        2        2              0         -0.200\n5        1        2        2             -1         -0.200\n\n\n…und jetzt noch F1450_06? Dann hätten wir drei Mal das mehr oder weniger gleiche getippt und damit gegen das “DRY”-Prinzip2 verstoßen. Außerdem gibt es in der ETB 2018 insgesamt 10 Spalten mit ähnlichen Zufriedenheitsvariablen. Wenn wir die alle bearbeiten möchten, ist copy & paste keine echte Option.\nEigene Funktionen helfen uns, das DRY-Prinzip in R umzusetzen. Wir machen die Berechnungsschritte Teil einer function() und wenden diese dann auf die gewünschten Variablen an. Eine Funktion hat einen Input, für welchen ein Platzhalter in der () definiert wird. Dieser Platzhalter kann dann innerhalb der Funktion - zwischen den {} - aufgerufen und bearbeitet werden. Als Ergebnis erhalten wir das Objekt, das wir in return() angeben. return() muss immer als letztes angeben werden und wir können immer nur ein Objekt als Output definieren:\n\ndtomean <- function(x){\n  d_x <- x - mean(x,na.rm = T)\n  return(d_x)\n}\n\n\nvar1 <- c(1,6,3,7,8,1,5)\nmean(var1)\n\n[1] 4.428571\n\ndtomean(var1)\n\n[1] -3.4285714  1.5714286 -1.4285714  2.5714286  3.5714286 -3.4285714  0.5714286\n\n\nWie können wir unsere Funktion dtomean() jetzt auf die Variablen aus unserem sat_small anwenden? Grundsätzlich haben wir ganz zu Beginn gesehen, dass ein data.frame lediglich zusammengefügte Sammlung von Vektoren (den Variablen) ist. Dementsprechend können wir jetzt unsere dtomean() auf eine Variable (einen Vektor) anwenden, indem wir ihn mit data.frame$variablename aufrufen:\n\ndtomean(sat_small$F1450_04)\n\n[1]  1  0  0  0 -1\n\n\nUm unsere Funktion jetzt auf jede Variable eines data.frame anzuwenden, können wir lapply() aus base R verwenden - der Output ist dann eine Liste, deren Elemente nach den Variablennamen benannt werden:\n\nsat_small %>% lapply(FUN = dtomean)\n\n$F1450_04\n[1]  1  0  0  0 -1\n\n$F1450_05\n[1]  0.8 -0.2 -0.2 -0.2 -0.2\n\n$F1450_06\n[1]  0.4 -0.6 -0.6  0.4  0.4\n\n\nIm {tidyverse} steht mit {purrr} ein Paket zur Verfügung, welches lapply() ersetzt:\n\nsat_small %>% map(.f = dtomean)\n\n$F1450_04\n[1]  1  0  0  0 -1\n\n$F1450_05\n[1]  0.8 -0.2 -0.2 -0.2 -0.2\n\n$F1450_06\n[1]  0.4 -0.6 -0.6  0.4  0.4\n\n\nMit bind_cols() können wir die Liste spaltenweise zusammenfügen:\n\nsat_small %>% map(.f = dtomean) %>% bind_cols()\n\n# A tibble: 5 × 3\n  F1450_04 F1450_05 F1450_06\n     <dbl>    <dbl>    <dbl>\n1        1    0.8        0.4\n2        0   -0.200     -0.6\n3        0   -0.200     -0.6\n4        0   -0.200      0.4\n5       -1   -0.200      0.4\n\nsat_small %>% map(~dtomean(.x)) %>% bind_cols() # formula syntax-Schreibweise\n\n# A tibble: 5 × 3\n  F1450_04 F1450_05 F1450_06\n     <dbl>    <dbl>    <dbl>\n1        1    0.8        0.4\n2        0   -0.200     -0.6\n3        0   -0.200     -0.6\n4        0   -0.200      0.4\n5       -1   -0.200      0.4\n\n\nDiese formula syntax Schreibweise findet sich dann auch in across() wieder - zusätzlich haben wir hier direkt über .names = die Möglichkeit, die Variablennamen für die Ergebnisse zu bearbeiten:\n\nsat_small %>% \n  mutate(across(matches(\"F1450\"),~dtomean(.x),.names = \"dmean_{.col}\"))\n\n# A tibble: 5 × 6\n  F1450_04 F1450_05 F1450_06 dmean_F1450_04 dmean_F1450_05 dmean_F1450_06\n     <dbl>    <dbl>    <dbl>          <dbl>          <dbl>          <dbl>\n1        3        3        2              1          0.8              0.4\n2        2        2        1              0         -0.200           -0.6\n3        2        2        1              0         -0.200           -0.6\n4        2        2        2              0         -0.200            0.4\n5        1        2        2             -1         -0.200            0.4\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nWir können Funktionen auch für andere Zwecke verwenden als Variablen zu bearbeiten. Bspw. können wir mit Funktionen eine Reihe an Datensätzen einlesen und direkt den gleichen Bearbeitungsschritten unterziehen, Modellserien oder Grafikserien erstellen usw. - etwas mehr dazu in Kapitel. Weiterführende Beispiele hier\nDie ‘formula syntax’ Schreibweise mit ~.x wird zunehmend durch anonyme Funktionen \\(x) fun(x) abgelöst - wird aber auf absehbare Zeit der Standard bleiben.\n\n\n\n\n6.4.1 Übung"
  },
  {
    "objectID": "06_data_wrangle2.html#hilfsfunktionen-ifelse-und-case_when",
    "href": "06_data_wrangle2.html#hilfsfunktionen-ifelse-und-case_when",
    "title": "6  Data Wrangling II",
    "section": "6.5 Hilfsfunktionen ifelse() und case_when()",
    "text": "6.5 Hilfsfunktionen ifelse() und case_when()\nifelse() ist eine große Hilfe für alle Umcodierungen: wir formulieren darin eine Bedingung und wenn diese zutrifft wird der erste Wert eingesetzt, wenn nicht wird der zweite Wert eingesetzt. Hier fragen wir also ab, ob studs-mean(studs) größer 0 ist - dann wird darüber eingesetzt, ansonsten eine darunter:\n\ndat3 %>% mutate(rel_to_mean = studs-mean(studs),\n                ab_mean_lab = ifelse(rel_to_mean > 0,\"darüber\",\"darunter\"))\n\n  studs profs gegr prom_recht                uni rel_to_mean ab_mean_lab\n1 19173   322 1971       TRUE         Uni Bremen   -2517.625    darunter\n2  5333    67 1830       TRUE         Uni Vechta  -16357.625    darunter\n3 15643   210 1973       TRUE      Uni Oldenburg   -6047.625    darunter\n4 14954   250 1971      FALSE          FH Aachen   -6736.625    darunter\n5 47269   553 1870       TRUE        RWTH Aachen   25578.375     darüber\n6 23659   438 1457       TRUE       Uni Freiburg    1968.375     darüber\n7  9415   150 1818       TRUE           Uni Bonn  -12275.625    darunter\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg   16388.375     darüber\n\n\ncase_when() ({dplyr}) erweitert dieses Prinzip, sodass wir mehr als zwei Optionen angeben können. Die Syntax ist aber etwas anders: hier geben wir erst die Bedingung an, dann nach einer ~3 die einzusetzenden Werte:\n\ndat3 %>% mutate(alter = case_when(gegr < 1500 ~ \"sehr alt\",\n                                  gegr < 1900 ~ \"alt\"))\n\n  studs profs gegr prom_recht                uni    alter\n1 19173   322 1971       TRUE         Uni Bremen     <NA>\n2  5333    67 1830       TRUE         Uni Vechta      alt\n3 15643   210 1973       TRUE      Uni Oldenburg     <NA>\n4 14954   250 1971      FALSE          FH Aachen     <NA>\n5 47269   553 1870       TRUE        RWTH Aachen      alt\n6 23659   438 1457       TRUE       Uni Freiburg sehr alt\n7  9415   150 1818       TRUE           Uni Bonn      alt\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg     <NA>\n\n\nMit TRUE können alle Fälle angesprochen werden, die bis dahin keiner Bedingung entsprochen haben:\n\ndat3 %>% mutate(alter = case_when(gegr < 1500 ~ \"sehr alt\",\n                                  gegr < 1900 ~ \"alt\",\n                                  TRUE ~ \"relativ neu\"))\n\n  studs profs gegr prom_recht                uni       alter\n1 19173   322 1971       TRUE         Uni Bremen relativ neu\n2  5333    67 1830       TRUE         Uni Vechta         alt\n3 15643   210 1973       TRUE      Uni Oldenburg relativ neu\n4 14954   250 1971      FALSE          FH Aachen relativ neu\n5 47269   553 1870       TRUE        RWTH Aachen         alt\n6 23659   438 1457       TRUE       Uni Freiburg    sehr alt\n7  9415   150 1818       TRUE           Uni Bonn         alt\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg relativ neu\n\n\nDas muss sich nicht auf eine Variable beschränken:\n\ndat3 %>% mutate(alter = case_when(gegr < 1500 & prom_recht == T ~ \"sehr alte Uni\",\n                                  gegr < 1900 & prom_recht == T ~ \"alte Uni\",\n                                  gegr > 1900 & prom_recht == T ~ \"junge Uni\",\n                                  gegr < 1900 & prom_recht == F ~ \"alte Hochschule\",\n                                  gegr > 1900 & prom_recht == F ~ \"junge Hochschule\"))\n\n  studs profs gegr prom_recht                uni            alter\n1 19173   322 1971       TRUE         Uni Bremen        junge Uni\n2  5333    67 1830       TRUE         Uni Vechta         alte Uni\n3 15643   210 1973       TRUE      Uni Oldenburg        junge Uni\n4 14954   250 1971      FALSE          FH Aachen junge Hochschule\n5 47269   553 1870       TRUE        RWTH Aachen         alte Uni\n6 23659   438 1457       TRUE       Uni Freiburg    sehr alte Uni\n7  9415   150 1818       TRUE           Uni Bonn         alte Uni\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg junge Hochschule\n\n\n\ncase_when() kann aber auch außerhalb von mutate() mit der base-Version verwendet werden, dafür müssen aber alle Variablen mit datensatz$ angewählt werden:\n\ncase_when(dat3$gegr < 1500 & dat3$prom_recht == T ~ \"sehr alte Uni\",\n          dat3$gegr < 1900 & dat3$prom_recht == T ~ \"alte Uni\",\n          dat3$gegr > 1900 & dat3$prom_recht == T ~ \"junge Uni\",\n          dat3$gegr < 1900 & dat3$prom_recht == F ~ \"alte Hochschule\",\n          dat3$gegr > 1900 & dat3$prom_recht == F ~ \"junge Hochschule\")\n\n\n6.5.1 Übung"
  },
  {
    "objectID": "06_data_wrangle2.html#variablen-umbenennen",
    "href": "06_data_wrangle2.html#variablen-umbenennen",
    "title": "6  Data Wrangling II",
    "section": "6.6 Variablen umbenennen",
    "text": "6.6 Variablen umbenennen\nUm Variablen umzubenennen gibt es rename(neuer_name = alter_name)\n\nsat_small %>% rename(neu=F1450_04)\n\n# A tibble: 5 × 3\n    neu F1450_05 F1450_06\n  <dbl>    <dbl>    <dbl>\n1     3        3        2\n2     2        2        1\n3     2        2        1\n4     2        2        2\n5     1        2        2\n\n\nFür fortgeschrittene Veränderungen empfiehlt sich ein Blick in rename_with(). Damit können wir Regular Expressions, bspw. aus {stringr} verwenden. Hier nur ein Beispiel:\n\nsat_small %>% rename_with(~tolower(.))\n\n# A tibble: 5 × 3\n  f1450_04 f1450_05 f1450_06\n     <dbl>    <dbl>    <dbl>\n1        3        3        2\n2        2        2        1\n3        2        2        1\n4        2        2        2\n5        1        2        2\n\nsat_small %>% rename_with(~str_remove(.x,\"1450_\"))\n\n# A tibble: 5 × 3\n    F04   F05   F06\n  <dbl> <dbl> <dbl>\n1     3     3     2\n2     2     2     1\n3     2     2     1\n4     2     2     2\n5     1     2     2"
  },
  {
    "objectID": "06_data_wrangle2.html#übungen",
    "href": "06_data_wrangle2.html#übungen",
    "title": "6  Data Wrangling II",
    "section": "6.7 Übungen",
    "text": "6.7 Übungen\n\n6.7.1 Übung\n\nErstellen Sie dat3 wie oben gezeigt aus dat1 und dat2\nBerechnen Sie das Betreuungsverhältnis (Studierende pro Professur studs/profs) an den Hochschulen relativ zum Mittelwert des Betreuungsverhältnisses (rel_studprofs).\nLiegt das Betreuungsverhältnis über oder unter dem Mittelwert? Wie können Sie den Befehl anpassen, sodass die Variable rel_studprofs lediglich TRUE oder FALSE enthält anstelle der Zahlenwerte.\nWandeln Sie rel_studprofs in eine Dummy-Variable mit 0/1 als Werten statt TRUE/FALSE\n\n\n\n\n\n\n\nTip\n\n\n\nDaumenregel zur Entscheidung, ob mutate() oder ...$newvar <- besser passt: Immer wenn es nur darum geht, schnell eine Variable zu erstellen/löschen, ist ...$newvar <- die einfachere Wahl. Sobald es darüber hinaus geht, hat mutate() sehr große Vorteile (folgender Abschnitt).\n\n\nZurück nach oben\n\n\n6.7.2 Übung\n\nVerwenden Sie weiterhin den Uni-Datensatz.\nBerechnen Sie das Betreuungsverhältnis (studprofs) relativ zum Mittelwert getrennt für Hochschulen/Unis mit und ohne Promotionsrecht und fügen Sie dieses als neue Spalte ein.\nTesten Sie sowohl die Variante mit group_by() als auch .by =.\n\nZurück nach oben\n\n\n\n\n\n6.7.3 Übung\n\nVerwenden Sie den etb18_small-Datensatz:\n\n\netb18_small <- haven::read_dta(\"./data/BIBBBAuA_2018_suf1.0.dta\",\n                               n_max = 10, # nur 10 Zeilen\n                               col_select = c(\"zpalter\",\"S1\",\"F1450_01\",\"F1450_02\",\"F1450_03\")\n                               )\n\n\nBerechnen Sie den Mittelwert für die Variablen F1450_01, F1450_02, und F1450_03:\n\n\n\n\n\n\n\n  \n  \n    \n      var\n      .\n    \n  \n  \n    F1450_01\nWie zufrieden sind Sie mit dem Einkommen aus dieser Tätigkeit?\n    F1450_02\nWie zufrieden sind Sie mit den derzeitigen Aufstiegsmöglichkeiten?\n    F1450_03\nWie zufrieden sind Sie mit Ihrer derzeitigen Arbeitszeit?\n  \n  \n  \n\n\n\n\n   zpalter S1 F1450_01 F1450_02 F1450_03\n1       41  1        2       NA        3\n2       51  2        4        4        2\n3       49  1        2        4        2\n4       63  2        2        2        2\n5       41  2        2        2        2\n6       57  1        1        2        4\n7       62  1        2       NA        2\n8       59  2        3        7        2\n9       32  2        3        3        3\n10      62  2        2        2        1\n\n\n\nVerwenden Sie across() und denken Sie ggf. daran, dass Sie NAs die na.rm = T in mean() setzen müssen: mean(....,na.rm = T)\nBerechnen Sie die Mittelwerte getrennt nach Geschlecht, indem Sie group_by() verwenden.\nFügen auch die Varianz (var()) und die Zahl der nicht-NA-Fälle hinzu und nutzen sie .names=, um die Spaltennamen nach dem Schema kennzahl.variable zu benennen.\n\nZurück nach oben\n\n\n6.7.4 Übung\nVerwenden Sie etb18_small3:\n\netb18_small3 <- haven::read_dta(\"./data/BIBBBAuA_2018_suf1.0.dta\",\n                       col_select = c(\"zpalter\",\"S1\",\"F1450_01\",\"F1450_02\",\"F1450_03\"))\netb18_small3 <- etb18_small3 %>% slice(5654:5666)\netb18_small3\n\n# A tibble: 13 × 5\n   zpalter   S1           F1450_01              F1450_02               F1450_03 \n   <dbl+lbl> <dbl+lbl>    <dbl+lbl>             <dbl+lbl>              <dbl+lbl>\n 1 54        2 [weiblich] 9 [keine Angabe]       4 [nicht zufrieden]   4 [nicht…\n 2 60        2 [weiblich] 2 [zufrieden]          2 [zufrieden]         2 [zufri…\n 3 63        1 [männlich] 2 [zufrieden]          2 [zufrieden]         2 [zufri…\n 4 49        2 [weiblich] 2 [zufrieden]          2 [zufrieden]         2 [zufri…\n 5 62        2 [weiblich] 1 [sehr zufrieden]     7 [Es gibt keine]     2 [zufri…\n 6 52        1 [männlich] 1 [sehr zufrieden]    NA                     1 [sehr …\n 7 59        1 [männlich] 2 [zufrieden]          2 [zufrieden]         2 [zufri…\n 8 59        1 [männlich] 1 [sehr zufrieden]    NA                     1 [sehr …\n 9 33        1 [männlich] 2 [zufrieden]         NA                     2 [zufri…\n10 41        2 [weiblich] 2 [zufrieden]          7 [Es gibt keine]     9 [keine…\n11 50        2 [weiblich] 2 [zufrieden]          7 [Es gibt keine]     1 [sehr …\n12 42        2 [weiblich] 3 [weniger zufrieden]  3 [weniger zufrieden] 3 [wenig…\n13 28        2 [weiblich] 9 [keine Angabe]       2 [zufrieden]         2 [zufri…\n\n\n\n\n   zpalter S1 F1450_01 F1450_02 F1450_03\n1       54  2        9        4        4\n2       60  2        2        2        2\n3       63  1        2        2        2\n4       49  2        2        2        2\n5       62  2        1        7        2\n6       52  1        1       NA        1\n7       59  1        2        2        2\n8       59  1        1       NA        1\n9       33  1        2       NA        2\n10      41  2        2        7        9\n11      50  2        2        7        1\n12      42  2        3        3        3\n13      28  2        9        2        2\n\n\n\n\n\n\n\n\n  \n  \n    \n      var\n      .\n      1\n      2\n      3\n      4\n      7/8/9\n    \n  \n  \n    F1450_01\nWie zufrieden sind Sie mit dem Einkommen aus dieser Tätigkeit?\nsehr zufrieden\nzufrieden\nweniger zufrieden\nnicht zufrieden\nt.n.z./k.A.\n    F1450_02\nWie zufrieden sind Sie mit den derzeitigen Aufstiegsmöglichkeiten?\nsehr zufrieden\nzufrieden\nweniger zufrieden\nnicht zufrieden\nt.n.z./k.A.\n    F1450_03\nWie zufrieden sind Sie mit Ihrer derzeitigen Arbeitszeit?\nsehr zufrieden\nzufrieden\nweniger zufrieden\nnicht zufrieden\nt.n.z./k.A.\n  \n  \n  \n\n\n\n\n\nStandardisieren Sie die Variablen F1450_01 - F1450_03 aus etb_small2 nach folgendem Muster:\n\n\netb_small2 %>% \n  mutate(std_F1450_01 = (F1450_01 - mean(F1450_01,na.rm = T))/sd(F1450_01,na.rm = T))\n\n\nNutzen Sie eine Funktion, um nicht wiederholt die gleichen Schritte einzugeben.\nVerwenden Sie zusätzlich across(), um die Funktion auf die gewünschten Variablen anzuwenden.\nBenennen Sie S1 in etb_small2 um\n\nZurück nach oben\n\n\n6.7.5 Übung\n\nBearbeiten Sie etb18_small:\n\n\netb18_small2 <- haven::read_dta(\"./data/BIBBBAuA_2018_suf1.0.dta\",\n                         col_select = c(\"zpalter\",\"S1\",\"F1450_01\",\"F1450_02\",\"F1450_03\"))\netb18_small2 <- etb18_small2 %>% slice(5654:5666)\netb18_small2\n\n# A tibble: 13 × 5\n   zpalter   S1           F1450_01              F1450_02               F1450_03 \n   <dbl+lbl> <dbl+lbl>    <dbl+lbl>             <dbl+lbl>              <dbl+lbl>\n 1 54        2 [weiblich] 9 [keine Angabe]       4 [nicht zufrieden]   4 [nicht…\n 2 60        2 [weiblich] 2 [zufrieden]          2 [zufrieden]         2 [zufri…\n 3 63        1 [männlich] 2 [zufrieden]          2 [zufrieden]         2 [zufri…\n 4 49        2 [weiblich] 2 [zufrieden]          2 [zufrieden]         2 [zufri…\n 5 62        2 [weiblich] 1 [sehr zufrieden]     7 [Es gibt keine]     2 [zufri…\n 6 52        1 [männlich] 1 [sehr zufrieden]    NA                     1 [sehr …\n 7 59        1 [männlich] 2 [zufrieden]          2 [zufrieden]         2 [zufri…\n 8 59        1 [männlich] 1 [sehr zufrieden]    NA                     1 [sehr …\n 9 33        1 [männlich] 2 [zufrieden]         NA                     2 [zufri…\n10 41        2 [weiblich] 2 [zufrieden]          7 [Es gibt keine]     9 [keine…\n11 50        2 [weiblich] 2 [zufrieden]          7 [Es gibt keine]     1 [sehr …\n12 42        2 [weiblich] 3 [weniger zufrieden]  3 [weniger zufrieden] 3 [wenig…\n13 28        2 [weiblich] 9 [keine Angabe]       2 [zufrieden]         2 [zufri…\n\n\n\nNutzen Sie ifelse(), um Personen ab 50 Jahren mit “ü50” zu kennzeichnen - lassen Sie für Personen bis unter 50 Jahren “u50” eintragen.\nFühren Sie eine Dreiteilung durch: Personen bis 40 bekommen “u40”, Personen bis einschließlich 50 “u50” und Personen über 50 Jahren “ü50”. Wie würden Sie mit case_when() vorgehen?\nNutzen Sie ifelse(), um Werte > 4 in den Variablen F1450_01, F1450_02, und F1450_03 in etb18_small2 mit NA zu überschreiben.\nSchreiben Sie zunächst eine ifelse()-Funktion, die für F1450_01 alle Werte > 4 mit NA überschreibt und ansonsten den Ausgangswert F1450_01 einsetzt.\nWie würde die Funktion aussehen, wenn Sie sie mit across() auf F1450_01, F1450_02 und F1450_03 gleichzeitig anwenden?\n\nZurück nach oben"
  },
  {
    "objectID": "06_data_wrangle2.html#anhang",
    "href": "06_data_wrangle2.html#anhang",
    "title": "6  Data Wrangling II",
    "section": "6.8 Anhang",
    "text": "6.8 Anhang\n\n6.8.1 Klassen bilden mit cut()\n\ndat3\n\n  studs profs gegr prom_recht                uni\n1 19173   322 1971       TRUE         Uni Bremen\n2  5333    67 1830       TRUE         Uni Vechta\n3 15643   210 1973       TRUE      Uni Oldenburg\n4 14954   250 1971      FALSE          FH Aachen\n5 47269   553 1870       TRUE        RWTH Aachen\n6 23659   438 1457       TRUE       Uni Freiburg\n7  9415   150 1818       TRUE           Uni Bonn\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg\n\n\nEine häufig Aufgabe in der Datenaufbereitung die Klassierung eines metrisches Merkmals, wie zum Beispiel die Professorenzahlen. Wir möchten also profs in 150er-Schritten zusammenfassen. Um die Klassen zu bilden, nutzen wir cut() und geben neben der zu unterteilenden Variable mit breaks die Klassengrenzen an. Für die Grenzen können wir seq() verwenden. Darin geben wir zunächst die obere und untere Grenze an und dann die Schrittbreiten.\n\ncut(dat3$profs,breaks = c(50, 200, 350, 500, 650))\n\n[1] (200,350] (50,200]  (200,350] (200,350] (500,650] (350,500] (50,200] \n[8] (500,650]\nLevels: (50,200] (200,350] (350,500] (500,650]\n\ncut(dat3$profs,breaks = seq(50,650,150))\n\n[1] (200,350] (50,200]  (200,350] (200,350] (500,650] (350,500] (50,200] \n[8] (500,650]\nLevels: (50,200] (200,350] (350,500] (500,650]\n\n\nDiese Werte legen wir in einer neuen Variable im Datensatz dat3 ab:\n\ndat3$prof_class <- cut(dat3$profs,breaks = seq(50,650,150))\ndat3\n\n  studs profs gegr prom_recht                uni prof_class\n1 19173   322 1971       TRUE         Uni Bremen  (200,350]\n2  5333    67 1830       TRUE         Uni Vechta   (50,200]\n3 15643   210 1973       TRUE      Uni Oldenburg  (200,350]\n4 14954   250 1971      FALSE          FH Aachen  (200,350]\n5 47269   553 1870       TRUE        RWTH Aachen  (500,650]\n6 23659   438 1457       TRUE       Uni Freiburg  (350,500]\n7  9415   150 1818       TRUE           Uni Bonn   (50,200]\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg  (500,650]\n\n\nFür diese neue Variable können wir mit count() eine Häufigkeitstabelle anfordern:\n\ndat3 %>% count(prof_class)\n\n  prof_class n\n1   (50,200] 2\n2  (200,350] 3\n3  (350,500] 1\n4  (500,650] 2\n\n\n\n\n\n( bedeutet dabei ausgeschlossen, ] inklusive. Es gibt also 3 Unis im Datensatz, die über 200 bis inklusive 350 Professuren unterhalten.\nFür die weiteren Beispiele löschen wir die prof_class wieder:\n\ndat3$prof_class <- NULL\n\nEinige hilfreiche Optionen für cut() im Anhang\n\nbsp <- c(1990,1998,2001,2009)\nbsp\n\n[1] 1990 1998 2001 2009\n\ncut(bsp,breaks = c(1990,2000,2010)) \n\n[1] <NA>             (1.99e+03,2e+03] (2e+03,2.01e+03] (2e+03,2.01e+03]\nLevels: (1.99e+03,2e+03] (2e+03,2.01e+03]\n\n# Anzahl der stellen in den labels\ncut(bsp,breaks = c(1990,2000,2010),dig.lab = 4) \n\n[1] <NA>        (1990,2000] (2000,2010] (2000,2010]\nLevels: (1990,2000] (2000,2010]\n\n# untere Grenze mit einbeziehen\ncut(bsp,breaks = c(1990,2000,2010),dig.lab = 4,include.lowest = T) \n\n[1] [1990,2000] [1990,2000] (2000,2010] (2000,2010]\nLevels: [1990,2000] (2000,2010]\n\n# durchnummerieren statt labels:\ncut(bsp,breaks = c(1990,2000,2010),labels = FALSE)\n\n[1] NA  1  2  2\n\n# eigene labels angeben:\ncut(bsp,breaks = c(1990,2000,2010),labels = c(\"90er\",\"00er\"))\n\n[1] <NA> 90er 00er 00er\nLevels: 90er 00er\n\n\n\n\n6.8.2 String-Funktionen für regex\n{stringr} stellt eine ganze Reihe an sehr hilfreichen String-Funktionen mit Regular Expressions zur Verfügung, einen Überblick bietet das Cheatsheet\n\ndat3 %>% mutate(uni_fh = str_detect(uni,\"Uni\"))\n\n  studs profs gegr prom_recht                uni uni_fh\n1 19173   322 1971       TRUE         Uni Bremen   TRUE\n2  5333    67 1830       TRUE         Uni Vechta   TRUE\n3 15643   210 1973       TRUE      Uni Oldenburg   TRUE\n4 14954   250 1971      FALSE          FH Aachen  FALSE\n5 47269   553 1870       TRUE        RWTH Aachen  FALSE\n6 23659   438 1457       TRUE       Uni Freiburg   TRUE\n7  9415   150 1818       TRUE           Uni Bonn   TRUE\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg  FALSE\n\ndat3 %>% mutate(bula = case_when(str_detect(uni,\"Bremen\")~ \"HB\",\n                                 str_detect(uni,\"Oldenb|Vechta\")~ \"NDS\",\n                                 str_detect(uni,\"Bonn|Aachen\")~ \"NRW\",\n                                 str_detect(uni,\"Freiburg\")~ \"BW\"\n                                 ))\n\n  studs profs gegr prom_recht                uni bula\n1 19173   322 1971       TRUE         Uni Bremen   HB\n2  5333    67 1830       TRUE         Uni Vechta  NDS\n3 15643   210 1973       TRUE      Uni Oldenburg  NDS\n4 14954   250 1971      FALSE          FH Aachen  NRW\n5 47269   553 1870       TRUE        RWTH Aachen  NRW\n6 23659   438 1457       TRUE       Uni Freiburg   BW\n7  9415   150 1818       TRUE           Uni Bonn  NRW\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg  NRW\n\ndat3 %>% mutate(ort = str_remove(uni,\"Uni |FH |RWTH \"))\n\n  studs profs gegr prom_recht                uni             ort\n1 19173   322 1971       TRUE         Uni Bremen          Bremen\n2  5333    67 1830       TRUE         Uni Vechta          Vechta\n3 15643   210 1973       TRUE      Uni Oldenburg       Oldenburg\n4 14954   250 1971      FALSE          FH Aachen          Aachen\n5 47269   553 1870       TRUE        RWTH Aachen          Aachen\n6 23659   438 1457       TRUE       Uni Freiburg        Freiburg\n7  9415   150 1818       TRUE           Uni Bonn            Bonn\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg Bonn-Rhein-Sieg"
  },
  {
    "objectID": "07_inferenz.html",
    "href": "07_inferenz.html",
    "title": "7  Inferenzstatistik & Zusammenhangsmaße",
    "section": "",
    "text": "library(tidyverse)\n\netb18_kap7 <- haven::read_dta(\"./data/BIBBBAuA_2018_suf1.0.dta\",\n                         n_max = 1000,\n                         col_select = c(\"intnr\",\"zpalter\",\"S1\",\"F231\",\"az\",\"F600_12\",\n                                        \"m1202\",\"F204\",\"gew2018_hr17\",\"gew2018\",\"F518_SUF\",\n                                        \"F411_01\",\"S3\",\"Mig\")) %>% \n  mutate(F600_12 = ifelse(F600_12 > 4,NA,F600_12),\n         zpalter = ifelse(zpalter>100,NA,zpalter),\n         m1202 = ifelse(m1202 > 4,NA,m1202))\nNeue Pakete:\nBisher haben wir die Angaben aus unserem Datensatz immer als fix angesehen. Ziel einer statistischen Auswertung ist aber meistens, Aussagen über die Grundgesamtheit oder Population zu treffen. Im Fall der ETB 2018 wären das also alle Erwerbstätigen in Deutschland."
  },
  {
    "objectID": "07_inferenz.html#t-tests",
    "href": "07_inferenz.html#t-tests",
    "title": "7  Inferenzstatistik & Zusammenhangsmaße",
    "section": "7.1 t-Tests",
    "text": "7.1 t-Tests\nEines der zentralen Werkzeuge der grundlegenden Inferenzstatistik ist der t-Test.\nEin typischer Anwendungsfall für t-Tests ist der Gruppenvergleich, dazu geben wir in t.test() die zu testende Variable und und nach einer ~1 die Gruppenvariable an. Wir testen hier also auf Altersunterschiede zwischen Männern (S1=1, daher group1) und Frauen (S1=2, daher group2).\n\nt.test(etb18_kap7$zpalter~etb18_kap7$S1)\n\n\n    Welch Two Sample t-test\n\ndata:  etb18_kap7$zpalter by etb18_kap7$S1\nt = -2.549, df = 974.9, p-value = 0.01095\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n95 percent confidence interval:\n -3.1679965 -0.4119377\nsample estimates:\nmean in group 1 mean in group 2 \n       47.28484        49.07480 \n\n\nEs hat sich als Konvention etabliert, von einem signifikanten Unterschied zu sprechen wenn die Irrtumswahrscheinlichkeit unter 5% liegt. Das bedeutet:\n\n\nDa hier der p-Wert sehr viel kleiner ist als 0.05 ist (p-value < 2.2e-16)2, können wir von einen statistisch signifikanten Unterschied sprechen.\nStandardmäßig bekommen wir einen beidseitigen Test (\"two.sided\"), wir können aber auch einen links- (\"less\") oder rechtsseitigen (\"greater\") Test anfordern mehr dazu:\n\nt.test(etb18_kap7$zpalter~etb18_kap7$S1,alternative = \"two.sided\")\nt.test(etb18_kap7$zpalter~etb18_kap7$S1,alternative = \"less\")\nt.test(etb18_kap7$zpalter~etb18_kap7$S1,alternative = \"greater\")\n\nFür Effektgrößen wie Cohen’s D empfiehlt sich das Paket {effectsize}:\n\nlibrary(effectsize)\ncohens_d(etb18_kap7$zpalter~etb18_kap7$S1)\n\nCohen's d |         95% CI\n--------------------------\n-0.16     | [-0.29, -0.04]\n\n- Estimated using pooled SD.\n\n\n\n\n\n\n7.1.1 Übung"
  },
  {
    "objectID": "07_inferenz.html#pearson",
    "href": "07_inferenz.html#pearson",
    "title": "7  Inferenzstatistik & Zusammenhangsmaße",
    "section": "7.2 Korrelation",
    "text": "7.2 Korrelation\nDen Korrelationskoeffizienten können wir in R mit cor.test() berechnen:\nF231: Wie viele Stunden arbeiten Sie i.d.R. im Durchschnitt pro Woche von zu Hause aus?\n\ncor.test(etb18_kap7$zpalter,etb18_kap7$F231,method = \"pearson\", use = \"pairwise.complete.obs\")\n\n\n    Pearson's product-moment correlation\n\ndata:  etb18_kap7$zpalter and etb18_kap7$F231\nt = 0.48542, df = 286, p-value = 0.6277\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.08717658  0.14379451\nsample estimates:\n       cor \n0.02869194 \n\n\n\n\n\nEs handelt sich mit 0.0287 also um einen geringen Zusammenhang. Der p-Wert gibt uns auch hier wieder Auskunft über die stat. Signifikanz: mit 0.62775 liegt der p-Wert deutlich unter 0,05.\nUm eine Korrelationsmatrix zu erhalten hilft das Paket {correlation}:\n\ninstall.packages(\"correlation\")\n\n\nlibrary(correlation)\netb18_kap7 %>% select(zpalter,F231,az) %>% \n  correlation() %>% \n  summary(.)\n\n# Correlation Matrix (pearson-method)\n\nParameter |    az | F231\n------------------------\nzpalter   | -0.05 | 0.03\nF231      | -0.10 |     \n\np-value adjustment method: Holm (1979)\n\n\n\ncorr_df <- \n  etb18_kap7 %>%\n    group_by(S1) %>%\n    select(zpalter,F231,az) %>% \n    correlation()\n\nAdding missing grouping variables: `S1`\n\ndata.frame(corr_df)\n\n  Group Parameter1 Parameter2            r   CI      CI_low    CI_high\n1     1    zpalter       F231 -0.008016615 0.95 -0.16106862 0.14541192\n2     1    zpalter         az -0.006654458 0.95 -0.09536128 0.08215722\n3     1       F231         az -0.107424635 0.95 -0.25645259 0.04659229\n4     2    zpalter       F231  0.029864101 0.95 -0.14722774 0.20510074\n5     2    zpalter         az -0.038373166 0.95 -0.12495280 0.04878647\n6     2       F231         az  0.042311811 0.95 -0.13429355 0.21631207\n           t df_error         p              Method n_Obs\n1 -0.1020381      162 1.0000000 Pearson correlation   164\n2 -0.1467035      486 1.0000000 Pearson correlation   488\n3 -1.3752506      162 0.5128577 Pearson correlation   164\n4  0.3300070      122 1.0000000 Pearson correlation   124\n5 -0.8638192      506 1.0000000 Pearson correlation   508\n6  0.4696813      123 1.0000000 Pearson correlation   125"
  },
  {
    "objectID": "07_inferenz.html#weitere-zusammenshangsmaße",
    "href": "07_inferenz.html#weitere-zusammenshangsmaße",
    "title": "7  Inferenzstatistik & Zusammenhangsmaße",
    "section": "7.3 Weitere Zusammenshangsmaße:",
    "text": "7.3 Weitere Zusammenshangsmaße:\n\n7.3.1 Rangkorrelation & Kendall’s \\(\\tau\\)\nEin klassisches ordinales Merkmal ist die Schulbildung, die wir aus S3 zusammenfassen können (Details im Code-Fenster unten). Wir sehen uns den (möglichen) Zusammenhang zwischen dem höchsten Ausbildungsabschluss m1202 und F600_12 an:\n\n\n\n\n \n  \n    v \n    l \n  \n \n\n  \n    F600_12 \n    Häufigkeit: unter Lärm arbeiten \n  \n  \n    1 \n    häufig \n  \n  \n    2 \n    manchmal \n  \n  \n    3 \n    selten \n  \n  \n    4 \n    nie \n  \n\n\n\n\n\nFür den Spearman-Rangkorrelationskoeffizienten können wir method = \"spearman\" nutzen:\n\ncor.test(etb18_kap7$m1202,etb18_kap7$F600_12,method = \"spearman\", use = \"pairwise.complete.obs\")\n\nEin weiteres Zusammenhangsmaß für ordinale Variablen sind Konkordanzmaße wie Kendall’s \\(\\tau\\), mit der Option method = \"kendall\":\n\ncor.test(etb18_kap7$m1202,etb18_kap7$F600_12, method = \"kendall\", use = \"pairwise.complete.obs\")\n\n\n\n7.3.2 \\(\\chi^2\\) & Cramér’s \\(v\\)\nMit chisq.test() bekommen wir \\(\\chi^2\\) ausgegeben, diese müssen wir jedoch auf ein xtabs()-Objekt anwenden (F204 Mehrarbeitsvergütung und S1 Geschlecht)\n\ntab1 <- xtabs(~ F204 + S1, data = etb18_kap7)\nchisq.test(tab1)\n\n\n    Pearson's Chi-squared test\n\ndata:  tab1\nX-squared = 12.541, df = 4, p-value = 0.01375\n\n\nFür Cramér’s \\(v\\) können wir wieder auf {effectsize} zurückgreifen:\n\neffectsize::cramers_v(etb18_kap7$F204,etb18_kap7$S1)\n\nCramer's V |       95% CI\n-------------------------\n0.17       | [0.06, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].\n\n\nWeitere Maße\n\n\n7.3.3 Übung"
  },
  {
    "objectID": "07_inferenz.html#gewichtung",
    "href": "07_inferenz.html#gewichtung",
    "title": "7  Inferenzstatistik & Zusammenhangsmaße",
    "section": "7.4 Gewichtung",
    "text": "7.4 Gewichtung\n\nBei der Datenanalyse ist man oft mit einer Stichprobe aus einer größeren Population konfrontiert und man möchte aus dieser Stichprobe Rückschlüsse auf die größere Population ziehen. Die meisten statistischen Verfahren für diese sog. „Inferenzstatistik“ beruhen dabei auf der Annahme, dass die Stichprobe eine einfache Zufallsstichprobe ist. Bei einer solchen Stichprobe gelangen alle Elemente der Grundgesamtheit mit der gleichen Wahrscheinlichkeit in die Stichprobe. In der Praxis sind solche Stichproben aber die große Ausnahme. Häufig haben bestimmte Gruppen von Personen höhere Auswahlwahrscheinlichkeiten als andere. Kohler/Kreuter, S.81\n\nGewichte sind ein häufig verwendetes Gegenmittel. Die einfachste Variante für eine Gewichtung ist die Option wt= in count():\n\netb18_kap7 %>% \n  count(S1,m1202,wt = gew2018_hr17)\n\n# A tibble: 10 × 3\n   S1           m1202       n\n   <dbl+lbl>    <dbl>   <dbl>\n 1 1 [männlich]    -1   1988.\n 2 1 [männlich]     1 115140.\n 3 1 [männlich]     2 496863.\n 4 1 [männlich]     3 127220.\n 5 1 [männlich]     4 268891.\n 6 2 [weiblich]    -1   1893.\n 7 2 [weiblich]     1  70031.\n 8 2 [weiblich]     2 459651.\n 9 2 [weiblich]     3  55828.\n10 2 [weiblich]     4 237108.\n\n\nFür umfangreichere Anwendungen stehen in R stehen die Pakete {survey} und das darauf aufbauende {srvyr} zur Verfügung.\n\ninstall.packages(\"survey\")\n\nZunächst verwenden wir svydesign(), um die Gewichtung festzulegen. Im weiteren stellt {survey} dann zahlreiche Funktionen zur Verfügung, die eine gewichtete Variante der basis-Befehle sind - bspw. svymean() und svytable():\n\nlibrary(survey)\netb18_kap7_weighted <- svydesign(id      = ~intnr,\n                            weights = ~gew2018,\n                            data    = etb18_kap7)\n\nsvymean(~zpalter, etb18_kap7_weighted, na.rm = TRUE)\n\n          mean     SE\nzpalter 44.234 0.6175\n\nmean(etb18_kap7$zpalter, na.rm = TRUE)\n\n[1] 48.19779\n\n\nFür Tabellen gibt es in {survey} auch eine Funktion: svytable(~S1+m1202,etb18_kap7_weighted)\nFür Regressionsmodelle gibt es bspw. survey::svyglm()\nLektüre: Kiesl, H. (2014). Gewichtung. In N. Baur & J. Blasius (Eds.), Handbuch Methoden der empirischen Sozialforschung (pp. 349–356). Springer Fachmedien Wiesbaden."
  },
  {
    "objectID": "07_inferenz.html#übungen",
    "href": "07_inferenz.html#übungen",
    "title": "7  Inferenzstatistik & Zusammenhangsmaße",
    "section": "7.5 Übungen",
    "text": "7.5 Übungen\n\n7.5.1 Übung 1\n\netb18_ue7 <- haven::read_dta(\"./data/BIBBBAuA_2018_suf1.0.dta\",\n                         n_max = 1000,\n                         col_select = c(\"intnr\",\"S1\",\"az\",\"F518_SUF\",\"m1202\",\"F411_01\",\"gew2018\")) %>% \n  mutate(across(matches(\"m1202|F411_01\"), ~ifelse(.x > 4|.x<0,NA,.x))) # missings in m1202 mit NA überschreiben\n\nTesten Sie die Hypothese, dass ein signifikanter Unterschied in der Arbeitszeit (az) zwischen Männern und Frauen besteht (S1). Beide Variablen haben keine Missings - Sie können direkt los legen\nBerechnen Sie das Cohen’s d für diesen Zusammenhang.\n\n\n7.5.2 Übung 2\n\nUntersuchen Sie die Korrelation zwischen der Wochenarbeitszeit (az) und dem Einkommen (F518_SUF) der Befragten.\nDenken Sie daran, die Missings in F518_SUF auszuschließen: etb18_kap7$F518_SUF[etb18_kap7$F518_SUF>99990] <- NA, az hat keine Missings.\nBerechnen Sie die Rangkorrelation für den Zusammenhang zwischen der Häufigkeit von starkem Termin- oder Leistungsdruck F411_01 und der Ausbildungsvariable m1202.\n\n\n\n\n\n\n\n  \n  \n    \n      var\n      .\n      1\n      2\n      3\n      4\n      9\n    \n  \n  \n    F411_01\nWie häufig kommt es vor, dass Sie unter starkem Termin- oder Leistungsdruck arbe\nhäufig\nmanchmal\nselten\nnie\nkeine Angabe\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.5.3 Übung 3\n\nLegen Sie die Gewichtung auf Basis von gew2018 an.\nBerechnen Sie den Mittelwert für den Bruttoverdienst F518_SUF (Schließen Sie die Missings ggf. mit etb18_kap7$F518_SUF[etb18_kap7$F518_SUF>99990] <- NA - sie können mit max(etb18_kap7$F518_SUF,na.rm = T) überprüfen ob das Maximum bei 99999 liegt)"
  },
  {
    "objectID": "07_inferenz.html#anhang",
    "href": "07_inferenz.html#anhang",
    "title": "7  Inferenzstatistik & Zusammenhangsmaße",
    "section": "7.6 Anhang",
    "text": "7.6 Anhang\n\n7.6.1 Weitere Korrelationsmaße\nKendall’s \\(\\tau_a\\), welches im Nenner alle Paarvergleiche berücksichtigt, können wir mit KendallTauA() aus dem Paket DescTools berechnen:\n\ninstall.packages(\"DescTools\")\n\n\nlibrary(DescTools)\nKendallTauA(etb18_kap7$m1202,etb18_kap7$F600_12)\n\n[1] 0.08970494\n\n\nDer Wert ist deutlich niedriger als von Kendall’s \\(\\tau_b\\), da hier der Nenner durch die Berücksichtigung aller möglichen Paarvergleiche größer wird, der Zähler aber für beide Varianten von Kendall’s \\(\\tau\\) gleich definiert ist.\nEine andere Alternative, welche auch beim Vorliegen von Bindungen den vollen Wertebereich [-1,1] erreichen kann ist Goodman & Kruskal’s \\(\\gamma\\). Dieses können wir mit dem Befehl GoodmanKruskalGamma aus dem Paket {DescTools} berechnen:\n\nlibrary(DescTools)\nGoodmanKruskalGamma(etb18_kap7$m1202,etb18_kap7$F600_12)\n\n[1] 0.2064219\n\n\nAuch Goodman & Kruskal’s \\(\\gamma\\) deutet auf einen negativen Zusammenhang hin, hier ist die Stärke aber deutlich höher. Dies ist auf die Berücksichtigung der Bindungen zurückzuführen: hier werden alle Bindungen ausgeschlossen, also auch Paarvgleiche mit Bindungen nur auf einer Variable. Es reduziert sich also der Nenner, somit ergibt sich im Ergebnis ein höherer Koeffizient für Goodman & Kruskal’s \\(\\gamma\\) als für Kendall’s \\(\\tau_b\\).\n\netb18_kap7 %>% \n  select(m1202,F600_12) %>% \n  correlation(method = \"kendall\")\n\n# Correlation Matrix (kendall-method)\n\nParameter1 | Parameter2 |  tau |       95% CI |    z |         p\n----------------------------------------------------------------\nm1202      |    F600_12 | 0.14 | [0.10, 0.18] | 4.93 | < .001***\n\np-value adjustment method: Holm (1979)\nObservations: 999\n\n\nHier findet sich eine Liste weiterer Kennzahlen, die sich mit {correlate} berechnen lassen."
  },
  {
    "objectID": "09_reg.html",
    "href": "09_reg.html",
    "title": "8  Regressionsmodelle",
    "section": "",
    "text": "Zum Einstieg betrachten wir zunächst einen (fiktiven) Datensatz mit lediglich fünf Fällen. Mit dem data.frame Befehl können wir einen Datensatz erstellen. Unserer hat zunächst lediglich zwei Variablen: var1 und var2"
  },
  {
    "objectID": "09_reg.html#lm1",
    "href": "09_reg.html#lm1",
    "title": "8  Regressionsmodelle",
    "section": "8.1 Regressionsmodelle mit lm()",
    "text": "8.1 Regressionsmodelle mit lm()\n\n\n\nRegressionsmodelle in R lassen sich mit lm() erstellen. Hier geben wir das Merkmal an, dass auf der y-Achse liegt (die abhängige Variable) und nach einer ~ das Merkmal für die x-Achse (unabhängige Variable). Die Interpretation des Ergebnisses wird uns die kommenden Wochen beschäftigen.\n\nlm(var2~ var1, data = dat1)\n\n\nCall:\nlm(formula = var2 ~ var1, data = dat1)\n\nCoefficients:\n(Intercept)         var1  \n     -2.340        1.839  \n\n\nDer Wert unter var1 gibt an, um wieviel sich die Gerade pro “Schritt nach rechts” nach oben/unten verändert. Die Gerade steigt also pro Einheit von var1 um 1.8389662. Die Ergebnisse können wir unter m1 ablegen:\n\nm1 <- lm(var2~ var1, data = dat1)  \n\nMit summary() bekommen wir dann eine Regressionstabelle:\n\nsummary(m1)\n\n\nCall:\nlm(formula = var2 ~ var1, data = dat1)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-8.372 -3.613  0.162  2.234 10.789 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)  \n(Intercept)  -2.3400     4.3454  -0.538   0.6096  \nvar1          1.8390     0.7727   2.380   0.0548 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.127 on 6 degrees of freedom\nMultiple R-squared:  0.4856,    Adjusted R-squared:  0.3999 \nF-statistic: 5.664 on 1 and 6 DF,  p-value: 0.05477\n\n\nm1 enthält alle Informationen zum Modell, besonders hilfreich ist $coefficients:\n\nm1$coefficients\n\n(Intercept)        var1 \n  -2.339960    1.838966 \n\nsummary(m1)$coefficients\n\n             Estimate Std. Error    t value   Pr(>|t|)\n(Intercept) -2.339960  4.3453801 -0.5384938 0.60961706\nvar1         1.838966  0.7727028  2.3799139 0.05477457\n\n\nWir können uns die einzelnen Werte mit View(m1) ansehen:"
  },
  {
    "objectID": "09_reg.html#regressionsmodelle-visualisieren",
    "href": "09_reg.html#regressionsmodelle-visualisieren",
    "title": "8  Regressionsmodelle",
    "section": "8.2 Regressionsmodelle visualisieren",
    "text": "8.2 Regressionsmodelle visualisieren\nMit geom_smooth(method = \"lm\") können wir Regressionsgeraden auch in {ggplot2} darstellen: Unser Modell mit var1 und var2 können wir so darstellen:\n\nlibrary(ggplot2)\nggplot(dat1, aes(x = var1, y = var2)) + \n  geom_point(size = 2) + \n  geom_smooth(method = \"lm\", color = \"darkblue\" , fill = \"lightskyblue\", size = .65)  \n\n\n\n\n\n\n\n\nHier scheinen wir einen Ausreißer zu haben. In unserem übersichtlichen Datensatz ist der schnell gefunden. In größeren Datensätzen hilft uns geom_text():\n\nggplot(dat1, aes(x = var1, y = var2)) + \n  geom_point(size = 2) + \n  geom_smooth(method = \"lm\", color = \"darkblue\" , fill = \"lightskyblue\", size = .65)  +\n  geom_text(data = . %>% filter(var2 > 20), aes(y = var2+3, label = id), color = \"sienna1\")\n\n\n\n\n\n\n\n\nWir können nämlich einzelne geom_ auch nur für ein Subset angeben - dazu vergeben wir data = neu (übernehmen also nicht die Auswahl aus dem Haupt-Befehl ggplot()) und setzen darin einen filter(). Außerdem verschieben wir mit var2+3 das Label etwas über den Punkt.\n\n8.2.1 Übung"
  },
  {
    "objectID": "09_reg.html#modelle-nur-für-manche-fälle-berechnen",
    "href": "09_reg.html#modelle-nur-für-manche-fälle-berechnen",
    "title": "8  Regressionsmodelle",
    "section": "8.3 Modelle nur für manche Fälle berechnen",
    "text": "8.3 Modelle nur für manche Fälle berechnen\nWenn wir jetzt das Modell nochmal berechnen wollen, haben wir zwei Möglichkeiten:\n\n8.3.1 Neuen data.frame erstellen\nWir können in R mehrere data.frame-Objekte im Speicher halten. Also können wir leicht einen neuen data.frame erstellen, der nur die Beobachtungen mit var2 < 20 enthält und diesen dann für unseren lm()-Befehl verwenden:\n\ndat1_u20 <- dat1 %>% filter(var2<20)\nm2a <- lm(var2~ var1, data = dat1_u20)\nsummary(m2a)\n\n\nCall:\nlm(formula = var2 ~ var1, data = dat1_u20)\n\nResiduals:\n      1       2       3       4       5       6       7 \n-0.4737  0.1941 -1.4737  4.5230  1.1875 -2.4803 -1.4770 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)   1.1382     1.9217   0.592    0.579\nvar1          0.6678     0.3877   1.722    0.146\n\nResidual standard error: 2.555 on 5 degrees of freedom\nMultiple R-squared:  0.3724,    Adjusted R-squared:  0.2469 \nF-statistic: 2.967 on 1 and 5 DF,  p-value: 0.1456\n\n\n\n\n8.3.2 Direkt in lm() filtern\nWir können filter()-Befehl auch direkt in das data=-Argument von lm() bauen:\n\nm2b <- lm(var2~ var1, data = dat1 %>% filter(var2<20))\nsummary(m2b)\n\n\nCall:\nlm(formula = var2 ~ var1, data = dat1 %>% filter(var2 < 20))\n\nResiduals:\n      1       2       3       4       5       6       7 \n-0.4737  0.1941 -1.4737  4.5230  1.1875 -2.4803 -1.4770 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)   1.1382     1.9217   0.592    0.579\nvar1          0.6678     0.3877   1.722    0.146\n\nResidual standard error: 2.555 on 5 degrees of freedom\nMultiple R-squared:  0.3724,    Adjusted R-squared:  0.2469 \nF-statistic: 2.967 on 1 and 5 DF,  p-value: 0.1456"
  },
  {
    "objectID": "09_reg.html#regressionstabellen",
    "href": "09_reg.html#regressionstabellen",
    "title": "8  Regressionsmodelle",
    "section": "8.4 Regressionstabellen",
    "text": "8.4 Regressionstabellen\nWenn wir diese verschiedenen Modelle jetzt vergleichen möchten, bietet sich eine Tabelle an.\nEs gibt zahlreiche Alternativen zur Erstellung von Regressionstabellen, mein persönlicher Favorit ist modelsummary() aus dem gleichnamigen Paket {modelsummary}. Es kommt mit (nahezu) allen Modellarten zurecht und bietet darüber hinaus eine breite Palette an (u.a. auch Word-Output - dazu später mehr) und auch Koeffizientenplots (auch dazu kommen wir noch). Außerdem ist die Dokumentation hervorragend.\n\ninstall.packages(\"modelsummary\")\n\n\nlibrary(modelsummary)\nmodelsummary(list(m1,m2a,m2b))\n\n\n\n \n  \n      \n    Model 1 \n    Model 2 \n    Model 3 \n  \n \n\n  \n    (Intercept) \n    −2.340 \n    1.138 \n    1.138 \n  \n  \n     \n    (4.345) \n    (1.922) \n    (1.922) \n  \n  \n    var1 \n    1.839 \n    0.668 \n    0.668 \n  \n  \n     \n    (0.773) \n    (0.388) \n    (0.388) \n  \n  \n    Num.Obs. \n    8 \n    7 \n    7 \n  \n  \n    R2 \n    0.486 \n    0.372 \n    0.372 \n  \n  \n    R2 Adj. \n    0.400 \n    0.247 \n    0.247 \n  \n  \n    AIC \n    55.4 \n    36.6 \n    36.6 \n  \n  \n    BIC \n    55.6 \n    36.5 \n    36.5 \n  \n  \n    Log.Lik. \n    −24.702 \n    −15.321 \n    −15.321 \n  \n  \n    F \n    5.664 \n    2.967 \n    2.967 \n  \n  \n    RMSE \n    5.31 \n    2.16 \n    2.16 \n  \n\n\n\n\n\nWir werden uns noch ein bisschen ausführlicher mit den Anpassungsmöglichkeiten für {modelsummary} befassen, hier nur schon mal zwei zentrale Optionen:\n\nmit stars = T können wir uns die Signifikanz mit den gebräuchlichen Sternchen-Codes anzeigen lassen (*: p < .05 usw.)\nmit gof_omit = \"IC|RM|Log\" können wir die Goodness of Fit Statistiken ausblenden die IC, RM oder Log im Namen haben (also AIC, BIC, RMSE und die LogLikelihood)\nmit \"Name\" = in list() können wir Namen angeben:\n\n\nmodelsummary(list(\"m1\"=m1,\"m2a\"=m2a,\"m2b\"=m2b),stars = T,gof_omit = \"IC|RM|Log\")\n\n\n\n \n  \n      \n    m1 \n    m2a \n    m2b \n  \n \n\n  \n    (Intercept) \n    −2.340 \n    1.138 \n    1.138 \n  \n  \n     \n    (4.345) \n    (1.922) \n    (1.922) \n  \n  \n    var1 \n    1.839+ \n    0.668 \n    0.668 \n  \n  \n     \n    (0.773) \n    (0.388) \n    (0.388) \n  \n  \n    Num.Obs. \n    8 \n    7 \n    7 \n  \n  \n    R2 \n    0.486 \n    0.372 \n    0.372 \n  \n  \n    R2 Adj. \n    0.400 \n    0.247 \n    0.247 \n  \n  \n    F \n    5.664 \n    2.967 \n    2.967 \n  \n\n\n + p < 0.1, * p < 0.05, ** p < 0.01, *** p < 0.001\n\n\n\n\n\n8.4.1 Übung"
  },
  {
    "objectID": "09_reg.html#kategoriale-unabhängige-variablen",
    "href": "09_reg.html#kategoriale-unabhängige-variablen",
    "title": "8  Regressionsmodelle",
    "section": "8.5 Kategoriale unabhängige Variablen",
    "text": "8.5 Kategoriale unabhängige Variablen\nNatürlich können wir auch kategoriale unabhängige Variablen in unser Modell mit aufnehmen. Dazu müssen wir aber entsprechende Variable als factor definieren - und R so mitteilen, dass die Zahlenwerte nicht numerisch zu interpretieren sind. Wenn wir educ aus unserem kleinen Beispiel betrachten - dann steht 1 für einen grundlegenden Bildungsabschluss, 2 für einen mittleren und 3 für einen hohen Bildungsabschluss.\n\ndat1\n\n  id var1 var2 educ gend  x\n1  1    2    2    3    2  2\n2  2    1    2    1    1  1\n3  3    2    1    2    1  2\n4  4    5    9    2    2  4\n5  5    7    7    1    1  1\n6  6    8    4    3    2 NA\n7  7    9   25    2    1 NA\n8  8    5    3   -1    2 NA\n\nm3 <- lm(var2~factor(educ), dat1)\nsummary(m3)\n\n\nCall:\nlm(formula = var2 ~ factor(educ), data = dat1)\n\nResiduals:\n         1          2          3          4          5          6          7 \n-1.000e+00 -2.500e+00 -1.067e+01 -2.667e+00  2.500e+00  1.000e+00  1.333e+01 \n         8 \n-2.387e-15 \n\nCoefficients:\n                Estimate Std. Error t value Pr(>|t|)\n(Intercept)    3.000e+00  8.848e+00   0.339    0.752\nfactor(educ)1  1.500e+00  1.084e+01   0.138    0.897\nfactor(educ)2  8.667e+00  1.022e+01   0.848    0.444\nfactor(educ)3 -1.632e-15  1.084e+01   0.000    1.000\n\nResidual standard error: 8.848 on 4 degrees of freedom\nMultiple R-squared:  0.2848,    Adjusted R-squared:  -0.2516 \nF-statistic: 0.531 on 3 and 4 DF,  p-value: 0.685\n\n\nNoch schöner ist das aber natürlich, wenn wir educ vorher labeln:\n\ndat1$ed_fct <- factor(dat1$educ, levels = 1:3,\n                        labels = c(\"basic\",\"medium\",\"high\"))\ndat1\n\n  id var1 var2 educ gend  x ed_fct\n1  1    2    2    3    2  2   high\n2  2    1    2    1    1  1  basic\n3  3    2    1    2    1  2 medium\n4  4    5    9    2    2  4 medium\n5  5    7    7    1    1  1  basic\n6  6    8    4    3    2 NA   high\n7  7    9   25    2    1 NA medium\n8  8    5    3   -1    2 NA   <NA>\n\n\nDann verwenden den factor im Regressionsbefehl:\n\nm3 <- lm(var2 ~ ed_fct, dat1)\nsummary(m3)\n\n\nCall:\nlm(formula = var2 ~ ed_fct, data = dat1)\n\nResiduals:\n      1       2       3       4       5       6       7 \n -1.000  -2.500 -10.667  -2.667   2.500   1.000  13.333 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)\n(Intercept)     4.500      6.257   0.719    0.512\ned_fctmedium    7.167      8.077   0.887    0.425\ned_fcthigh     -1.500      8.848  -0.170    0.874\n\nResidual standard error: 8.848 on 4 degrees of freedom\n  (1 Beobachtung als fehlend gelöscht)\nMultiple R-squared:  0.2594,    Adjusted R-squared:  -0.1109 \nF-statistic: 0.7005 on 2 and 4 DF,  p-value: 0.5485\n\n\n\nIm Vergleich zu educ = basic ist der vorhergesagte Wert für var2 bei educ = medium um 7.17 höher.\nIm Vergleich zu educ = basic ist der vorhergesagte Wert für var2 bei educ = high um -1.5 höher.\n\nWir können die Referenzkategorie auch ändern:\n\ndat1$ed_fct <- relevel(dat1$ed_fct,ref = \"medium\")\nm3b <- lm(var2 ~ ed_fct, dat1)\nsummary(m3b)\n\n\nCall:\nlm(formula = var2 ~ ed_fct, data = dat1)\n\nResiduals:\n      1       2       3       4       5       6       7 \n -1.000  -2.500 -10.667  -2.667   2.500   1.000  13.333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)  \n(Intercept)   11.667      5.109   2.284   0.0844 .\ned_fctbasic   -7.167      8.077  -0.887   0.4251  \ned_fcthigh    -8.667      8.077  -1.073   0.3437  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.848 on 4 degrees of freedom\n  (1 Beobachtung als fehlend gelöscht)\nMultiple R-squared:  0.2594,    Adjusted R-squared:  -0.1109 \nF-statistic: 0.7005 on 2 and 4 DF,  p-value: 0.5485\n\n\n\nIm Vergleich zu educ = medium ist der vorhergesagte Wert für var2 bei educ = basic um 7.17 niedriger.\nIm Vergleich zu educ = medium ist der vorhergesagte Wert für var2 bei educ = high um 8.67 niedriger.\n\n\n8.5.1 Übung"
  },
  {
    "objectID": "09_reg.html#mehre-unabhängige-variablen",
    "href": "09_reg.html#mehre-unabhängige-variablen",
    "title": "8  Regressionsmodelle",
    "section": "8.6 Mehre unabhängige Variablen",
    "text": "8.6 Mehre unabhängige Variablen\nUm mehrere unabhängige Variablen in unser Regressionsmodellen aufzunehmen, geben wir sie mit + an:\n\nm4 <- lm(var2 ~ ed_fct  + var1, dat1)\nsummary(m4)\n\n\nCall:\nlm(formula = var2 ~ ed_fct + var1, data = dat1)\n\nResiduals:\n     1      2      3      4      5      6      7 \n 4.258  2.758 -4.824 -2.082 -2.758 -4.258  6.907 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)   2.3187     5.8227   0.398    0.717\ned_fctbasic  -4.8297     6.0381  -0.800    0.482\ned_fcthigh   -8.0824     5.9411  -1.360    0.267\nvar1          1.7527     0.8347   2.100    0.127\n\nResidual standard error: 6.501 on 3 degrees of freedom\n  (1 Beobachtung als fehlend gelöscht)\nMultiple R-squared:  0.7002,    Adjusted R-squared:  0.4003 \nF-statistic: 2.335 on 3 and 3 DF,  p-value: 0.2521"
  },
  {
    "objectID": "09_reg.html#modelplot",
    "href": "09_reg.html#modelplot",
    "title": "8  Regressionsmodelle",
    "section": "8.7 Koeffizientenplots",
    "text": "8.7 Koeffizientenplots\nNeben Regressionstabellen stellt {modelsummary} auch die Funktion modelplot() zur Verfügung, mit denen einfach ein Koeffizientenplot aus einem oder mehreren Modellen erstellt werden kann:\n\nmodelplot(m4)\n\n\n\n\nFür einen Modellvergleich geben wir einfach die Modelle in einer named list an, außerdem können wir mit den üblichen {ggplot2}-Befehlen die Grafik weiter anpassen:\n\nmodelplot(list(\"Modell 1\"=m1,\n               \"Modell 4\"=m4))\n\n\n\n\nMit coef_map können wir Labels für die Koeffizienten vergeben ((Intercept) bekommt keinen Namen und wird daher weggelassen:\n\nmodelplot(list(\"Modell 1\"=m1,\n               \"Modell 4\"=m4),\n          coef_map = c(\"var1\" = \"Name für var1\",\n                       \"ed_fcthigh\"  = \"Höhere Bildung\",\n                       \"ed_fctbasic\" = \"Grundlegende Bildung\"\n                          ))\n\n\n\n\nAußerdem können wir mit den üblichen {ggplot2}-Befehlen die Grafik weiter anpassen:\n\nmodelplot(list(\"Modell 1\"=m1,\n               \"Modell 4\"=m4),\n          coef_map = c(\"var1\" = \"Name für var1\",\n                       \"ed_fcthigh\"  = \"Höhere Bildung\",\n                       \"ed_fctbasic\" = \"Grundlegende\\nBildung\")) + # \\n fügt einen Zeilenumbruch ein\n  geom_vline(aes(xintercept = 0), linetype = \"dashed\", color = \"grey40\") +  # 0-Linie einfügen\n  scale_color_manual(values = c(\"orange\",\"navy\")) +\n  theme_minimal(base_size = 15,base_family = \"mono\") \n\n\n\n\nMit {broom} können wir auch einen data.frame aus den Regressionsergebnissen erstellen und den ggplot ganz selbst erstellen - siehe Anhang.\n\n8.7.1 Übung"
  },
  {
    "objectID": "09_reg.html#übungen",
    "href": "09_reg.html#übungen",
    "title": "8  Regressionsmodelle",
    "section": "8.8 Übungen",
    "text": "8.8 Übungen\n\n8.8.1 Übung 1: Regression\nVerwenden Sie folgenden Subdatensatz der ETB2018:\n\netb_reg1 <- etb18 %>% filter(F518_SUF < 99990,intnr< 200000)\n\n\nErstellen Sie ein Objekt mod1 mit einem linearen Regressionsmodell (lm) mit F518_SUF (Monatsbrutto in EUR) als abhängiger und az (Arbeitszeit in Stunden) als unabhängiger Variable! (siehe hier)\nBetrachten Sie Ergebnisse mod1 - was können Sie zum Zusammenhang zwischen F518_SUF und az erkennen?\nVisualisieren Sie Ihr Regressionsmodell mit {ggplot2}.\nSehen Sie Ausreißer im Scatterplot? Markieren Sie diese mit Hilfe der Variable intnr und geom_text().\n\n\n\n8.8.2 Übung 2\n\nErstellen Sie ein lm()-Modell mod2, welches nur auf den Beobachtungen mit einem Monatseinkommen unter 20.000 EUR beruht.\nErstellen Sie eine Regressionstabelle, welche diese neue Modell mod2 neben das Modell mod1 aus Übung 1 stellt.\nErstellen Sie auch eine grafische Gegenüberstellung der beiden Modelle.\n\n\n\n8.8.3 Übung 3: kat. UVs\n\nErstellen Sie ein Regressionsmodell mit de Einkommen der Befragen (F518_SUF) als abhängiger und dem Ausbildungsabschluss der Befragten m1202 als unabhängiger Variable:\n\n\n\n\n\n\n\n  \n  \n    \n      var\n      .\n      -1\n      1\n      2\n      3\n      4\n    \n  \n  \n    m1202\nHöchster Ausbildungsabschluss\nkeine Angabe\nOhne Berufsabschluss\nduale o. schulische Berufsausbildung/einf.,mittl. Beamte\nAufstiegsfortbildung (Meister, Techniker, kfm. AFB u.ä.)\nFachhochschule, Universität/ geh., höhere Beamte\n  \n  \n  \n\n\n\n\n\nAchten Sie darauf, dass m1202 als factor definiert ist. Vergeben Sie für die Levels 1-4 die Labels ohne, dual/schulisch, Aufstieg, FH/Uni und legen sie den factor als Variable m1202_fct in Ihrem data.frame ab - siehe Code-Hilfe unten:\n\n\n\nCode\netb_reg1$m1202_fct <-  factor(etb_reg1$m1202,levels = 1:4, labels = c(\"ohne\",\"dual\",\"Aufstieg\",\"FH/Uni\"))\n\n\n\nErstellen Sie das Regressionsmodell mit dieser neuen factor-Variable für m1202 als unabhängiger Variablen.\nÄndern Sie die Referenzkategorie auf die Ausprägung Aufstiegsfortbildung (m1202 = 3) und schätzen Sie das Modell erneut."
  },
  {
    "objectID": "09_reg.html#anhang",
    "href": "09_reg.html#anhang",
    "title": "8  Regressionsmodelle",
    "section": "8.9 Anhang",
    "text": "8.9 Anhang\n\ndat1 <- dat1 %>% select(-matches(\"compl\"))\n\n\n8.9.1 Vorhergesagte Werte\nDie vorhergesagten Werte von lm() finden sich unter $fitted.values:\n\nm1$fitted.values\n\n        1         2         3         4         5         6         7         8 \n 1.337972 -0.500994  1.337972  6.854871 10.532803 12.371769 14.210736  6.854871 \n\n\nDiese vorhergesagten Werte entsprechen einfach der Summe aus dem Wert unter Intercept und dem Wert unter var1 multipliziert mit dem jeweiligen Wert für var1.\n\nm1\n\n\nCall:\nlm(formula = var2 ~ var1, data = dat1)\n\nCoefficients:\n(Intercept)         var1  \n     -2.340        1.839  \n\n\nFür die erste Zeile aus dat1 ergibt sich also m1 folgender vorhergesagter Wert: 2.1351+0.5811*1=2.7162\nDie Werte unter fitted.values folgen der Reihenfolge im Datensatz, sodass wir sie einfach als neue Spalte in dat1 ablegen können:\n\ndat1$lm_vorhersagen <- m1$fitted.values\ndat1\n\n  id var1 var2 educ gend  x ed_fct lm_vorhersagen\n1  1    2    2    3    2  2   high       1.337972\n2  2    1    2    1    1  1  basic      -0.500994\n3  3    2    1    2    1  2 medium       1.337972\n4  4    5    9    2    2  4 medium       6.854871\n5  5    7    7    1    1  1  basic      10.532803\n6  6    8    4    3    2 NA   high      12.371769\n7  7    9   25    2    1 NA medium      14.210736\n8  8    5    3   -1    2 NA   <NA>       6.854871\n\n\nDie Grafik zeigt wie Vorhersagen auf Basis von m1 aussehen: Sie entsprechen den Werten auf der blauen Geraden (der sog. Regressionsgeraden) an den jeweiligen Stellen für var1.\n\n\nCode\nggplot(dat1, aes(x = var1, y = var2)) +\n  geom_point(size = 3) +      \n  geom_smooth(method = \"lm\", color = \"darkblue\" , se = FALSE,size =.65) +\n  geom_point(aes(x = var1, y = lm_vorhersagen), color = \"dodgerblue3\", size = 3) +\n  expand_limits(x = c(0,8),y=c(0,8)) \n\n\n\n\n\n\n\n\n\n\n\n8.9.2 Residuen\nDie hellblauen Punkte (also die Vorhersagen von m1) liegen in der Nähe der tatsächlichen Punkte. Trotzdem sind auch die hellblauen Punkte nicht deckungsgleich mit den tatsächlichen Werten. Diese Abweichungen zwischen den vorhergesagten und tatsächlichen Werten werden als Residuen bezeichnet:\n\\[Residuum = beobachteter\\, Wert \\; - \\; vorhergesagter\\,Wert\\]\n\\[\\varepsilon_{\\text{i}} = \\text{y}_{i} - \\hat{y}_{i}\\]\nWir können diese per Hand berechnen als Differenz zwischen dem tatsächlichen und dem vorhergesagten Wert oder einfach unter m1$residuals aufrufen:\n\nm1$residuals\n\n         1          2          3          4          5          6          7 \n 0.6620278  2.5009940 -0.3379722  2.1451292 -3.5328032 -8.3717694 10.7892644 \n         8 \n-3.8548708 \n\n\nAuch die Residuen für lm können wir in dat1 ablegen:\n\ndat1$lm_residuen <- m1$residuals\ndat1\n\n  id var1 var2 educ gend  x ed_fct lm_vorhersagen lm_residuen\n1  1    2    2    3    2  2   high       1.337972   0.6620278\n2  2    1    2    1    1  1  basic      -0.500994   2.5009940\n3  3    2    1    2    1  2 medium       1.337972  -0.3379722\n4  4    5    9    2    2  4 medium       6.854871   2.1451292\n5  5    7    7    1    1  1  basic      10.532803  -3.5328032\n6  6    8    4    3    2 NA   high      12.371769  -8.3717694\n7  7    9   25    2    1 NA medium      14.210736  10.7892644\n8  8    5    3   -1    2 NA   <NA>       6.854871  -3.8548708\n\n\nHier sind die Residuen für lm hellblau eingezeichnet:\n\n\nCode\nggplot(dat1, aes(x = var1, y = var2)) + \n  geom_smooth(method = \"lm\", color = \"darkblue\" , se = FALSE,size =.65) +\n  geom_segment(aes(x = var1, xend = var1, y = var2, yend = lm_vorhersagen), color = \"dodgerblue3\", size = .65, linetype = 1) +\n  geom_point(size = 3) +\n  geom_point(aes(x = var1, y = lm_vorhersagen), color = \"dodgerblue3\", size = 3) +\n  expand_limits(x = c(0,8),y=c(0,8)) \n\n\n\n\n\n\n\n\n\n\n\n8.9.3 Annahmen checken\nmodel dashboard\n\ninstall.packages(\"performance\")\n\n\nlibrary(performance)\n\nmodel_test <- check_model(m4)\nplot(model_test)\n\n\n\n\n\n\n8.9.4 Test auf Normalverteilung der Residuen\nGrafische Überprüfung: Q-Q-Plot\n\nlibrary(ggfortify)\nautoplot(m1,which = 2)\n\n\n\n\n\n\n\n\n\n\nÜberprüfen lässt sich die NV-Annahme mit dem Shapiro-Wilk-Test & shapiro.test(). Dieser testet die \\(H_0\\): “Die Residuen sind normalverteilt” gegen die \\(H_A\\): “Die Residuen weichen signifikant von der Normalverteilung ab”\n\nshapiro.test(m1$residuals) \n\n\n    Shapiro-Wilk normality test\n\ndata:  m1$residuals\nW = 0.95346, p-value = 0.746\n\n\n\n\n8.9.5 Test auf Homoskedastizität\nHomoskedastizität ist gegeben, wenn die vorhergesagten Werte über den kompletten Wertebereich (ungefähr) gleich weit von den tatsächlichen Werten (m1\\$fitted.values) entfernt sind. Auch hier gibt es eine graphische Überprüfungsmethode sowie einen Test. Zur graphischen Überprüfung werden die vorhergesagten Werten und die Residuen als Scatterplot dargestellt. Auch hier hilft uns autoplot():\n\nautoplot(m1, which = 1)\n\n\n\n\n\n\n\n\n\n\nDer dazugehörige Test ist der Breusch-Pagan-Test. Dieser testet die \\(H_0\\) “Homoskedastizität” gegen die \\(H_A\\) “Heteroskedastizität”, der p-Wert gibt also an mit welcher Irrtumswahrscheinlichkeit wir die Homoskedastizitäts-Annahme verwerfen müssen. In R können wir dafür bptest aus dem Paket lmtest verwenden:\n\ninstall.packages(\"lmtest\")\n\n\nlibrary(lmtest)\nbptest(m3)\n\n\n    studentized Breusch-Pagan test\n\ndata:  m3\nBP = 3.6069, df = 2, p-value = 0.1647\n\n\n\n\n8.9.6 Test auf Multikollinearität\n\ninstall.packages(\"car\")\n\n\n# library(car)\netb18x <- haven::read_dta(\"./data/BIBBBAuA_2018_suf1.0.dta\",n_max = 300)  %>% filter(F518_SUF < 99998, zpalter < 100)\nmox <- lm(F518_SUF ~ zpalter + az,data=etb18x)\ncar::vif(mox)\n\n zpalter       az \n1.000688 1.000688 \n\n\nInterpretation:\n\n\nEin verbreiteter Schwellenwert des VIF beträgt 10,00. Werte des VIF über 10 deuten auf ein schwerwiegendes Multikollinearitätsproblem, oftmals werden Gegenmaßnahmen schon ab einem strikteren Grenzwert von ca. 5,00 empfohlen. Im konkreten Beispiel ist für alle UVs also nach beiden Grenzwerten alles in Ordnung.\nBeim Vorliegen von Mulitkollinearität gibt es mehrere Möglichkeiten, das zu beheben: Wir können eine oder mehrere unabh. Variablen aus dem Modell ausschließen. Das ist letztlich eine inhaltliche Frage und kann nicht mit einem Standardrezept gelöst werden. Alternativ können wir die kollinearen unabh. Variablen zu Indexvariablen zusammenfassen. Wir würden also einen gemeinsamen Index, bspw. der Mittelwert über die jeweiligen unabh. Variablen, erstellen.\n\n\n\n8.9.7 Regressionsmodelle vergleichen\nMit dem Paket {performance} können wir auch einen umfassenden Modellvergleich bekommen:\n\ninstall.packages(\"performance\")\n\n\nlibrary(performance)\ncompare_performance(m1,m4,metrics = c(\"R2\",\"R2_adj\"))\n\nWarning: When comparing models, please note that probably not all models were fit\n  from same data.\n\n\n# Comparison of Model Performance Indices\n\nName | Model |    R2 | R2 (adj.)\n--------------------------------\nm1   |    lm | 0.486 |     0.400\nm4   |    lm | 0.700 |     0.400\n\n\n\n\n8.9.8 Individuellere Koeffizientenplots mit {broom}\nmodelplot() bietet eine schnelle Art, Koeffizientenplots zu erstellen, allerdings verwende ich häufig {broom}. Mit broom::tidy(..., conf.int = TRUE) bekommen wir einen data.frame mit den Ergebnissen des Regressionsmodells, die wir bspw. in einem {ggplot2} weiterverarbeiten können - wenn uns die Standardlösung von modelplot() nicht weiterhilft/gefällt:\n\nlibrary(broom) ## schon geladen als Teil des tidyverse\ntidy(m3, conf.int = TRUE)\n\n# A tibble: 3 × 7\n  term         estimate std.error statistic p.value conf.low conf.high\n  <chr>           <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl>\n1 (Intercept)      4.5       6.26     0.719   0.512    -12.9      21.9\n2 ed_fctmedium     7.17      8.08     0.887   0.425    -15.3      29.6\n3 ed_fcthigh      -1.5       8.85    -0.170   0.874    -26.1      23.1\n\ntidy(m3, conf.int = TRUE) %>% \n  mutate(term = str_replace(term, \"ed_fct\", \"Education: \")) %>% \n  ggplot(aes(y = term, x = estimate)) +\n  geom_vline(aes(xintercept = 0), linetype = \"dashed\", color = \"navy\") +\n  geom_errorbarh(aes(xmin = conf.low, xmax  = conf.high), height = .1) + \n  geom_point(color = \"orange\", shape = 17,size = 3) +\n  theme_minimal(base_size = 16)"
  },
  {
    "objectID": "09_reg2.html",
    "href": "09_reg2.html",
    "title": "9  Regressionsmodelle: Erweiterungen",
    "section": "",
    "text": "Nach den basics für Regressionsmodelle sehen wir uns in diesem Kapitel einige hilfreiche Erweiterungen von Regressionsmodellen in R an."
  },
  {
    "objectID": "09_reg2.html#nur-vollständige-zeilen-behalten",
    "href": "09_reg2.html#nur-vollständige-zeilen-behalten",
    "title": "9  Regressionsmodelle: Erweiterungen",
    "section": "9.1 Nur vollständige Zeilen behalten",
    "text": "9.1 Nur vollständige Zeilen behalten\nWenn wir die beiden Modelle m1 und m3 vergleichen, sehen wir unterschiedliche Fallzahlen:\n\nm1 <- lm(var2~ var1, data = dat1)  \nm4 <- lm(var2 ~ ed_fct  + var1, dat1)\nmodelsummary(list(\"m1\"=m1,\"m4\"=m4),gof_omit = \"IC|RM|Log|F\")\n\n\n\n \n  \n      \n    m1 \n    m4 \n  \n \n\n  \n    (Intercept) \n    −2.340 \n    −2.511 \n  \n  \n     \n    (4.345) \n    (5.681) \n  \n  \n    var1 \n    1.839 \n    1.753 \n  \n  \n     \n    (0.773) \n    (0.835) \n  \n  \n    ed_fctmedium \n     \n    4.830 \n  \n  \n     \n     \n    (6.038) \n  \n  \n    ed_fcthigh \n     \n    −3.253 \n  \n  \n     \n     \n    (6.554) \n  \n  \n    Num.Obs. \n    8 \n    7 \n  \n  \n    R2 \n    0.486 \n    0.700 \n  \n  \n    R2 Adj. \n    0.400 \n    0.400 \n  \n\n\n\n\n\nEs zeigt sich, dass in Modell m4 mit edu_fct 1 Fall verloren geht. Woran liegt das? Dazu lohnt sich ein Blick in die Daten:\n\ndat1\n\n  id var1 var2 educ gend  x ed_fct\n1  1    2    2    3    2  2   high\n2  2    1    2    1    1  1  basic\n3  3    2    1    2    1  2 medium\n4  4    5    9    2    2  4 medium\n5  5    7    7    1    1  1  basic\n6  6    8    4    3    2 NA   high\n7  7    9   25    2    1 NA medium\n8  8    5    3   -1    2 NA   <NA>\n\n\nDie Angabe für ed_fct fehlt in für id = 8.\nUm die Modelle zu vergleichen sollten wir also nur die Zeilen verwenden, für die auch die Werte für ed_fct vorliegen. Hier können wir diese Zeilen per Hand auswählen (und id=8 ausschließen), in größeren Datensätzen ist das aber mühsam.\n\n9.1.1 complete.cases()\nHier hilft uns complete.cases(). Diese Funktion erstellt eine logische Variable, welche ein TRUE für alle vollständigen Fälle (also ohne ein NA). Unvollständige Fälle werden mit einem FALSE versehen. Dazu geben wir an, welche Variablen jeweils für diese Betrachtung berücksichtigt werden sollen und legen die Variable einfach im Datensatz als neue Spalte an. Für Modell 1 ist ein Fall complete, wenn var2 und var1 vorliegen. Wir wählen also mit select() die relevanten Variablen aus und wenden complete.cases auf diese Auswahl an:\n\ndat1 %>% select(var1,var2) %>% complete.cases(.) \n\n[1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n\ndat1$compl_m1 <- dat1 %>% select(var1,var2) %>% complete.cases(.) \ndat1\n\n  id var1 var2 educ gend  x ed_fct compl_m1\n1  1    2    2    3    2  2   high     TRUE\n2  2    1    2    1    1  1  basic     TRUE\n3  3    2    1    2    1  2 medium     TRUE\n4  4    5    9    2    2  4 medium     TRUE\n5  5    7    7    1    1  1  basic     TRUE\n6  6    8    4    3    2 NA   high     TRUE\n7  7    9   25    2    1 NA medium     TRUE\n8  8    5    3   -1    2 NA   <NA>     TRUE\n\n\n\n\n\n\n\n\ncomplete.cases() alleine sucht in allen Variablen nach NA\n\n\n\n\n\nAchtung: wenn wir keine Variablen angeben, werden NA aus allen Variablen berücksichtigt, hier also auch die NA aus x - die uns hier nicht interessieren:\n\ndat1 %>% complete.cases(.) \n\n[1]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE\n\ndat1$compl <- dat1 %>% complete.cases(.) \ndat1\n\n  id var1 var2 educ gend  x ed_fct compl_m1 compl\n1  1    2    2    3    2  2   high     TRUE  TRUE\n2  2    1    2    1    1  1  basic     TRUE  TRUE\n3  3    2    1    2    1  2 medium     TRUE  TRUE\n4  4    5    9    2    2  4 medium     TRUE  TRUE\n5  5    7    7    1    1  1  basic     TRUE  TRUE\n6  6    8    4    3    2 NA   high     TRUE FALSE\n7  7    9   25    2    1 NA medium     TRUE FALSE\n8  8    5    3   -1    2 NA   <NA>     TRUE FALSE\n\n\n\n\n\n\n\n\n…das gleiche machen wir für Modell m4, welches neben var2 und var1 ja auch noch ed_fct enthält:\n\ndat1$compl_m4 <- dat1 %>% select(var1,var2,ed_fct) %>% complete.cases(.)\n\nSo sieht das dann im Datensatz aus:\n\ndat1\n\n  id var1 var2 educ gend  x ed_fct compl_m1 compl_m4\n1  1    2    2    3    2  2   high     TRUE     TRUE\n2  2    1    2    1    1  1  basic     TRUE     TRUE\n3  3    2    1    2    1  2 medium     TRUE     TRUE\n4  4    5    9    2    2  4 medium     TRUE     TRUE\n5  5    7    7    1    1  1  basic     TRUE     TRUE\n6  6    8    4    3    2 NA   high     TRUE     TRUE\n7  7    9   25    2    1 NA medium     TRUE     TRUE\n8  8    5    3   -1    2 NA   <NA>     TRUE    FALSE\n\n\n\n\n9.1.2 Fälle mit missings finden\nJetzt können wir nach diesen Variablen filtern und uns diese Fälle genauer ansehen. Dazu filtern wir nach den Fällen, die zwar in m1 enthalten (also compl_m1 = TRUE) sind, aber nicht in m4 (compl_m4 = FALSE):\n\ndat1 %>% filter(compl_m1 == T & compl_m4 == F) \n\n  id var1 var2 educ gend  x ed_fct compl_m1 compl_m4\n1  8    5    3   -1    2 NA   <NA>     TRUE    FALSE\n\n\n\n\n9.1.3 Modelle nur mit vollständigen Fällen berechnen\nAußerdem können wir jetzt auch das Modell m1 so erstellen, dass wir nur die Fälle miteinbeziehen, die auch in Modell2 berücksichtigt werden:\n\nm1_m4vars <- lm(var2 ~ var1     , data = filter(dat1,compl_m4 == T))\nmodelsummary(list(\"m1\"=m1,\"m1 mit m4vars\"=m1_m4vars,\"m4\"=m4),gof_omit = \"IC|RM|Log|F\")\n\n\n\n \n  \n      \n    m1 \n    m1 mit m4vars \n    m4 \n  \n \n\n  \n    (Intercept) \n    −2.340 \n    −1.832 \n    −2.511 \n  \n  \n     \n    (4.345) \n    (4.646) \n    (5.681) \n  \n  \n    var1 \n    1.839 \n    1.848 \n    1.753 \n  \n  \n     \n    (0.773) \n    (0.814) \n    (0.835) \n  \n  \n    ed_fctmedium \n     \n     \n    4.830 \n  \n  \n     \n     \n     \n    (6.038) \n  \n  \n    ed_fcthigh \n     \n     \n    −3.253 \n  \n  \n     \n     \n     \n    (6.554) \n  \n  \n    Num.Obs. \n    8 \n    7 \n    7 \n  \n  \n    R2 \n    0.486 \n    0.508 \n    0.700 \n  \n  \n    R2 Adj. \n    0.400 \n    0.409 \n    0.400 \n  \n\n\n\n\n\nJetzt haben wir also in m1 mit m4vars und m4 die gleiche Fallzahl und können so die Ergebnisse direkt miteinander vergleichen."
  },
  {
    "objectID": "09_reg2.html#interaktionen",
    "href": "09_reg2.html#interaktionen",
    "title": "9  Regressionsmodelle: Erweiterungen",
    "section": "9.2 Interaktionen",
    "text": "9.2 Interaktionen\nInteraktionen zwischen zwei Variablen können wir mit * berechnen:\n\ndat1$g_fct <- factor(dat1$gend,levels = 1:2,\n                     labels = c(\"women\",\"men\"))\nm5 <- lm(var2 ~ var1 * g_fct, dat1)\nsummary(m5)\n\n\nCall:\nlm(formula = var2 ~ var1 * g_fct, data = dat1)\n\nResiduals:\n      1       2       3       4       5       6       7       8 \n-1.5000  2.6145 -0.8827  4.5000 -7.3687 -1.5000  5.6369 -1.5000 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)  \n(Intercept)    -3.1117     4.7702  -0.652   0.5498  \nvar1            2.4972     0.8211   3.041   0.0384 *\ng_fctmen        5.9451     8.4973   0.700   0.5227  \nvar1:g_fctmen  -2.1639     1.5331  -1.411   0.2310  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.493 on 4 degrees of freedom\nMultiple R-squared:  0.7244,    Adjusted R-squared:  0.5177 \nF-statistic: 3.504 on 3 and 4 DF,  p-value: 0.1286\n\n\nInteraktionen sollten immer visualisiert werden. Dafür ist {ggeffects} eine große Hilfe:\n\ninstall.packages(\"ggeffects\")\n\n\nlibrary(ggeffects)\nggpredict(m5, terms = c(\"var1\",\"g_fct[women,men]\")) %>% plot()\n\n\n\n# oder nebeneinander:\nggpredict(m5, terms = c(\"var1\",\"g_fct[women,men]\")) %>% plot(facet=TRUE)\n\n\n\n\nWir können diese Darstellung mit den bekannten {ggplot2}-Befehlen verändern:\n\nggpredict(m5, terms = c(\"var1\",\"g_fct[women,men]\")) %>% plot() + \n  scale_color_viridis_d(breaks = c(\"women\",\"men\"),labels=c(\"Frauen\",\"Männer\")) +\n  scale_fill_viridis_d(breaks = c(\"women\",\"men\"),labels=c(\"Frauen\",\"Männer\")) +\n  labs(title = \"Vorhergesagte Werte für var2\",\n       color = \"Gender\",\n       x = \"Werte für var1\",\n       y = \"Vorhergesagte Werte für var1\")\n\nScale for 'colour' is already present. Adding another scale for 'colour',\nwhich will replace the existing scale."
  },
  {
    "objectID": "09_reg2.html#quadratische-terme-polynome",
    "href": "09_reg2.html#quadratische-terme-polynome",
    "title": "9  Regressionsmodelle: Erweiterungen",
    "section": "9.3 Quadratische Terme & Polynome",
    "text": "9.3 Quadratische Terme & Polynome\n\nm6 <- lm(var2 ~ var1 + I(var1^2), dat1 %>% filter(id != 7))\nsummary(m6)\n\n\nCall:\nlm(formula = var2 ~ var1 + I(var1^2), data = dat1 %>% filter(id != \n    7))\n\nResiduals:\n      1       2       3       4       5       6       7 \n-0.5443  1.4334 -1.5443  3.2043  1.2713 -1.0248 -2.7957 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)  -1.8580     3.4066  -0.545    0.614\nvar1          2.6481     1.9083   1.388    0.238\nI(var1^2)    -0.2235     0.2110  -1.059    0.349\n\nResidual standard error: 2.524 on 4 degrees of freedom\nMultiple R-squared:  0.5099,    Adjusted R-squared:  0.2648 \nF-statistic: 2.081 on 2 and 4 DF,  p-value: 0.2402\n\n\n\nggpredict(m6, terms = c(\"var1\")) %>% plot()"
  },
  {
    "objectID": "09_reg2.html#gewichtetes-regressionsmodell",
    "href": "09_reg2.html#gewichtetes-regressionsmodell",
    "title": "9  Regressionsmodelle: Erweiterungen",
    "section": "9.4 Gewichtetes Regressionsmodell",
    "text": "9.4 Gewichtetes Regressionsmodell\n\nlibrary(survey)\netb18 <- haven::read_dta(\"./data/BIBBBAuA_2018_suf1.0.dta\") \n\netb18x <- etb18 %>% filter(F518_SUF < 99998, zpalter < 100)\nmodx <- lm(F518_SUF ~ zpalter + I(zpalter^2),data=etb18x)\n\netb18_weighted <- svydesign(id      = ~intnr,\n                            weights = ~gew2018,\n                            data    = etb18x)\n# family = gaussian() bekommen wir ein lineares Regressionsmodell, wie bei lm() - mit gewichtet\nsurvey_modx <- svyglm(F518_SUF ~ zpalter + I(zpalter^2), \n                    family = gaussian(), data = etb18,design = etb18_weighted)\n\nmodelsummary(list(\"lm()\"=modx,\"svyglm()\"= survey_modx),gof_omit = \"RM|IC|Log\")\n\n\n\n \n  \n      \n    lm() \n    svyglm() \n  \n \n\n  \n    (Intercept) \n    586.343 \n    118.307 \n  \n  \n     \n    (381.240) \n    (338.854) \n  \n  \n    zpalter \n    110.543 \n    121.639 \n  \n  \n     \n    (17.556) \n    (17.635) \n  \n  \n    I(zpalter^2) \n    −0.959 \n    −1.116 \n  \n  \n     \n    (0.194) \n    (0.213) \n  \n  \n    Num.Obs. \n    16543 \n    16543 \n  \n  \n    R2 \n    0.008 \n    0.013 \n  \n  \n    R2 Adj. \n    0.008 \n    0.013 \n  \n  \n    F \n    64.956 \n    109.810"
  },
  {
    "objectID": "09_reg2.html#weitere-beispiele-mit-starwars",
    "href": "09_reg2.html#weitere-beispiele-mit-starwars",
    "title": "9  Regressionsmodelle: Erweiterungen",
    "section": "9.5 Weitere Beispiele mit starwars",
    "text": "9.5 Weitere Beispiele mit starwars\nDie folgenden Beispiele basieren vornehmlich auf dem starwars-Datensatz aus {dplyr}, hier ein kurzer Blick in die Daten:\n\nstarwars %>% select(name,height,mass,hair_color,gender)\n\n# A tibble: 87 × 5\n   name               height  mass hair_color    gender   \n   <chr>               <int> <dbl> <chr>         <chr>    \n 1 Luke Skywalker        172    77 blond         masculine\n 2 C-3PO                 167    75 <NA>          masculine\n 3 R2-D2                  96    32 <NA>          masculine\n 4 Darth Vader           202   136 none          masculine\n 5 Leia Organa           150    49 brown         feminine \n 6 Owen Lars             178   120 brown, grey   masculine\n 7 Beru Whitesun lars    165    75 brown         feminine \n 8 R5-D4                  97    32 <NA>          masculine\n 9 Biggs Darklighter     183    84 black         masculine\n10 Obi-Wan Kenobi        182    77 auburn, white masculine\n# … with 77 more rows\n\n\nUnser Beispiel ist ein simples: der Zusammenhang zwischen Größe und Gewicht der Star Wars Helden:\n\nmod1 <- lm(mass ~ height, data = starwars)"
  },
  {
    "objectID": "09_reg2.html#robuste-standardfehler",
    "href": "09_reg2.html#robuste-standardfehler",
    "title": "9  Regressionsmodelle: Erweiterungen",
    "section": "9.6 “Robuste” Standardfehler",
    "text": "9.6 “Robuste” Standardfehler\nHäufig müssen die Standardfehler an Verstöße gegen die allgemeinen Annahmen (Homoskedastizität usw.) angepasst werden.\nDie gute Nachricht ist, dass R eine ganze Reihe an Möglichkeiten bietet, Standard-Fehler zu korrigieren. Unter anderem mit {sandwich} oder {estimatr}.\nEine sehr einfache Variante ist die Korrektur von Standardfehlern in {modelsummary}, die wir uns etwas genauer ansehen:\nWir können sog. heteroskedasticity-consistent (HC) “robuste” Standardfehler mit der vcov-Option HC in modelsummary() anfordern. Die Hilfe-Seite für {modelsummary} bietet eine Liste mit allen Optionen.\nEine Option ist auch stata, um Ergebnisse aus Statas , robust zu replizieren. Hier mehr zu den Hintergründen und Unterschieden.\n\nlibrary(modelsummary)\nmodelsummary(list(mod1,mod1,mod1,mod1),vcov = c(\"classical\",\"HC\",\"HC2\",\"stata\"),gof_omit = \"RM|IC|Log\")\n\n\n\n \n  \n      \n    Model 1 \n    Model 2 \n    Model 3 \n    Model 4 \n  \n \n\n  \n    (Intercept) \n    −13.810 \n    −13.810 \n    −13.810 \n    −13.810 \n  \n  \n     \n    (111.155) \n    (22.963) \n    (23.456) \n    (23.362) \n  \n  \n    height \n    0.639 \n    0.639 \n    0.639 \n    0.639 \n  \n  \n     \n    (0.626) \n    (0.085) \n    (0.088) \n    (0.086) \n  \n  \n    Num.Obs. \n    59 \n    59 \n    59 \n    59 \n  \n  \n    R2 \n    0.018 \n    0.018 \n    0.018 \n    0.018 \n  \n  \n    R2 Adj. \n    0.001 \n    0.001 \n    0.001 \n    0.001 \n  \n  \n    F \n    1.040 \n    56.856 \n    52.753 \n    54.928 \n  \n  \n    Std.Errors \n    Classical \n    HC \n    HC2 \n    Stata"
  },
  {
    "objectID": "09_reg2.html#fixed-effects-modelle-mit-fixest",
    "href": "09_reg2.html#fixed-effects-modelle-mit-fixest",
    "title": "9  Regressionsmodelle: Erweiterungen",
    "section": "9.7 Fixed effects Modelle mit {fixest}",
    "text": "9.7 Fixed effects Modelle mit {fixest}\n\ninstall.packages(\"fixest\")\n\n{fixest}) ist zwar noch relativ neu, aber bietet eine große Auswahl an Möglichkeiten: logitische Modelle, mehr-dimensionale Fixed Effects, Multiway clustering, … Und es ist sehr schnell, bspw. schneller als Statas reghdfe. Für mehr Details empfiehlt sich die Vignette.\nDie zentrale Funktion zur Schätzung linearer FE-Regressionsmodelle ist feols() - sie funktioniert ganz ähnlich zu lm(). Auch hier geben wir wieder eine Formel nach dem Schema abhängige Variabe ~ unabhängige Variable(n) an. Wir fügen lediglich mit | die Variable hinzu, welche die FEs festlegt:\n\nlibrary(fixest)\nfe_mod1 <- feols(mass ~ height | species, data = starwars)\nfe_mod1\n\nOLS estimation, Dep. Var.: mass\nObservations: 58 \nFixed-effects: species: 31\nStandard-errors: Clustered (species) \n       Estimate Std. Error t value  Pr(>|t|)    \nheight 0.974876   0.044291 22.0105 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 9.69063     Adj. R2: 0.99282 \n                Within R2: 0.662493\n\n\n{fixest} clustert automatisch die Standardfehler entlang der FE-Variable (hier also species). Wenn wir das mal nicuth möchten, können wir mit der se-Option = \"standard\" ungeclusterte SE anfordern:\n\nsummary(fe_mod1, se = 'standard')\n\nOLS estimation, Dep. Var.: mass\nObservations: 58 \nFixed-effects: species: 31\nStandard-errors: IID \n       Estimate Std. Error t value   Pr(>|t|)    \nheight 0.974876   0.136463  7.1439 1.3797e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 9.69063     Adj. R2: 0.99282 \n                Within R2: 0.662493\n\nsummary(fe_mod1, cluster = ~species)\n\nOLS estimation, Dep. Var.: mass\nObservations: 58 \nFixed-effects: species: 31\nStandard-errors: Clustered (species) \n       Estimate Std. Error t value  Pr(>|t|)    \nheight 0.974876   0.044291 22.0105 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 9.69063     Adj. R2: 0.99282 \n                Within R2: 0.662493\n\n\n{modelsummary} zeigt die geclusterten SE:\n\nmodelsummary(list(fe_mod1),gof_omit = \"R|IC|Log|F\")\n\n\n\n \n  \n      \n    Model 1 \n  \n \n\n  \n    height \n    0.975 \n  \n  \n     \n    (0.044) \n  \n  \n    Num.Obs. \n    58 \n  \n  \n    Std.Errors \n    by: species"
  },
  {
    "objectID": "09_reg2.html#mehrebenenmodelle-mit-lme4",
    "href": "09_reg2.html#mehrebenenmodelle-mit-lme4",
    "title": "9  Regressionsmodelle: Erweiterungen",
    "section": "9.8 Mehrebenenmodelle mit {lme4}",
    "text": "9.8 Mehrebenenmodelle mit {lme4}\nMit lmer() können wir ein Random Intercept Modell berechnen, indem wir mit ( 1 | species) angeben, dass für species jeweils ine eigenes Random Intercept berechnet werden soll:\n\nlibrary(lme4)\nml_m3 <- lmer(mass ~ height + ( 1 | species), data=starwars)\n\nmodelsummary(list(ml_m3),gof_omit = \"R|IC|Log|F\")\n\n\n\n \n  \n      \n    Model 1 \n  \n \n\n  \n    (Intercept) \n    −52.698 \n  \n  \n     \n    (47.579) \n  \n  \n    height \n    0.969 \n  \n  \n     \n    (0.135) \n  \n  \n    SD (Intercept species) \n    231.270 \n  \n  \n    SD (Observations) \n    14.472 \n  \n  \n    Num.Obs. \n    58 \n  \n\n\n\n\n\nMehr zu Mehrebenenmodellen und {lme4} in Blogposts von Rense Nieuwenhuis und Tristan Mahr."
  },
  {
    "objectID": "10_log_reg.html",
    "href": "10_log_reg.html",
    "title": "10  Logistische Regressionsmodelle",
    "section": "",
    "text": "In diesem Kapitel widmen wir uns dem Fall einer binären abhängigen Variable/Dummyvariable. Für solche Fälle sind logistische Regressionsmodelle gebräuchlich, die sich in Ihrer Anwendung etwas von ‘normalen’, linearen Regressionsmodellen unterscheiden. Kern dieses Unterschieds ist die Link-Funktion, welche die Koeffizienten etwas schwerer interpretierbar macht - daher haben sich sog. marginal effects als Darstellungsform für Ergebnisse logistischer Regressionen etabliert. In R steht uns dafür das Paket {marginaleffects}, welches sich in der Anwendung sehr dem margins-Befehl in Stata ähnelt.\nBisher hatten wir immer Regressionsmodelle betrachtet, die eine metrisch skalierte abhängige Variable hatten.1 Aber gerade Individualmerkmale sind nur selten metrisch skaliert, z.B. Erwerbstatus, Familienstand, Geschlecht, Elternstand, … Ein lineares OLS-Regressionsmodell wie wir es bisher kennen gelernt haben, hilft uns hier nicht weiter. Schauen wir uns beispielsweise die Arbeitsplatzsituation der männlichen Befragten in der ETB 2018 an (F605)2 :\nArbeiten Sie mehr als die Hälfte Ihrer Arbeitszeit im Freien?\nDie 1 steht dabei jeweils für “ja”, die 2 für “nein”. Wir verändern die Codierung aber so, dass die “nein”-Antworten mit 0 versehen werden. Die neue Variable nennen wir outside. Außerdem teilen wir F518_SUF durch 100 und legen die so erstellte Variable “Einkommen in 100EUR” in inc100 ab, um die Nachkommastellen des Koeffizienten zu reduzieren:"
  },
  {
    "objectID": "10_log_reg.html#logmod",
    "href": "10_log_reg.html#logmod",
    "title": "10  Logistische Regressionsmodelle",
    "section": "10.1 Das logistische Regressionsmodell",
    "text": "10.1 Das logistische Regressionsmodell\nSomit sieht unser logistisches Regressionsmodell in der allgemeinen Schreibweise wie folgt aus:\n\\[\\begin{equation*}\n\\widehat{Logit(outside=1)} = \\widehat{ln\\left(\\frac{P(outside=1)}{1-P(outside=1)}\\right)} = \\hat\\beta0 + \\hat{\\beta1}\\times \\texttt{inc100}\n\\end{equation*}\\]\nIn R können wir ein solches Modell mit glm() und der Option family=\"binomial\" berechnen:3\n\nm2 <- glm(outside ~ inc100, family = \"binomial\", data = m_etb18)\nsummary(m2)\n\n\nCall:\nglm(formula = outside ~ inc100, family = \"binomial\", data = m_etb18)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.9580  -0.6005  -0.4841  -0.3042   5.5160  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -0.54045    0.07285  -7.419 1.18e-13 ***\ninc100      -0.03861    0.00218 -17.716  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 6643.5  on 8431  degrees of freedom\nResidual deviance: 6209.8  on 8430  degrees of freedom\nAIC: 6213.8\n\nNumber of Fisher Scoring iterations: 6\n\n\nDie Interpretation der \\(\\beta\\) aus einem logistischen Regressionsmodell bezieht sich also auf die Logits (die logarithmierten Odds):\n\nEs besteht ein am 0,001-Niveau signifikanter Zusammenhang zwischen dem Einkommen und der Wahrscheinlichkeit, im Freien zu arbeiten. Mit einem um 100 Euro höheren Einkommen gehen um 0.038612 niedrigere Logits einher, mehr als die Hälfte Ihrer Arbeitszeit im Freien zu arbeiten."
  },
  {
    "objectID": "10_log_reg.html#average-marginal-effects",
    "href": "10_log_reg.html#average-marginal-effects",
    "title": "10  Logistische Regressionsmodelle",
    "section": "10.2 average marginal effects",
    "text": "10.2 average marginal effects\nLogits sind aber sehr unhandlich - wie verändert sich jetzt aber die Wahrscheinlichkeit für \\(\\texttt{outside} = 1\\) mit inc100? Hier haben wir das Problem, dass die Ableitung der “rücktransformierten Funktion” nicht so einfach ist wie im Fall der OLS. Verändern wir nämlich auch die Regressionsgleichung von oben4 mit exp() und \\(p=\\frac{Odds}{1+Odds}\\), so landen wir bei\n\\[\\begin{equation*}\n\\widehat{P(outside=1)} = \\frac{e^{\\hat\\beta0+\\hat\\beta1 \\times \\texttt{inc100}}}{1+e^{\\hat\\beta0+\\hat{\\beta1}\\times \\texttt{inc100}}}\n\\end{equation*}\\]\nDiesen Ausdruck müssten wir nach inc100 ableiten, um eine Antwort zu bekommen um wieviel sich die vorhergesagte Wahrscheinlichkeit für \\(\\texttt{outside} = 1\\) mit einem um einen Euro höheren Befragteneinkommen verändert. Durch die Tatsache dass inc hier im Exponenten der e-Funktion und sowohl im Dividenden als auch Divisor (“oben und unten”) steht, wird die Ableitung hier aber deutlich komplizierter als das in den bisherigen lm()-Modellen der Fall war. Für uns ist an dieser Stelle aber nur wichtig, dass wir für die Berechnung der Veränderung der vorhergesagten Wahrscheinlichkeiten die sog. marginalen Effekte aus dem Paket {marginaleffects} brauchen. Darin findet sich der Befehl avg_slopes(), welcher uns erlaubt ein \\(\\beta\\) zwischen dem Einkommen und der Wahrscheinlichkeit für \\(\\texttt{outside} = 1\\) zu berechnen. Dieses wird auch als average marginal effect bezeichnet, da sie den durchschnittlichen marginalen Effekt der betrachteten unabhängigen Variable auf die abhängige Variable wiedergeben.\n\ninstall.packages(\"marginaleffects\") # nur einmal nötig\nlibrary(marginaleffects)\n\n\navg_slopes(m2, by = TRUE)\n\n\n   Term Estimate Std. Error     z Pr(>|z|)    2.5 %   97.5 %\n inc100 -0.00426    0.00024 -17.7   <0.001 -0.00473 -0.00379\n\nColumns: term, estimate, std.error, statistic, p.value, conf.low, conf.high \n\n\n\n\n\n\nMit einem um 100 Euro (inc100 ist in 100 EUR gemessen) höheren Einkommen geht im Durchschnitt eine um 0.00426 (0.42632 Prozentpunkte) geringere Wahrscheinlichkeit einher, mehr als die Hälfte der Arbeitszeit im Freien zu arbeiten."
  },
  {
    "objectID": "10_log_reg.html#übung-1",
    "href": "10_log_reg.html#übung-1",
    "title": "10  Logistische Regressionsmodelle",
    "section": "10.3 Übung 1",
    "text": "10.3 Übung 1"
  },
  {
    "objectID": "10_log_reg.html#feglm",
    "href": "10_log_reg.html#feglm",
    "title": "10  Logistische Regressionsmodelle",
    "section": "10.4 Fixed effects logistische Regression mit {fixest}",
    "text": "10.4 Fixed effects logistische Regression mit {fixest}\nMit feglm() lassen sich auch logistische FE-Modelle schätzen:\n\nlibrary(fixest)\nm_etb18 <-\n  m_etb18 %>%\n  mutate(m1202_fct = factor(m1202,levels = c(-1,1:4),\n                            labels = names(attributes(m1202)$labels) %>%\n                              substr(.,1,5) %>% str_squish()),\n         m1202_fct = fct_relevel(m1202_fct,\"Ohne\"))\n\nfeglm(outside ~ m1202_fct + zpalter |Bula, data = m_etb18, family = binomial)\n\nGLM estimation, family = binomial, Dep. Var.: outside\nObservations: 8,432 \nFixed-effects: Bula: 16\nStandard-errors: Clustered (Bula) \n                Estimate Std. Error    t value   Pr(>|t|)    \nm1202_fctkeine  0.652523   0.373049   1.749164 8.0263e-02 .  \nm1202_fctduale -0.180213   0.115800  -1.556234 1.1965e-01    \nm1202_fctAufst -0.623841   0.155694  -4.006834 6.1538e-05 ***\nm1202_fctFachh -1.935948   0.121357 -15.952541  < 2.2e-16 ***\nzpalter        -0.001068   0.003650  -0.292556 7.6986e-01    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nLog-Likelihood: -3,023.8   Adj. Pseudo R2: 0.083676\n           BIC:  6,237.4     Squared Cor.: 0.06534 \n\nfe_log1 <- feglm(outside ~ m1202_fct + zpalter|Bula, data = m_etb18, family = binomial)\navg_slopes(fe_log1,by = TRUE, variables = \"m1202_fct\")\n\n\n      Term     Contrast Estimate Std. Error     z Pr(>|z|)   2.5 %   97.5 %\n m1202_fct Aufst - Ohne  -0.0907     0.0217 -4.17   <0.001 -0.1333 -0.04812\n m1202_fct Fachh - Ohne  -0.1874     0.0249 -7.52   <0.001 -0.2363 -0.13861\n m1202_fct duale - Ohne  -0.0298     0.0192 -1.55    0.120 -0.0675  0.00781\n m1202_fct keine - Ohne   0.1316     0.0827  1.59    0.112 -0.0305  0.29361\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high \n\navg_slopes(fe_log1,by = TRUE, variables = \"zpalter\")\n\n\n    Term  Estimate Std. Error    z Pr(>|z|)    2.5 %   97.5 %\n zpalter -0.000116   0.000385 -0.3    0.764 -0.00087 0.000639\n\nColumns: term, estimate, std.error, statistic, p.value, conf.low, conf.high"
  },
  {
    "objectID": "10_log_reg.html#ame1",
    "href": "10_log_reg.html#ame1",
    "title": "10  Logistische Regressionsmodelle",
    "section": "10.5 Übung",
    "text": "10.5 Übung\n\netb_ue10 <- haven::read_dta(\"./data/BIBBBAuA_2018_suf1.0.dta\",\n                            col_select = c(\"F1605e\",\"m1202\")) %>% \n  filter(F1605e < 4, !is.na(F1605e), m1202 %in% 1:4) %>% \n  mutate(fam_beruf = 2-F1605e,\n         m1202 = factor(m1202))\n\n\nErstellen Sie ein logistisches Regressionsmodell mit fam_beruf basierend auf der Frage\n\nHaben Sie aufgrund ihrer Kinder Abstriche gemacht, um Familie und Beruf zu vereinbaren?\nals abhängiger Variable (1 = ja, 0 = nein.) Verwenden Sie die Ausbildung m1202 als unabhängige Variable.\nBerechnen Sie die AME mit marginaleffects."
  },
  {
    "objectID": "10_log_reg.html#anhang-hintergrund-zu-log.-regression-average-marginal-effects",
    "href": "10_log_reg.html#anhang-hintergrund-zu-log.-regression-average-marginal-effects",
    "title": "10  Logistische Regressionsmodelle",
    "section": "10.6 Anhang: Hintergrund zu log. Regression & average marginal effects",
    "text": "10.6 Anhang: Hintergrund zu log. Regression & average marginal effects\nWenn wir uns fragen, ob sich Befragte mit höherem Einkommen seltener im Freien arbeiten, hilft uns die OLS-Vorgehensweise nicht so richtig weiter. Die “Punktewolke” zur Optimierung der Abweichung zwischen tatsächlichen und vorhergesagten Werten (Residuen) sieht hier anders aus als bisher:\n\n\nCode\nggplot(m_etb18, aes(x = inc100, y = outside)) +\n  geom_point(color = \"#172869\") +\n  theme(aspect.ratio = .75)\n\n\n\n\n\n\n\n\n\nUm trotzdem ein Regressionsmodell zu berechnen, könnten wir die abhängige Variable uminterpretieren. \\(\\hat{y}\\) wird dann nicht mehr dichotom, sondern als metrische Wahrscheinlichkeit interpretiert, dass der Befragte mehr als die Hälfte der Arbeitszeit im Freien arbeitet (also die Wahrscheinlichkeit für outside = 1). Das können wir dann wie gehabt in eine Regressionsgleichung aufnehmen, zB. mit dem Einkommen als unabhängiger Variable:\n\\[\\begin{equation*}\n\\widehat{y_i} = P(outside\\texttt{\\small{=}}1) = \\hat\\beta0 + \\hat\\beta1 * \\texttt{inc100}_i\n\\end{equation*}\\]\nAllerdings führt das zwangsläufig zu Verstößen gegen die Annahmen bzgl. der Residuen - die Fehler werden immer heteroskedastisch und nicht normalverteilt sein. Zudem wird es vorhergesagte Werte geben, die nicht sinnvoll interpretiert werden können, weil es mit 0 und 1 Grenzen gibt, jenseits derer Wahrscheinlichkeiten nicht existieren (zB gibt es keine negativen Wahrscheinlichkeiten).\n\n\nCode\nggplot(m_etb18, aes(x = inc100, y = outside)) +\n  geom_point(color = \"#172869\", size = .75) +\n  geom_smooth(method = \"lm\", color = lacroix_palette(\"PeachPear\",6)[2],se = F ) + \n  labs(y = \"P(outside = 1)\", x = \"Einkommen (in 100 EUR)\",\n       title = \"lineares Wahrscheinlichkeitsmodell\")\n\n\n\n\n\n\n\n\n\n\nlibrary(ggfortify)\nautoplot(m1,which = 1:2) # Homosk. & NV \n\n\n\n\n\n\n\n\n\n\n\n10.6.1 Logistische Linkfunktion\nUm diese Probleme zu umgehen, sind für dichotome abhängige Variablen logistische Regressionsmodelle ein sehr verbreitetes Vorgehen. Dafür werden neben dem bereits angesprochenen Schritt der Betrachtung von \\(\\hat{y}\\) als Wahrscheinlichkeit zwei weitere Transformationen der abhängigen Variable vorgenommen:\n\nOdds statt Wahrscheinlichkeiten: Um die obere Grenze des Wertebereichs der abhängigen Variablen auf \\(+\\infty\\) auszudehnen, werden statt Wahrscheinlichkeiten Odds betrachtet. Odds sind definiert als der Quotient aus Wahrscheinlichkeit und der Gegenwahrscheinlichkeit für ein gegebenes Ereignis. In unserem Beispiel sind also die Odds dafür, dass eine Befragter angibt, sich nachts outside zu fühlen: \\[Odds(outside=1) = \\frac{P(outside=1)}{P(outside=0)}= \\frac{P(outside=1)}{1-P(outside=1)} \\] Die Odds gehen gegen 0, je unwahrscheinlicher das betrachtete Ereignis ist. Für sehr wahrscheinliche Ereignisse nehmen die Odds Werte an, die gegen \\(+\\infty\\) gehen, das Verhältnis zwischen Dividend (“Zähler”) und Divisor (“Nenner”) wird immer größer.\nLogits statt Odds: Damit bleibt aber noch das Problem der negativen Werte bestehen: Auch Odds sind nur für [0;\\(+\\infty\\)] definiert. Um auch den negativen Wertebereich sinnvoll interpretierbar zu machen, werden die Odds logarithmiert, wir erhalten die sogenannten Logits: \\[Logit(outside=1) = log(Odds(outside=1)) = log\\left(\\frac{P(outside=1)}{1-P(outside=1)}\\right)\\] Die Logarithmierung führt für Werte zwischen 0 und 1 zu negativen Werten, für Werte größer als 1 zu positiven Werten.\n\nDementsprechend gibt es bei logistischen Regressionen drei Einheiten:\n\nWahrscheinlichkeiten \\(P = \\frac{\\text{Anzahl Treffer}}{\\text{Anzahl aller Möglichkeiten}}\\)\n\\(\\text{Odds} = \\frac{P}{1-P} = \\frac{\\text{Anzahl Treffer}}{\\text{Anzahl Nicht-Treffer}}\\)\n\\(\\text{log-Odds/Logits} = log(Odds) = log( \\frac{\\text{Anzahl Treffer}}{\\text{Anzahl Nicht-Treffer}})\\)\n\n\n\n\n\n\n\n\n  \n    \n    \n    \n    \n  \n  \n  \n    \n      $$P$$\n      $$Odds = \\frac{P}{1-P}$$\n      \n      $$Logits = log(Odds)$$\n    \n  \n  \n    $$\\frac{1}{2}$$\n\n$$1$$\n\noder 1:1\n\n0\n\n    $$\\frac{1}{3}$$\n\n$$0.5$$\n\noder 1:2\n\n-0.6931\n\n    $$\\frac{1}{4}$$\n\n$$0.33$$\n\noder 1:3\n\n-1.0986\n\n    $$\\frac{1}{5}$$\n\n$$0.25$$\n\noder 1:5\n\n-1.3863\n\n    $$\\frac{2}{3}$$\n\n$$2$$\n\noder 2:1\n\n0.6931\n\n    $$\\frac{3}{4}$$\n\n$$3$$\n\noder 3:1\n\n1.0986\n\n    $$1$$\n\n$$\\frac{1}{0}$$\n\nsicher\n\nInf\n\n  \n  \n  \n\n\n\n\n\n\n10.6.2 Vorhergesagte Werte\nZunächst stellt sich die Frage, was Logits denn bedeuten. Eigentlich möchten wir ja Wahrscheinlichkeiten im Wertebereich zwischen 0 und 1 (bzw. 0% und 100%) als Interpretationseinheit haben. Die Berechnung eines vorhergesagten Werts für einen Befragten mit einem Einkommen von 1000 Euro (inc100=10) ergibt durch einsetzen bzw. predict() natürlich auch die Logits:\n\nsummary(m2)$coefficients\n\n               Estimate  Std. Error   z value     Pr(>|z|)\n(Intercept) -0.54045018 0.072851290  -7.41854 1.184188e-13\ninc100      -0.03861198 0.002179513 -17.71588 3.162624e-70\n\n-0.53856546   + -0.03868975 * 10\n\n[1] -0.925463\n\npredict(m2, data.frame(inc100 = 10))\n\n         1 \n-0.9265699 \n\n\n\nBefragte mit einem Einkommen von 1000EUR haben dem Modell zu Folge Logits von -0.92657, mehr als die Hälfte der Arbeitszeit im Freien zu arbeiten.\n\nUm an die Wahrscheinlichkeit für outside = 1 zu bekommen, müssen wir die Transformationsschritte sozusagen “rückabwickeln”! Dafür müssen wir zunächst mit exp den ln() vor den Odds heraus rechnen und können dann durch die die Formel \\(p=\\frac{Odds}{1+Odds}\\) die Wahrscheinlichkeit aus den odds berechnen:\n\nlogits <- -0.9254629 \nexp(logits) # Odds statt Logits\n\n[1] 0.3963479\n\nodds <- exp(logits) \nodds/(1+odds) # Wahrscheinlichkeit statt Odds \n\n[1] 0.2838461\n\nexp(logits)/(1+exp(logits)) # beide Schritte auf einmal\n\n[1] 0.2838461\n\n\n\nDie Wahrscheinlichkeit, dass ein Befragter mit einem Einkommen von 1000 Euro angibt, mehr als die Hälfte Ihrer Arbeitszeit im Freien zu arbeiten, liegt also unserem Modell zu Folge bei 28.362%.\n\nMit der Option type=\"response\" können wir das auch mit predict() direkt berechnen:\n\npredict(m2, data.frame(inc100 = 10), type=\"response\")\n\n        1 \n0.2836211 \n\n\n\n\n10.6.3 Die Idee von average marginal effects\nWie verändern sich dann die vorhergesagten Werte, wenn wir inc100 um eine Einheit (also 100€) erhöhen? Die Logits verändern sich pro Einheit inc100 natürlich genau um \\(\\hat\\beta1\\), also hier -0.03861. Um sich die Steigung an einigen Werten anzusehen, berechnen wir jeweils die Abstände der vorhergesagten Werte für \\(x-0.5\\) und \\(x+0.5\\):\nUm die Werte jeweils mit dem eingesetzten Wert zu beschriften, stellen wir den Wert mit  \"\"= voran:\n\npredict(m2, data.frame(inc100=c(\"54.5\"=54.5,\"55.5\"=55.5,\"64.5\"=64.5,\"65.5\"=65.5,\n                                \"74.5\"=74.5,\"75.5\"=75.5)))\n\n     54.5      55.5      64.5      65.5      74.5      75.5 \n-2.644803 -2.683415 -3.030923 -3.069535 -3.417042 -3.455654 \n\n\nDie Differenzen sind immer gleich - entsprechend der Interpretation gehen mit einem um eine Einheit höheren inc100 um 0.03861 höhere Logits einher, dass die Befragten mehr als die Hälfte Ihrer Arbeitszeit im Freien arbeiten:\n\nSteigung bei inc100 = 55: -2.68341 \\(-\\) -2.64480 = -0.03861 \nSteigung bei inc100 = 65: -3.06953 \\(-\\) -3.03092 = -0.03861 \nSteigung bei inc100 = 75: -3.45565 \\(-\\) -3.41704 = -0.03861 \n\nWenn wir uns diese Schritte aber jeweils für die vorhergesagten Wahrscheinlichkeiten ansehen, sieht das aber anders aus:\n\npredict(m2, data.frame(inc100=c(\"54.5\"=54.5,\"55.5\"=55.5,\"64.5\"=64.5,\"65.5\"=65.5,\n                                \"74.5\"=74.5,\"75.5\"=75.5)), type = \"response\")\n\n      54.5       55.5       64.5       65.5       74.5       75.5 \n0.06631006 0.06395913 0.04604828 0.04438156 0.03176707 0.03060068 \n\n\nHier werden die Differenzen mit zunehmendem inc100 immer kleiner:\n\nSteigung bei inc100 = 55: 0.06396 \\(-\\) 0.06631 = -0.00235 \nSteigung bei inc100 = 65: 0.04438 \\(-\\) 0.04605 = -0.00167 \nSteigung bei inc100 = 75: 0.03060 \\(-\\) 0.03177 = -0.00117 \n\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiese Steigungen werden für alle Beobachtungen aus dem zu Grunde liegenden Datensatz aufsummiert und dann der Durchschnitt gebildet (\\(\\rightarrow\\) average marginal effects)"
  },
  {
    "objectID": "10_log_reg.html#links",
    "href": "10_log_reg.html#links",
    "title": "10  Logistische Regressionsmodelle",
    "section": "10.7 Links",
    "text": "10.7 Links\n\nDie Seite zu {marginaleffects} bietet sehr ausführliche und anschauliche Beispiele zu den verschiedenen Varianten marginaler Effekte\nAusführliche Einführung zu marginalen Effekten von Andrew Heiss\n\nAbleitungen grafisch erstellt"
  },
  {
    "objectID": "11_data_wrangle3.html",
    "href": "11_data_wrangle3.html",
    "title": "11  Data Wrangling III",
    "section": "",
    "text": "A mutating join allows you to combine variables from two tables. It first matches observations by their keys, then copies across variables from one table to the other.\nR for Data Science: Mutating joins\n\nEin Überblick zu den wichtigsten Befehlen:1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEs gibt natürlich auch right_join() oder anti_join(). Für eine tiefergehende Einführung lohnt sich das Kapitel Relational Data aus R for Data Science.\nEine sehr hilfreiche Option in den ..._join() ist die Verbindung unterschiedlicher Variablen. Bspw. haben wir hier einige Fälle aus der ETB18 und\n\n\nCode\netb18_int_bl <- haven::read_dta(\"./data/BIBBBAuA_2018_suf1.0.dta\",\n                                col_select = c(\"intnr\",\"Bula\") # mit col_select() können Variablen ausgewählt werden\n                                )\n\netb_ids <-  etb18_int_bl %>% slice(c(1,125,1230,21010,8722) )\n\nset.seed(90459)\nalo_bula <- data.frame(bundesland = seq(1:8),\n                       Werte = sample(letters,size = 8) # mit sample() kann eine zufällige Auswahl getroffen werden \n                       )\n\n\n\netb_ids\n\n#> # A tibble: 4 × 2\n#>     intnr Bula                    \n#>     <dbl> <dbl+lbl>               \n#> 1     260 11 [Berlin]             \n#> 2   30699  5 [Nordrhein-Westfalen]\n#> 3  209604  6 [Hessen]             \n#> 4 1540064  8 [Baden-Württemberg]\n\nalo_bula\n\n#>   bundesland Werte\n#> 1          1     g\n#> 2          2     m\n#> 3          3     n\n#> 4          4     z\n#> 5          5     w\n#> 6          6     r\n#> 7          7     t\n#> 8          8     h\n\netb_ids %>% left_join(alo_bula,by = c(\"Bula\"=\"bundesland\"))\n\n#> # A tibble: 4 × 3\n#>     intnr Bula                     Werte\n#>     <dbl> <dbl+lbl>                <chr>\n#> 1     260 11 [Berlin]              <NA> \n#> 2   30699  5 [Nordrhein-Westfalen] w    \n#> 3  209604  6 [Hessen]              r    \n#> 4 1540064  8 [Baden-Württemberg]   h\n\n\nEin sehr hilfreiche Checkmöglichkeit, die ich häufig verwende: Für alle Bula in etb_ids findet sich eine Entsprechung in alo$bundesland:\n\ntable(etb_ids$Bula %in% alo_bula$bundesland)\n\n#> \n#> FALSE  TRUE \n#>     1     3"
  },
  {
    "objectID": "11_data_wrangle3.html#reshape-pivot_longer-pivot_wider",
    "href": "11_data_wrangle3.html#reshape-pivot_longer-pivot_wider",
    "title": "11  Data Wrangling III",
    "section": "11.2 Reshape: pivot_longer() & pivot_wider()",
    "text": "11.2 Reshape: pivot_longer() & pivot_wider()\n\nbsp_df <- \n  data.frame(\n    bula    = c(\"NRW\",\"NDS\"),\n    alo2018 = c(2,2),\n    alo2017 = c(1,1)\n    )\n\nbsp_df\n\n#>   bula alo2018 alo2017\n#> 1  NRW       2       1\n#> 2  NDS       2       1\n\n\nMit pivot_longer() können wir aus einem wide shape data.frame einen long shape machen:\n\nbsp_df %>% pivot_longer(cols = c(\"alo2018\",\"alo2017\"),names_to = \"year\",values_to = \"alo\")\n\n#> # A tibble: 4 × 3\n#>   bula  year      alo\n#>   <chr> <chr>   <dbl>\n#> 1 NRW   alo2018     2\n#> 2 NRW   alo2017     1\n#> 3 NDS   alo2018     2\n#> 4 NDS   alo2017     1\n\n\nMit names_prefix = \"alo\" können wir das alo direkt löschen lassen:\n\nbsp_df %>% pivot_longer(cols = c(\"alo2018\",\"alo2017\"),names_to = \"year\",values_to = \"alo\",names_prefix = \"alo\")\n\n#> # A tibble: 4 × 3\n#>   bula  year    alo\n#>   <chr> <chr> <dbl>\n#> 1 NRW   2018      2\n#> 2 NRW   2017      1\n#> 3 NDS   2018      2\n#> 4 NDS   2017      1\n\n\nMit pivot_wider() können wir den umgekehrten Weg gehen:\n\nbsp_df2 <- \n  data.frame(land = c(\"NRW\",\"NDS\",\"NRW\",\"NDS\"),\n             alo = c(2.1,1.8,2.4,2.2),\n             alter = c(\"age_1825\",\"age_1825\",\"age_2630\",\"age_2630\"))\nbsp_df2\n\n#>   land alo    alter\n#> 1  NRW 2.1 age_1825\n#> 2  NDS 1.8 age_1825\n#> 3  NRW 2.4 age_2630\n#> 4  NDS 2.2 age_2630\n\n\n\nbsp_df2 %>% pivot_wider(names_from = alter,values_from = alo)\n\n#> # A tibble: 2 × 3\n#>   land  age_1825 age_2630\n#>   <chr>    <dbl>    <dbl>\n#> 1 NRW        2.1      2.4\n#> 2 NDS        1.8      2.2"
  },
  {
    "objectID": "11_data_wrangle3.html#übungen",
    "href": "11_data_wrangle3.html#übungen",
    "title": "11  Data Wrangling III",
    "section": "11.3 Übungen",
    "text": "11.3 Übungen\n\n11.3.1 Übung 1\nVerknüpfen Sie die ausgewählten Beobachtungen der ETB 2018 mit Arbeitsmarktstatistiken von Destatis. Lesen die ETB mit folgendem Befehl ein:\n\netb_ue11 <- haven::read_dta(\"./data/BIBBBAuA_2018_suf1.0.dta\",\n                       col_select = c(\"intnr\",\"int_jahr\",\"Bula\")) %>% \n  slice(34:35,68:69,62,687,625,684,599:600)\netb_ue11\n\n#> # A tibble: 10 × 3\n#>     intnr int_jahr Bula                   \n#>     <dbl>    <dbl> <dbl+lbl>              \n#>  1   7045     2017 3 [Niedersachsen]      \n#>  2   7119     2017 3 [Niedersachsen]      \n#>  3  15443     2017 5 [Nordrhein-Westfalen]\n#>  4  15527     2017 5 [Nordrhein-Westfalen]\n#>  5  13619     2018 3 [Niedersachsen]      \n#>  6 104699     2018 3 [Niedersachsen]      \n#>  7  94148     2018 5 [Nordrhein-Westfalen]\n#>  8 103957     2018 5 [Nordrhein-Westfalen]\n#>  9  87426     2017 1 [Schleswig-Holstein] \n#> 10  87648     2017 6 [Hessen]\n\n\nSo können Sie die aufbereiteten Arbeitslosendaten einlesen (die Zahlencodes in beiden Datensätzen stimmen überein):\n\nalo <- readRDS(file = \"./data/alo_bula1.Rdata\")\nalo\n\n#> # A tibble: 2 × 3\n#>     ags name                aloquote\n#>   <dbl> <chr>               <chr>   \n#> 1     3 Niedersachsen       5.8     \n#> 2     5 Nordrhein-Westfalen 7.4\n\n\nWie müssten Sie vorgehen, wenn Sie nun jahresgenaue Angaben haben und dementsprechend zusätzlich auch nach dem Jahr mergen möchten?\n\nalo_j <- readRDS(file = \"./data/alo_bula1_jahr.Rdata\")\nalo_j\n\n#> # A tibble: 4 × 4\n#>     ags name                aloquote  jahr\n#>   <dbl> <chr>               <chr>    <dbl>\n#> 1     3 Niedersachsen       5.8       2017\n#> 2     5 Nordrhein-Westfalen 7.4       2017\n#> 3     3 Niedersachsen       5.3       2018\n#> 4     5 Nordrhein-Westfalen 6.8       2018\n\n\n\n\n11.3.2 Übung 2\n\nalo_wide <- readRDS(file = \"./data/alo_bula2.Rdata\")\nalo_wide\n\n#> # A tibble: 2 × 4\n#>   ags   name                alo_2017 alo_2018\n#>   <chr> <chr>               <chr>    <chr>   \n#> 1 03    Niedersachsen       5.8      5.3     \n#> 2 05    Nordrhein-Westfalen 7.4      6.8\n\n\nBringen Sie alo_wide in das long shape:\n\n\n#> # A tibble: 4 × 4\n#>   ags   name                jahr  alo_quote\n#>   <chr> <chr>               <chr> <chr>    \n#> 1 03    Niedersachsen       2017  5.8      \n#> 2 03    Niedersachsen       2018  5.3      \n#> 3 05    Nordrhein-Westfalen 2017  7.4      \n#> 4 05    Nordrhein-Westfalen 2018  6.8"
  },
  {
    "objectID": "12_apply_loop.html",
    "href": "12_apply_loop.html",
    "title": "12  Schleifen & Funktionen",
    "section": "",
    "text": "etbx <-  haven::read_dta(\"./data/BIBBBAuA_2018_suf1.0.dta\",\n                         col_select = c(\"S1\",\"F518_SUF\",\"m1202\",\"az\",\"zpalter\",\"F1605e\",\"Bula\")) %>% \n  filter(F518_SUF < 99998, m1202 %in% 1:4, zpalter < 9999 ) %>% \n  mutate(ausb = factor(m1202, levels = 1:4, labels = c(\"ohne\",\"dual/schul.\",\"Aufst.\",\"FH/Uni\")),\n         S1 = factor(S1,levels = 1:2,labels =c(\"m\",\"w\")))\nSchleifen im Sinne von for()-Loops werden in R selten verwendet. Stattdessen werden meist Funktionen mit Hilfe von lapply() bzw. map() aus {purrr} über eine Reihe von Werten geschleift. Die grundlegende Idee ist zunächst die gleiche wie bei klassischen for()-Loops: wir definieren erst eine Serie an Werten, für dann eine Operation (eine function()) ausgeführt werden soll.\nGrundsätzlich können wir in R solche Schleife auf wirklich alles anwenden: data.frames(), Vektoren, lists. Das macht das Vorgehen sehr flexibel und kann uns beispielsweise helfen:\nNatürlich würde so etwas funktionieren, wäre aber ein Verstoß gegen das DRY-Prinzip[^dry] und anfällig für Vertipper:"
  },
  {
    "objectID": "12_apply_loop.html#modellserien-mit-lapply",
    "href": "12_apply_loop.html#modellserien-mit-lapply",
    "title": "12  Schleifen & Funktionen",
    "section": "12.1 Modellserien mit lapply()",
    "text": "12.1 Modellserien mit lapply()\nEin typisches Beispiel ist eine Modellserie. Wir möchten folgende Modelle schätzen:\n\nModell 1 = F518_SUF ~ az\nModell 2 = F518_SUF ~ az + S1\nModell 3 = F518_SUF ~ az + S1 + m1202\nModell 4 = F518_SUF ~ az + S1 + m1202 + zpalter"
  },
  {
    "objectID": "12_apply_loop.html#modell-function",
    "href": "12_apply_loop.html#modell-function",
    "title": "12  Schleifen & Funktionen",
    "section": "12.1 Modell-function()",
    "text": "12.1 Modell-function()\nWir definieren dann eine function(), in der wir angeben, dass das angegebene Argument die Formel für ein lm() sein soll - das Ergebnis dieses lm() `lassen wir uns dann ausgeben.\n\nmod_function <- function(modx){\n  mx <- lm(formula = modx,data = etbx)\n  return(mx)\n}\n\nWenn wir jetzt in mod_function eine Modellformel angeben, wird ein lm() berechnet:\n\nmod_function(\"F518_SUF ~ az\")\n\n\nCall:\nlm(formula = modx, data = etbx)\n\nCoefficients:\n(Intercept)           az  \n     -371.3        102.1"
  },
  {
    "objectID": "12_apply_loop.html#modelle-als-list-erstellen",
    "href": "12_apply_loop.html#modelle-als-list-erstellen",
    "title": "12  Schleifen & Funktionen",
    "section": "12.2 Modelle als list erstellen",
    "text": "12.2 Modelle als list erstellen\nIm nächsten Schritt können wir jetzt eine Liste mit verschiedenen Modellvarianten erstellen:\n\nmlst <- list(\n  \"Modell 1\" = \"F518_SUF ~ az\",\n  \"Modell 2\"  = \"F518_SUF ~ az + S1\",\n  \"Modell 3\" = \"F518_SUF ~ az + S1 + m1202\",\n  \"Modell 4\" = \"F518_SUF ~ az + S1 + m1202 + zpalter\"\n)\n\nWir können die Elemente einer list() entweder mit [[]] oder (ggf.) über ihren Namen aufrufen. Hier haben wir vor dem = einen Namen angegeben:\n\nmlst[[4]]\n\n[1] \"F518_SUF ~ az + S1 + m1202 + zpalter\"\n\nmlst$`Modell 4`\n\n[1] \"F518_SUF ~ az + S1 + m1202 + zpalter\"\n\n\nMit lapply wenden wir unsere mod_function jetzt auf diese Liste von Modellen an:\n\nmods <- lapply(mlst,mod_function)\nmods$`Modell 1`\n\n\nCall:\nlm(formula = modx, data = etbx)\n\nCoefficients:\n(Intercept)           az  \n     -371.3        102.1  \n\nmods$`Modell 2`\n\n\nCall:\nlm(formula = modx, data = etbx)\n\nCoefficients:\n(Intercept)           az          S1w  \n     359.51        91.73      -683.55  \n\n\nAußerdem können wir uns alle Modelle auch direkt in modelsummary ausgeben lassen:\n\nmodelsummary::modelsummary(mods,stars = T,gof_omit = \"IC|RM|Log\")\n\n\n\n \n  \n      \n    Modell 1 \n     Modell 2 \n     Modell 3 \n     Modell 4 \n  \n \n\n  \n    (Intercept) \n    -371.260*** \n    359.515*** \n    -1526.254*** \n    -2609.682*** \n  \n  \n     \n    (89.299) \n    (106.687) \n    (118.849) \n    (153.625) \n  \n  \n    az \n    102.097*** \n    91.733*** \n    82.716*** \n    83.152*** \n  \n  \n     \n    (2.234) \n    (2.376) \n    (2.321) \n    (2.313) \n  \n  \n    S1w \n     \n    -683.549*** \n    -725.053*** \n    -755.165*** \n  \n  \n     \n     \n    (55.184) \n    (53.540) \n    (53.414) \n  \n  \n    m1202 \n     \n     \n    797.911*** \n    778.380*** \n  \n  \n     \n     \n     \n    (24.734) \n    (24.706) \n  \n  \n    zpalter \n     \n     \n     \n    24.282*** \n  \n  \n     \n     \n     \n     \n    (2.194) \n  \n  \n    Num.Obs. \n    16521 \n    16521 \n    16521 \n    16521 \n  \n  \n    R2 \n    0.112 \n    0.120 \n    0.173 \n    0.179 \n  \n  \n    R2 Adj. \n    0.112 \n    0.120 \n    0.172 \n    0.178 \n  \n  \n    F \n    2089.519 \n    1131.116 \n    1148.445 \n    898.308 \n  \n\n\n + p < 0.1, * p < 0.05, ** p < 0.01, *** p < 0.001"
  },
  {
    "objectID": "12_apply_loop.html#if-in-function",
    "href": "12_apply_loop.html#if-in-function",
    "title": "12  Schleifen & Funktionen",
    "section": "12.2 if in function()",
    "text": "12.2 if in function()\nWir können unsere function() auch weitere Argumente aufnehmen und auch if und else-Statements einbauen. Hier ein Beispiel: wenn wir das zweite Argument add_age auf TRUE setzen, wird der add_controls hinzugefügt:\n\nadd_controls <- c(\"+ zpalter + I(zpalter^2)\")\n\nmod_function2 <- function(modx, add_age){\n  if(add_age == T) {\n        mx <- lm(formula = paste0(modx,add_controls),data = etbx)\n  } else {\n        mx <- lm(formula = paste0(modx),data = etbx)\n  }\n  return(mx)\n}\n\nmod_function2(\"F518_SUF ~ az\",add_age=F)\n\n\nCall:\nlm(formula = paste0(modx), data = etbx)\n\nCoefficients:\n(Intercept)           az  \n     -371.3        102.1  \n\nmod_function2(\"F518_SUF ~ az\",add_age=T)\n\n\nCall:\nlm(formula = paste0(modx, add_controls), data = etbx)\n\nCoefficients:\n (Intercept)            az       zpalter  I(zpalter^2)  \n  -2498.4123      102.5538       66.6746       -0.4356  \n\n\nWenn wir einen Standardwert für ein Argument vergeben möchten, dann können wir das mit = angeben. Hier erweitern wir unsere Modellfunktion um einen tidy()-Schritt - der aber mit Hilfe einer Option tidy_mod ausgeschaltet werden kann, indem er auf FALSE gesetzt wird.\n\nmod_function3 <- function(modx, tidy_mod = T){\n  mx <- lm(formula = modx,data = etbx)\n  if(tidy_mod == T) mx <- tidy(mx,conf.int = T)\n  return(mx)\n}\n\nmod_function3(\"F518_SUF ~ az\")\n\n# A tibble: 2 × 7\n  term        estimate std.error statistic   p.value conf.low conf.high\n  <chr>          <dbl>     <dbl>     <dbl>     <dbl>    <dbl>     <dbl>\n1 (Intercept)    -371.     89.3      -4.16 0.0000323   -546.      -196.\n2 az              102.      2.23     45.7  0             97.7      106.\n\nmod_function3(\"F518_SUF ~ az\",tidy_mod = F)\n\n\nCall:\nlm(formula = modx, data = etbx)\n\nCoefficients:\n(Intercept)           az  \n     -371.3        102.1"
  },
  {
    "objectID": "12_apply_loop.html#list-zu-data.frame",
    "href": "12_apply_loop.html#list-zu-data.frame",
    "title": "12  Schleifen & Funktionen",
    "section": "12.3 List zu data.frame",
    "text": "12.3 List zu data.frame\nWenn die Einzelbestandteile einer list bereits data.frames sind, können wir mit bind_rows() diese zu einem data.frame zusammenfügen. Mit .id=\"\" können wir eine Variable erstellen, welche die Listennamen enthält:\n\nmod_l3 <- lapply(mlst,mod_function3)\nlapply(mod_l3,class)\n\n$`Modell 1`\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n$`Modell 2`\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n$`Modell 3`\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n$`Modell 4`\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n\nbind_rows(mod_l3,.id=\"Mod_name\")\n\n\n\n\n\n  \n\n\n\n\nlapply(mlst,mod_function3) %>% bind_rows(.id=\"Mod_name\")"
  },
  {
    "objectID": "12_apply_loop.html#modelle-auf-subdatensets-anwenden",
    "href": "12_apply_loop.html#modelle-auf-subdatensets-anwenden",
    "title": "12  Schleifen & Funktionen",
    "section": "12.4 Modelle auf Subdatensets anwenden",
    "text": "12.4 Modelle auf Subdatensets anwenden\n“Habt ihr das auch mal getrennt für Ost/West gerechnet?”\n\netbx %>%\n  mutate(east = ifelse(Bula > 10,\"east\",\"west\")) %>% # Berlin = east\n  split(.$east) %>% \n  map(.,~lm(\"F518_SUF ~ az + ausb + zpalter + S1\",data = .x)) %>% \n  modelsummary::modelplot(.,coef_omit = \"Intercept\") +\n  geom_vline(aes(xintercept = 0), linetype = 2, alpha = .5) +\n  scale_color_manual(values = c(\"orange\",\"navy\")) \n\n\n\n\n\netbx %>%\n  mutate(east = ifelse(Bula > 10,\"east\",\"west\")) %>% # Berlin = east\n  split(.$east) %>% \n  map(.,~lm(\"F518_SUF ~ az + ausb + zpalter + S1\",data = .x)) %>% \n  modelsummary::modelsummary(.,stars = T,gof_omit = \"IC|RM|Log\")\n\n\n\n \n  \n      \n    east \n    west \n  \n \n\n  \n    (Intercept) \n    -509.068 \n    -1731.303*** \n  \n  \n     \n    (380.613) \n    (187.221) \n  \n  \n    az \n    71.902*** \n    88.157*** \n  \n  \n     \n    (5.374) \n    (2.562) \n  \n  \n    ausbdual/schul. \n    -345.508 \n    425.407*** \n  \n  \n     \n    (283.463) \n    (124.716) \n  \n  \n    ausbAufst. \n    -75.817 \n    936.694*** \n  \n  \n     \n    (329.344) \n    (151.324) \n  \n  \n    ausbFH/Uni \n    1294.027*** \n    2097.328*** \n  \n  \n     \n    (287.443) \n    (126.477) \n  \n  \n    zpalter \n    12.272** \n    28.938*** \n  \n  \n     \n    (4.720) \n    (2.468) \n  \n  \n    S1w \n    -399.585*** \n    -830.732*** \n  \n  \n     \n    (110.121) \n    (60.787) \n  \n  \n    Num.Obs. \n    3438 \n    13083 \n  \n  \n    R2 \n    0.124 \n    0.201 \n  \n  \n    R2 Adj. \n    0.122 \n    0.201 \n  \n\n\n + p < 0.1, * p < 0.05, ** p < 0.01, *** p < 0.001"
  },
  {
    "objectID": "12_apply_loop.html#adhoc-function",
    "href": "12_apply_loop.html#adhoc-function",
    "title": "12  Schleifen & Funktionen",
    "section": "12.5 adhoc function",
    "text": "12.5 adhoc function\nWir müssen aber nicht notwendigerweise erst eine Funktion definieren, um sie dann anzuwenden. Wir können die Funktion auch im gleichen Zug wie lapply() definieren:\n\nmods3 <- lapply(mlst,function(modx){\n  mx <- lm(formula = modx,data = etbx)\n  return(mx)\n})\nmods3$`Modell 1`\n\n\nCall:\nlm(formula = modx, data = etbx)\n\nCoefficients:\n(Intercept)           az  \n     -371.3        102.1"
  },
  {
    "objectID": "12_apply_loop.html#loop-mit-for",
    "href": "12_apply_loop.html#loop-mit-for",
    "title": "12  Schleifen & Funktionen",
    "section": "12.6 Loop mit for",
    "text": "12.6 Loop mit for\n\nfor(i in 1:8){\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7\n[1] 8\n\n\nKleines Beispiel: Zeile für Zeile der ersten 8 Zeilen aus etbx ausgeben:\n\nfor(i in 1:8){\n  etbx %>% slice(i) %>% print()\n}"
  },
  {
    "objectID": "12_apply_loop.html#übungen",
    "href": "12_apply_loop.html#übungen",
    "title": "12  Schleifen & Funktionen",
    "section": "12.7 Übungen",
    "text": "12.7 Übungen\n\netb_ue12 <- \n  haven::read_dta(\"./data/BIBBBAuA_2018_suf1.0.dta\",\n                  col_select = c(\"S1\",\"F518_SUF\",\"m1202\",\"az\",\"zpalter\",\"F1605e\")) %>% \n  filter(F518_SUF < 99998, m1202 %in% 1:4, zpalter < 9999 ) %>% \n  mutate(ausb = factor(m1202, levels = 1:4, labels = c(\"ohne\",\"dual/schul.\",\"Aufst.\",\"FH/Uni\")),\n         S1 = factor(S1,levels = 1:2,labels =c(\"m\",\"w\")))\n\n\nErstellen Sie eine Funktion, welche den data.frame etb_ue12 für ein lm() verwendet und als Input eine Modellformel verwendet. Testen Sie Ihre Funktion mit folgender Formel: az ~ S1 + ausb + zpalter (Denken Sie daran, die Formula in \"\" zu setzen).\nErstellen Sie eine Liste mit folgenden Modellen:\n\nModell 1 \"az ~ S1\",\nModell 2 \"az ~ S1 + ausb\",\nModell 3 \"az ~ S1 + ausb + zpalter\"\n\nVerwenden Sie lapply() und die erstellte Funktion, um die Modelle zu schätzen und in modelsummary() anzuzeigen\nErweitern Sie Ihre Funktion um ein zweites Argument only_women, welches über ein TRUE / FALSE steuert ob lediglich die Beobachtungen von weiblichen Befragten verwendet werden: etb_ue12 %>% filter(S1 == \"w\"). Legen Sie innerhalb der Funktion die entsprechenden Schritt mit einer if-Bedingung versehen."
  },
  {
    "objectID": "12_apply_loop.html#anhang-schleifen-mit-purrr",
    "href": "12_apply_loop.html#anhang-schleifen-mit-purrr",
    "title": "12  Schleifen & Funktionen",
    "section": "12.8 Anhang: Schleifen mit {purrr}",
    "text": "12.8 Anhang: Schleifen mit {purrr}\nIm {tidyverse} stellt das Paket {purrr} map() zur Verfügung, das function(x) { ... x} auf ~ und .x abkürzen lässt:\n\nmods <- map(mlst,~lm(formula = .x,data = etbx))\n\nSehr hilfreich ist map_dfr: hier wir aus dem Ergebnis der Schleife ein data.frame” mit row_bind() erstellt. Mit .id = können wir eine Spalte erstellen, welche die Namen der Liste enthält (Hier die Modellnamen):\n\nmap_dfr(mlst,~lm(formula = .x,data = etbx) %>% tidy(.),.id = \"mod\")\n\n# A tibble: 14 × 6\n   mod      term        estimate std.error statistic   p.value\n   <chr>    <chr>          <dbl>     <dbl>     <dbl>     <dbl>\n 1 Modell 1 (Intercept)   -371.      89.3      -4.16 3.23e-  5\n 2 Modell 1 az             102.       2.23     45.7  0        \n 3 Modell 2 (Intercept)    360.     107.        3.37 7.54e-  4\n 4 Modell 2 az              91.7      2.38     38.6  2.08e-312\n 5 Modell 2 S1w           -684.      55.2     -12.4  4.41e- 35\n 6 Modell 3 (Intercept)  -1526.     119.      -12.8  1.44e- 37\n 7 Modell 3 az              82.7      2.32     35.6  4.57e-268\n 8 Modell 3 S1w           -725.      53.5     -13.5  1.47e- 41\n 9 Modell 3 m1202          798.      24.7      32.3  1.79e-221\n10 Modell 4 (Intercept)  -2610.     154.      -17.0  3.57e- 64\n11 Modell 4 az              83.2      2.31     36.0  1.33e-272\n12 Modell 4 S1w           -755.      53.4     -14.1  4.06e- 45\n13 Modell 4 m1202          778.      24.7      31.5  1.28e-211\n14 Modell 4 zpalter         24.3      2.19     11.1  2.21e- 28\n\n\nWer mehr über purrr und map() erfahren möchte, findet hier eine hervorragende Einführung.\n\n12.8.1 loop über Variablen\nMöchten wir über Variablen loopen, müssen wir R explizit mitteilen, dass die mitgegebenen strings als Variablen zu verstehen sind:\n\nfor(v in c(\"ausb\",\"S1\",\"F1605e\")){\n  etbx %>% count(v) %>% print()\n}\n\nError in `count()`:\n! Must group by variables found in `.data`.\n✖ Column `v` is not found.\n\n\nDas können wir mit !!rlang::sym(v):\n\nfor(v in c(\"ausb\",\"S1\",\"F1605e\")){\n  etbx %>% count(!!rlang::sym(v)) %>% print()\n}\n\n# A tibble: 4 × 2\n  ausb            n\n  <fct>       <int>\n1 ohne          886\n2 dual/schul.  7679\n3 Aufst.       1460\n4 FH/Uni       6496\n# A tibble: 2 × 2\n  S1        n\n  <fct> <int>\n1 m      8442\n2 w      8079\n# A tibble: 4 × 2\n  F1605e                n\n  <dbl+lbl>         <int>\n1  1 [ja]            7104\n2  2 [nein]          3970\n3  9 [keine Angabe]    43\n4 NA                 5404"
  },
  {
    "objectID": "14_tabellenexport.html",
    "href": "14_tabellenexport.html",
    "title": "13  Tabellenexport",
    "section": "",
    "text": "Eure Zeit ist zu wertvoll, um Tabellen per Hand zu erstellen!\nDiese Pakete werden gebraucht, alle sind mit dem entsprechenden install.packages(\"\") installierbar:\nZu diesen Variablen sollen folgende deskriptiven Übersichtstabellen erstellt und als Word-Dokument exportiert werden:\nWir starten mit einem Ausschnitt der ETB 2018:"
  },
  {
    "objectID": "14_tabellenexport.html#flextable",
    "href": "14_tabellenexport.html#flextable",
    "title": "13  Tabellenexport",
    "section": "13.1 {flextable}",
    "text": "13.1 {flextable}\nMit dem Paket {flextable} können wir data.frames als Tabelle in eine Word-Datei exportieren, {officer} erweiteret diese Funktionen speziell für den Export in Word:\n\ninstall.packages(\"flextable\")\nlibrary(flextable)\ninstall.packages(\"officer\")\nlibrary(officer)\n\n\ndf1 <- data.frame(x1= c(2,2), y1 = c(0,1))\ndf1\n\n  x1 y1\n1  2  0\n2  2  1\n\n\n{flextable} stellt uns eine Reihe an Funktionen zur Formatierung zur Verfügung, um die Darstellung des data.frame zu anzupassen:\n\nflextable(df1) %>% \n  border_remove() %>% \n  hline_top(border = fp_border(color = \"orange\")) %>%\n  hline(i=1,border = fp_border(color = \"blue\",style = \"dotted\")) %>% \n  set_header_labels(x1 = \"Anderes Label\") %>% \n  add_header_row(values = c(\"Überschrift\",\"\"),colwidths = c(1,1)) %>% \n  autofit()\n\n\nÜberschriftAnderes Labely12021\n\n\nHier finden sich weitere Infos zu flextable, u.a. können bspw. die Trennlinien dünner gemacht werden oder eine andere Farbe angegeben werden. Hier finden sich alle vefügbaren Funktionen."
  },
  {
    "objectID": "14_tabellenexport.html#deskription",
    "href": "14_tabellenexport.html#deskription",
    "title": "13  Tabellenexport",
    "section": "13.2 Deskription",
    "text": "13.2 Deskription\n\n13.2.1 Verteilungstabellen für metrische Variablen\nFür die metrischen Merkmale kennen wir ja das summary():\n\nsummary(etb18_kap14$F518_SUF)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      1    2000    3000    3533    4200   72000 \n\nsummary(etb18_kap14$az)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  10.00   32.00   40.00   38.25   45.00  120.00 \n\n\nEine einfach Möglichkeit, diese summary() untereinander anzuordnen, ist summarise in Kombination mit pivot_longer() zu verwenden:\n\netb18_kap14 %>% \n  select(az,F518_SUF) %>% \n  pivot_longer(cols = everything(), names_to = \"variable\") %>% \n  group_by(variable) %>% \n  summarise(min = min(value,na.rm = T),\n            mean = mean(value,na.rm = T),\n            max = max(value,na.rm = T))\n\n# A tibble: 2 × 4\n  variable   min   mean   max\n  <chr>    <dbl>  <dbl> <dbl>\n1 F518_SUF     1 3533.  72000\n2 az          10   38.3   120\n\n\n\n\n\n\n\n\n\n\n\n\n\netb18_kap14 %>% \n  select(az,F518_SUF) %>% \n  pivot_longer(cols = everything(), names_to = \"variable\") %>% \n  group_by(variable) %>% \n  summarise(Min  = min(value,na.rm = T),\n            Mean = mean(value,na.rm = T),\n            Max  = mean(value,na.rm = T)) %>% \n  flextable()\n\n\nvariableMinMeanMaxF518_SUF13,533.103293,533.10329az1038.2510138.25101\n\n\n\nmet_ft <- \n  etb18_kap14 %>% \n  select(az,F518_SUF) %>% \n  pivot_longer(cols = everything(), names_to = \"variable\") %>% \n  group_by(variable) %>% \n  summarise(Min  = min(value,na.rm = T),\n            Mean = mean(value,na.rm = T),\n            Max  = mean(value,na.rm = T)) %>% \n  flextable() %>% \n  autofit()\n\nDer eigentliche Export ist dann mit save_as_docx, wo wir eine Überschrift und mit path die Zieldatei angeben können:\n\nsave_as_docx(\"Metrische unab. Variablen\" = met_ft, path = \"./results/Met_UVs_Tabelle.docx\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAussagekräftigere Variablenbeschriftung mit rename() & Nachkommastellen\n\n\n\n\n\nUm den Variablen in der Tabelle aussagekräftigere Namen zu geben, benennen wir sie einfach mit rename() um. Falls wir mehr als ein Wort als Variablenname/späteres Label vergeben wollen, setzen wir die Wörter in '``'.\nMit digits = in colformat_double() können wir die Anzahl der Nachkommastellen setzen:\n\n  etb18_kap14 %>% \n  select(`Arbeitszeit umfangreichste Tätigkeit` =az,Bruttoverdienst=F518_SUF) %>% \n  pivot_longer(cols = everything(), names_to = \"variable\") %>% \n  group_by(variable) %>% \n  summarise(Min  = min(value,na.rm = T),\n            Mean = mean(value,na.rm = T),\n            Max  = mean(value,na.rm = T)) %>% \n  flextable() %>% \n  colformat_double(digits = 2) %>% \n  autofit()\n\n\nvariableMinMeanMaxArbeitszeit umfangreichste Tätigkeit10.0038.2538.25Bruttoverdienst1.003,533.103,533.10\n\n\n\n\n\n\n\n13.2.2 Häufigkeitsauszählungen\n\netb18_kap14 %>%  \n  select(S1,m1202) %>% \n  mutate(S1 = factor(S1,levels = 1:2, labels = c(\"Männer\",\"Frauen\")),\n           m1202 = factor(m1202, levels = 1:4,labels = c(\"ohne\",\"dual/schul.\",\"Aufst.\",\"FH/Uni\"))) %>% \n  pivot_longer(everything(),names_to = \"variable\") %>% \n  count(variable,value)\n\n# A tibble: 6 × 3\n  variable value           n\n  <chr>    <fct>       <int>\n1 S1       Männer       8486\n2 S1       Frauen       8127\n3 m1202    ohne          899\n4 m1202    dual/schul.  7723\n5 m1202    Aufst.       1469\n6 m1202    FH/Uni       6522\n\n\n\netb18_kap14 %>%  \n  select(S1,m1202) %>% \n  mutate(S1 = factor(S1,levels = 1:2, labels = c(\"Männer\",\"Frauen\")),\n           m1202 = factor(m1202, levels = 1:4,labels = c(\"ohne\",\"dual/schul.\",\"Aufst.\",\"FH/Uni\"))) %>% \n  pivot_longer(everything(),names_to = \"variable\") %>% \n  count(variable,value) %>% \n  flextable()\n\n\nvariablevaluenS1Männer8,486S1Frauen8,127m1202ohne899m1202dual/schul.7,723m1202Aufst.1,469m1202FH/Uni6,522\n\n\n\nkat_ft <- \n  etb18_kap14 %>%  \n    select(S1,m1202) %>% \n    mutate(S1 = factor(S1,levels = 1:2, labels = c(\"Männer\",\"Frauen\")),\n           m1202 = factor(m1202, levels = 1:4,labels = c(\"ohne\",\"dual/schul.\",\"Aufst.\",\"FH/Uni\"))) %>% \n    pivot_longer(everything(),names_to = \"variable\") %>% \n    count(variable,value)  %>% \n  flextable()\n\nFür den Export können wir dann wieder save_as_docx() verwenden:\n\nsave_as_docx(\"Kategoriale unab. Variablen\" = kat_ft, path = \"./results/Kat_UVs_Tabelle.docx\")\n\n\n\n\n\n\n\n\n\n\n\n\n13.2.3 Übung"
  },
  {
    "objectID": "14_tabellenexport.html#regressionstabellen",
    "href": "14_tabellenexport.html#regressionstabellen",
    "title": "13  Tabellenexport",
    "section": "13.3 Regressionstabellen",
    "text": "13.3 Regressionstabellen\nFür Regressionstabellen können wir mit {modelsummary} eine {flextable}-Tabelle erstellen:\n\netb18_kap14_reg_df <- \n  etb18_kap14 %>%\n  mutate(S1 = factor(S1,levels = 1:2, labels = c(\"Männer\",\"Frauen\")),\n         m1202 = factor(m1202, levels = 1:4,labels = c(\"ohne\",\"dual/schul.\",\"Aufst.\",\"FH/Uni\")))\n\nm1 <- lm(F518_SUF ~ az + S1, data = etb18_kap14_reg_df)\nm2 <- lm(F518_SUF ~ az + S1 + m1202, data = etb18_kap14_reg_df)\nmodelsummary(list(\"Modell 1\"=m1,\"Modell 2\"=m2),\n                                output = \"flextable\",gof_omit = \"IC|Log|RMS\",\n                           coef_rename = c(\"(Intercept)\"=\"Intercept\",\n                                           \"S1Frauen\" = \"Frauen\",\n                                           \"m1202dual/schul.\" = \"Duale/Schulische Ausbildung\",\n                                           \"m1202Aufst.\" = \"Aufstiegsfortbildung\",\n                                           \"m1202FH/Uni\" = \"FH/Uni-Abschluss\"),\n                           stars = T,fmt =2)\n\n\n Modell 1Modell 2Intercept362.15***-385.14**(106.17)(140.07)az91.65***83.39***(2.36)(2.31)Frauen-684.47***-725.04***(54.93)(53.38)Duale/Schulische Ausbildung395.98***(113.49)Aufstiegsfortbildung910.33***(136.63)FH/Uni-Abschluss2085.47***(114.96)Num.Obs.1661316613R20.1210.174R2 Adj.0.1210.174F1139.534702.027+ p < 0.1, * p < 0.05, ** p < 0.01, *** p < 0.001\n\n\n\n13.3.1 Referenzkategorien einfügen\nUm die Referenzkategorie für kategoriale Variablen kenntlich zu machen, können wir den Hinweis ref. mitaufanzeigen.\nDazu können wir mit Hilfe des Arguments add_rows eine zusätzliche Zeile für die Referenzkategorie der Variable S1 einfügen. Zunächst erstellen wir einen data.frame, welcher neben den Modellnamen die Koeffizientennamen sowie die einzufügenden Werte enthält. Mit tribble aus dem Paket tibble lässt sich das einfach bewerkstelligen: wir können die Zeilen und Spalten gleich so aufschreiben, wie wir sie haben möchten:\n\nlibrary(tibble)\nref_rows <- tribble( ~ term,    ~ \"Modell 1\",  ~ \"Modell 2\",\n                     \"Männer\",    'ref.',   'ref.')\nattr(ref_rows, 'position') <- 5 # Zeile angeben \n\nmodelsummary(\n  list(\"Modell 1\" = m1, \"Modell 2\" = m2),\n  output = \"flextable\",\n  gof_omit = \"IC|Log|RMS\",\n  coef_rename = c(\n    \"(Intercept)\" = \"Intercept\",\n    \"S1Frauen\" = \"Frauen\",\n    \"m1202dual/schul.\" = \"Duale/Schulische Ausbildung\",\n    \"m1202Aufst.\" = \"Aufstiegsfortbildung\",\n    \"m1202FH/Uni\" = \"FH/Uni-Abschluss\"\n  ),\n  add_rows = ref_rows,\n  stars = T,\n  fmt = 2\n) %>% autofit()\n\n\n Modell 1Modell 2Intercept362.15***-385.14**(106.17)(140.07)az91.65***83.39***(2.36)(2.31)Männerref.ref.Frauen-684.47***-725.04***(54.93)(53.38)Duale/Schulische Ausbildung395.98***(113.49)Aufstiegsfortbildung910.33***(136.63)FH/Uni-Abschluss2085.47***(114.96)Num.Obs.1661316613R20.1210.174R2 Adj.0.1210.174F1139.534702.027+ p < 0.1, * p < 0.05, ** p < 0.01, *** p < 0.001\n\n\nDas funktioniert auch für mehrere Referenzkategorien:\n\nref_rows2 <- tribble(~term,    ~\"Modell 1\",  ~\"Modell 2\",\n                \"Männer\",    'ref.',   'ref.',\n                \"keine Ausbildung\",    '',   'ref.',\n                )\nattr(ref_rows2, 'position') <- c(5,8) # Zeile angeben \n\nmodelsummary(\n  list(\"Modell 1\" = m1, \"Modell 2\" = m2),\n  output = \"flextable\",\n  gof_omit = \"IC|Log|RMS\",\n  coef_rename = c(\n    \"(Intercept)\" = \"Intercept\",\n    \"S1Frauen\" = \"Frauen\",\n    \"m1202dual/schul.\" = \"Duale/Schulische Ausbildung\",\n    \"m1202Aufst.\" = \"Aufstiegsfortbildung\",\n    \"m1202FH/Uni\" = \"FH/Uni-Abschluss\"\n  ),\n  add_rows = ref_rows2,\n  stars = T,\n  fmt = 2\n)\n\n\n Modell 1Modell 2Intercept362.15***-385.14**(106.17)(140.07)az91.65***83.39***(2.36)(2.31)Männerref.ref.Frauen-684.47***-725.04***(54.93)(53.38)keine Ausbildungref.Duale/Schulische Ausbildung395.98***(113.49)Aufstiegsfortbildung910.33***(136.63)FH/Uni-Abschluss2085.47***(114.96)Num.Obs.1661316613R20.1210.174R2 Adj.0.1210.174F1139.534702.027+ p < 0.1, * p < 0.05, ** p < 0.01, *** p < 0.001\n\n\n\n\n\n\n\n\nTipparbeit beim Umbenennen sparen mit coef_rename =\n\n\n\n\n\nMit Hilfe der Option coef_rename = und einer function() können wir die Variablenumbenennung auch automatisieren. Mehr dazu hier Dazu erstellen wir eine Funktion erstellen, welche bspw. mit gsub() Variablennamen durch die gewünschte Beschriftung ersetzt:\n\nrename_function <- function(old_names) {\n  new_names <- \n    gsub(\"m1202\", \"Ausbildung: \", old_names) %>% \n    gsub(\"S1\", \"Geschlecht: \",.) %>% \n    gsub(\"az\", \"Arbeitszeit (h) \",.)\n  \n  return(setNames(new_names, old_names))\n}\n\n## diese Funktion dann in modelsummary verwenden:\nmodelsummary(list(\"Modell 1\" = m1, \"Modell 2\" = m2),\n             output = \"flextable\",gof_omit = \"IC|Log|RMS\", \n             coef_rename = rename_function) # function anwenden\n\n\n Modell 1Modell 2(Intercept)362.146-385.135(106.167)(140.070)Arbeitszeit (h) 91.65283.387(2.364)(2.312)Geschlecht: Frauen-684.473-725.039(54.926)(53.379)Ausbildung: dual/schul.395.981(113.488)Ausbildung: Aufst.910.327(136.635)Ausbildung: FH/Uni2085.465(114.957)Num.Obs.1661316613R20.1210.174R2 Adj.0.1210.174F1139.534702.027\n\n\n\n\n\nAuf den mit {modelsummary} erstellten flextable können wir natürlich auch alle Funktionen für flextable anwenden und dann mit save_as_docx() die Tabelle exportieren:\n\nregtab2 <- \n  modelsummary(\n  list(\"Modell 1\" = m1, \"Modell 2\" = m2),\n  output = \"flextable\",\n  gof_omit = \"IC|Log|RMS\",\n  coef_rename = c(\n    \"(Intercept)\" = \"Intercept\",\n    \"S1Frauen\" = \"Frauen\",\n    \"m1202dual/schul.\" = \"Duale/Schulische Ausbildung\",\n    \"m1202Aufst.\" = \"Aufstiegsfortbildung\",\n    \"m1202FH/Uni\" = \"FH/Uni-Abschluss\"\n  ),\n  add_rows = ref_rows2,\n  stars = T,\n  fmt = 2) %>% \n  autofit() %>% \n  italic(i = ~ `Modell 2` == \"ref.\",j =2:3)\n\n\nsave_as_docx(regtab2,path = \"./results/regressionstabelle.docx\")"
  },
  {
    "objectID": "14_tabellenexport.html#alle-tabellen-in-eine-datei-mit-officer",
    "href": "14_tabellenexport.html#alle-tabellen-in-eine-datei-mit-officer",
    "title": "13  Tabellenexport",
    "section": "13.4 Alle Tabellen in eine Datei mit {officer}",
    "text": "13.4 Alle Tabellen in eine Datei mit {officer}\nUm die Tabellen in Dokument gemeinsames Dokument zu exportieren, ist das Paket officer eine große Hilfe. Mehr Infos hier.\n\nlibrary(officer)\n\nZunnächst lesen wir mit read_docx() eine Vorlage ein, welche Einstellungen für das Word-Dokument enthält (Seitenformat,..) und fügen dann mit body_add_flextable() die Tabellen ein. Mit body_add_par(.,\"\") können wir leere Absätze einfügen.\n\nread_docx(\"pfad/zur/Vorlage/DIN_A4_Vorlage.docx\") %>%\n   body_add_flextable(., value = met_ft ) %>% # flextable met_ft einfügen\n   body_add_par(.,\"\") %>% # leeren Absatz einfügen\n   body_add_flextable(., value = kat_ft ) %>% # flextable cat_ft einfügen\n   print(target = \"./results/Descriptives_final.docx\")"
  },
  {
    "objectID": "14_tabellenexport.html#übung-1",
    "href": "14_tabellenexport.html#übung-1",
    "title": "13  Tabellenexport",
    "section": "13.5 Übung",
    "text": "13.5 Übung\n\n13.5.1 Übung\n\netb_ue14 <- \n  haven::read_dta(\"./data/BIBBBAuA_2018_suf1.0.dta\",col_select = c(\"gkpol\",\"az\",\"zpalter\",\"m1202\"))%>% \n  filter(zpalter < 100, m1202 > 0) %>% \n  mutate(gkpol = factor(gkpol,levels = 1:7, labels = c(\"<2k\", \"2k bis <5k\", \"5k bis <20k\", \"20k bis <50k\", \"50k bis <100k\", \n                                                         \"100k bis <500k\", \"500k und mehr\")),\n           m1202 = factor(m1202, levels = 1:4,labels = c(\"ohne\",\"dual/schul.\",\"Aufst.\",\"FH/Uni\"))) \n\n\nErstellen Sie eine Übersicht für die Variablen zpalter (Alter) und az (Arbeitszeit) und exportieren Sie diese in eine Word-Datei. Verwenden Sie den obigen Einlesebefehl - dann sind die Missings bereits ausgeschlossen,\n\nErstellen Sie zunächst einen data.frame mit min, mean und max der beiden Variablen.\nFormatieren Sie diesen data.frame dann als flextable\nSpeichern Sie diesen mit save_as_docx()\n\nErstellen Sie eine Übersichtstabelle zu gkpol (Größe der Wohngemeinde) und m1202 (Ausbildung).\n\nDie Labels sind bereits im obigen Einlesebefehl gesetzt.\n\n\n\n\n13.5.2 Übung\n\nErstellen sie folgende Regressionsmodelle und erstellen Sie mit {modelsummary} eine Regressiontabelle:\n\n\nm1 <- lm(az ~ m1202 , etb_ue14)\nm2 <- lm(az ~ m1202 + zpalter, etb_ue14)"
  },
  {
    "objectID": "14_tabellenexport.html#anhang",
    "href": "14_tabellenexport.html#anhang",
    "title": "13  Tabellenexport",
    "section": "13.6 Anhang",
    "text": "13.6 Anhang\n\n13.6.1 Kreuztabellen\n\n\n\nGeschlechtAusbildungMännerFrauenTotalohne500399899dual/schul.3,7164,0077,723Aufst.9125571,469FH/Uni3,3583,1646,522Total8,4868,12716,613\n\n\nHier ist die Herausforderung, einen data.frame() für {flextable} vorzubereiten: xtabs() gibt keinen data.frame aus und meistens ist der long shape Output von count() auch nicht das was wir wollen:\n\ntab1 <- xtabs(~S1+m1202,etb18_kap14)\nclass(tab1)\n\n[1] \"xtabs\" \"table\"\n\n\n\netb18_kap14 %>% \n  mutate(S1 = factor(S1,levels = 1:2, labels = c(\"Männer\",\"Frauen\"))) %>% # zahlenwerte in S1 mit labels überschreiben \n  mutate(m1202 = factor(m1202, levels = 1:4,labels = c(\"ohne\",\"dual/schul.\",\"Aufst.\",\"FH/Uni\"))) %>% # auch für m1202\n  count(S1,m1202) %>% \n  flextable()\n\n\nS1m1202nMännerohne500Männerdual/schul.3,716MännerAufst.912MännerFH/Uni3,358Frauenohne399Frauendual/schul.4,007FrauenAufst.557FrauenFH/Uni3,164\n\n\ntabyl() aus {janitor} hilft hier weiter:\n\nlibrary(janitor)\netb18_kap14 %>% \n  mutate(S1 = factor(S1,levels = 1:2, labels = c(\"Männer\",\"Frauen\"))) %>% # zahlenwerte in S1 mit labels überschreiben \n  mutate(m1202 = factor(m1202, levels = 1:4,labels = c(\"ohne\",\"dual/schul.\",\"Aufst.\",\"FH/Uni\"))) %>% # auch für m1202\n  tabyl(m1202,S1) %>%\n    adorn_totals(where = c(\"row\",\"col\")) \n\n       m1202 Männer Frauen Total\n        ohne    500    399   899\n dual/schul.   3716   4007  7723\n      Aufst.    912    557  1469\n      FH/Uni   3358   3164  6522\n       Total   8486   8127 16613\n\n\n\n\n\n\n\n\nTip\n\n\n\nÜbrigens: Mit adorn_percentages() können wir bspw. statt absoluten Häufigkeiten die prozentualen Anteile ausgeben lassen. Weitere adorn_...() Funktionen in der Vignette.\n\n\n\netb18_kap14 %>% \n  mutate(S1 = factor(S1,levels = 1:2, labels = c(\"Männer\",\"Frauen\"))) %>% # zahlenwerte in S1 mit labels überschreiben \n  mutate(m1202 = factor(m1202, levels = 1:4,labels = c(\"ohne\",\"dual/schul.\",\"Aufst.\",\"FH/Uni\"))) %>% # auch für m1202\n  tabyl(m1202,S1) %>%\n    adorn_totals(where = c(\"row\",\"col\"))  %>%\n  flextable() %>%\n  border_remove() %>% # linien raus\n  hline(i=4) %>% # in zeile 4 eine Linie einfügen\n  hline_top() %>% # linie oben\n  set_header_labels(m1202 = \"Ausbildung\") %>%  # kopf-label links\n  add_header_row(values = c(\"\",\"Geschlecht\",\"\"),colwidths = c(1,2,1)) # label oben\n\n\nGeschlechtAusbildungMännerFrauenTotalohne500399899dual/schul.3,7164,0077,723Aufst.9125571,469FH/Uni3,3583,1646,522Total8,4868,12716,613\n\n\n\ncross_tab <- \n  etb18_kap14 %>% \n    mutate(S1 = factor(S1,levels = 1:2, labels = c(\"Männer\",\"Frauen\"))) %>% # zahlenwerte in S1 mit labels überschreiben \n    mutate(m1202 = factor(m1202, levels = 1:4,labels = c(\"ohne\",\"dual/schul.\",\"Aufst.\",\"FH/Uni\"))) %>% # auch für m1202\n    tabyl(m1202,S1) %>%\n      adorn_totals(where = c(\"row\",\"col\"))  %>%\n    flextable() %>%\n    border_remove() %>% # linien raus\n    hline(i=4) %>% # in zeile 4 eine Linie einfügen\n    hline_top() %>% # linie oben\n    set_header_labels(m1202 = \"Ausbildung\") %>%  # kopf-label links\n    add_header_row(values = c(\"\",\"Geschlecht\",\"\"),colwidths = c(1,2,1)) # label oben\n\n\nsave_as_docx(\"Kreuztabelle\" = cross_tab, path = \"./results/Kreuztabelle.docx\")\n\n\n\n13.6.2 Layout-Tipps für Tabellen\nHier finden sich einige Hinweise von Claus Wilke für ein gelungenes Tabellen-Layout:\n\nDo not use vertical lines.\nDo not use horizontal lines between data rows. Horizontal lines as separator between the title row and the first data row or as frame for the entire table are fine.\nText columns should be left aligned.\nNumber columns should be right aligned and should use the same number of decimal digits throughout.\nColumns containing single characters are centered.\nThe header fields are aligned with their data, i.e., the heading for a text column will be left aligned and the heading for a number column will be right aligned.\n\n\n\n13.6.3 weitere Pakete\nNeben {flextable} gibt es noch eine ganze Reihe an weiteren Paketen - allerdings sind zielen diese vor allem auf pdf und HTML-Formate. Hier findet sich eine gelungene Übersicht. Hier eine Übersicht mit meiner persönlichen Einschätzung1\n\n\nCode\n# create table-table with gt\npkg_tabl <- \nlist(\n  printer = c(\"gt\", \"flextable\", \"kableExtra\"),\n  output = c(\"HTML\", \"PDF\", \"Word\")\n) %>%\n  purrr::cross_df() %>%\n  dplyr::mutate(\n    rating = dplyr::case_when(\n      printer == \"gt\" & output == \"HTML\" ~ 1, # good output\n      printer == \"gt\" & output %in% c(\"Word\") ~ 5, # under construction\n      printer == \"gt\" & output %in% c(\"PDF\") ~ 3, # under construction\n      \n      \n      printer == \"flextable\" & output == \"Word\" ~ 1, # bester\n      printer == \"flextable\" & output %in% c(\"HTML\",\"PDF\") ~ 2, # okay\n      \n      printer == \"kableExtra\" & output %in% c(\"PDF\", \"HTML\") ~ 1, # good output\n      printer == \"kableExtra\" & output %in% c(\"Word\") ~ 4, # not supported\n      \n      \n    ) %>%\n      factor()\n  ) %>%\n  tidyr::pivot_wider(id_cols = printer, names_from = output, values_from = rating) %>%\n  dplyr::mutate(\n    link = dplyr::case_when(\n      printer == \"gt\" ~ \n        \"[gt](https://gt.rstudio.com/index.html)\",\n      printer == \"kable\" ~ \n        \"[kable](https://bookdown.org/yihui/rmarkdown-cookbook/kable.html)\",\n      printer == \"flextable\" ~\n        \"[flextable](https://davidgohel.github.io/flextable/articles/overview.html)\",\n      printer == \"kableExtra\" ~ \n        \"[kableExtra](http://haozhu233.github.io/kableExtra/)\",\n      printer == \"huxtable\" ~\n        \"[huxtable](https://hughjonesd.github.io/huxtable/)\",\n      printer == \"tibble\" ~ \n        \"[tibble](https://tibble.tidyverse.org/)\"\n    )\n  ) %>%\n  gt() %>%\n  cols_move_to_start(columns = c(link)) %>%\n  cols_hide(columns = c(printer)) %>%\n  cols_label(link = md(\"**Paket**\"), \n             \n             HTML = md(\"**HTML**\"), PDF = md(\"**PDF**\"), \n             Word = md(\"**Word**\")) %>%\n  fmt_markdown(columns = c(link)) %>%\n  fmt_markdown(columns = everything()) %>%\n  data_color(\n    columns = c(HTML, PDF, Word),\n    colors = scales::col_factor(\n      palette = c(\"#bae1ff\", \"#ffb3ba\", \"#ffdfba\", \"#ffffba\", \"#baffc9\"),\n      domain = NULL,\n      reverse = TRUE\n    ),\n    alpha = 0.8\n  ) %>%\n  cols_width(c(HTML, PDF, Word) ~ px(60),\n             c(link) ~ px(110),\n             c(link) ~ px(140))\n  \n# Emoji library: https://gist.github.com/rxaviers/7360908\n\npkg_tabl %>% \n  text_transform(\n    locations = cells_body(columns = c(HTML, PDF,  Word)),\n    fn = function(x) {\n      dplyr::case_when(\n          x == 1 ~ as.character(emo::ji(\"star\")),\n          x == 2 ~ as.character(emo::ji(\"heavy_check_mark\")),\n          x == 3 ~ as.character(emo::ji(\"grey_question\")),\n          x == 4 ~ as.character(emo::ji(\"o2\")),\n          x == 5 ~ as.character(emo::ji(\"wrench\")),\n          TRUE   ~ as.character(emo::ji(\"o2\"))\n      )\n    }\n  )\n\n\n\n\n\n\n  \n    \n    \n    \n    \n  \n  \n  \n    \n      Paket\n      HTML\n      PDF\n      Word\n    \n  \n  \n    gt\n\n⭐\n❔\n🔧\n    flextable\n\n✔️\n✔️\n⭐\n    kableExtra\n\n⭐\n⭐\n🅾️\n  \n  \n  \n\n\n\n\n\n{kableExtra} - mein Favorit für Tabellen in html und pdf Outputs.\n{gt} Großes Projekt mit sehr vielen Möglichkeiten, Tabellen auch interaktiv zu gestalten - daher vor allem für HTML-Outputs geeignet.\n{gtsummary} - {gt} speziell für Deskriptionen eines Treatment/Control Vergleich, hier eine aktuelle Einführung\n\n\n\nOh my goodness, oh my goodness, oh my goodness!🎆{gt}📦v0.7.0 is on CRAN and includes support for WORD OUTPUT---WORD! 🕺🪩🕺Thank you @riannone & @ellis_hughes ❤️#RStats https://t.co/t2gKOfni1O pic.twitter.com/dxM5NwU09v— Daniel Sjoberg (@statistishdan) August 26, 2022\n\n\n\nWeitere Tabellenpakete:\n\n{huxtable}\n{DT}\n{reactable}"
  },
  {
    "objectID": "15_RMarkdown.html",
    "href": "15_RMarkdown.html",
    "title": "14  RMarkdown",
    "section": "",
    "text": "{rmarkdown} erlaubt, formatierte Textelemente mit Markdown und R code bzw. Output zu kombinieren. Anders als ein R Script enthält ein RMarkdown-Dokument nicht nur Befehle, sondern auch Text - welcher mit Hilfe von Markdown-Befehlen formatiert werden kann. So können Grafiken, Tabellen, usw. direkt und zeitgleich mit dem Begleittext erstellt werden. Mit R Markdown können wir HTML, PDF, Word Dokumente, PowerPoint und HTML Präsentationen, Webseiten und Bücher erstellen. Diese gesamte Webseite wurde mit {R Markdown} bzw. dem verwandten Paket {Quarto} erstellt.\nDieses Kapitel kann lediglich eine kleine Einführung in RMarkdown sein. Die Hilfeseiten und Dokumentation für R Markdown ist extrem umfangreich und auch die Tutorials und Cheatsheets sind hervorragend. Daher hier nur eine kleiner Überblick.\nEin RMarkdown-Dokument sieht in seiner Grundform ungefähr so aus:"
  },
  {
    "objectID": "15_RMarkdown.html#rmarkdown-dokument-einrichten",
    "href": "15_RMarkdown.html#rmarkdown-dokument-einrichten",
    "title": "14  RMarkdown",
    "section": "14.1 RMarkdown Dokument einrichten",
    "text": "14.1 RMarkdown Dokument einrichten\nEin RMarkdown-Dokument können wir entweder einrichten, indem wir über das Menü File -> R Markdown… das Einrichtungsmenü aufrufen. Hier können wir den Titel, Autorennamen und das Datum sowie das Output-Format angeben:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlternativ können wir auch rechts unten ein R Skript in RMarkdown-Dokument umformatieren:\n\n\n\n\n\n\n\n\n\nRMarkdown-Dateien haben die Dateiendung .rmd. Das Knitten einer RMarkdown-Datei findet in einer neuen Umgebung statt - d.h. hier müssen alle Pakete und Daten geladen werden, auch wenn Sie in der Session bereits geladen sind."
  },
  {
    "objectID": "15_RMarkdown.html#wichtige-begriffe",
    "href": "15_RMarkdown.html#wichtige-begriffe",
    "title": "14  RMarkdown",
    "section": "14.2 Wichtige Begriffe",
    "text": "14.2 Wichtige Begriffe\n\nChunk: Abschnitt mit R-Code innerhalb eines RMarkdown-Dokuments.\n\n```{r}\n# hier kommt der R Code hin\n```\n\nVor und nach dem Chunk muss eine Leerzeile stehen. Die letzten drei Backticks müssen alleine in der letzten Zeile eines chunks stehen.\n\nKnit: Beim “knitten” eines RMarkdown Dokuments, werden zuerst alle chunks ausgeführt und der jeweilige Output in Markdown konvertiert. Im Anschluss ruft R pandoc auf um, den Markdown-Text in HTML, PDF oder Word zu konvertieren.\n\nKnitten kann entweder über das “Knit”-Symbol oben im Editor mit der Tastenkombination ⌘⇧K auf macOS oder STRG + ⇧ + k in Windows"
  },
  {
    "objectID": "15_RMarkdown.html#chunks-einfügen",
    "href": "15_RMarkdown.html#chunks-einfügen",
    "title": "14  RMarkdown",
    "section": "14.3 Chunks einfügen",
    "text": "14.3 Chunks einfügen\nWir können neue chunks auf zwei Arten erstellen\n\nMit ⌘⌥I auf macOS oder STRG + alt + I auf Windows-Rechnern. Funktioniert auch, um einen existierenden chunck in zwei Teile zu teilen.\nMit dem “Insert” Button oben im Editor:"
  },
  {
    "objectID": "15_RMarkdown.html#namen-für-chunks",
    "href": "15_RMarkdown.html#namen-für-chunks",
    "title": "14  RMarkdown",
    "section": "14.4 Namen für chunks",
    "text": "14.4 Namen für chunks\nWir können den Abschnitten Namen hinzufügen, um die Navigation innerhalb des Dokument zu erleichtern. Wenn wir in RStudio auf das kleine Dropdown-Menü (mit dem #) am unteren Rand des Editors klicken, bekommen wir ein Inhaltsverzeichnis, das alle Überschriften und Abschnitte anzeigt. Wenn wir die Abschnitte benennen, werden sie in der Liste angezeigt. Wenn Sie keinen Namen angeben, wird der Chunk trotzdem angezeigt, aber Sie wissen nicht, was er tut.\n\n\n\n\n\n\n\n\n\nNamen werden direkt nach dem {r in der ersten Zeile des chunks angegeben. Leerzeichen sind in chunk-Namen nicht erlaubt, aber Unterstriche und Bindestriche. Jeder chunk-Name darf innerhalb eines Dokuments nur einmal vergeben werden.\n```{r chunk_Name}\n# R Code\n```"
  },
  {
    "objectID": "15_RMarkdown.html#chunk-optionen",
    "href": "15_RMarkdown.html#chunk-optionen",
    "title": "14  RMarkdown",
    "section": "14.5 Chunk-Optionen",
    "text": "14.5 Chunk-Optionen\nWir haben eine Reihe an Möglichkeiten festzulegen, wie RMarkdown mit Chunks umgehen soll. Eine vollständige Übersicht findest sich im RMarkdown Reference Guide oder auf der Webseite von knitr.\nOptionen werden in der ersten Zeile eines chunks nach dem {r} festgelegt:\n```{r name-of-this-chunk, warning=FALSE, message=FALSE}\n# Code goes here\n```\nHier eine kleine Liste der wichtigsten Optionen:\n\nfig.width=5 & fig.height=4: Größe von Plots\necho=FALSE: Der chunk wird zwar ausgeführt und das Ergebnis im Zieldokument gezeigt, nicht aber der Code\ninclude=FALSE: Der chunk wird zwar ausgeführt, aber im Zieldokument werden weder der Code selbst noch das Ergebnis gezeigt\neval=FALSE: Der chunk wird nicht ausgeführt, aber im Zieldokument gezeigt\nmessage=FALSE: messages werden ausgeblendet (bspw. alles was beim Laden von Paketen angezeigt wird)\nwarning=FALSE: warnings werden ausgeblendet\n\nAußerdem können Optionen auch mit einem Klick auf das Zahnrad rechts oben in einem Chunk gesetzt werden:"
  },
  {
    "objectID": "15_RMarkdown.html#inline-chunks",
    "href": "15_RMarkdown.html#inline-chunks",
    "title": "14  RMarkdown",
    "section": "14.6 Inline chunks",
    "text": "14.6 Inline chunks\nEine weitere Stärke von RMarkdown ist, dass Ergebnisse direkt im Text dargestellt werden können. Dazu dienen “inline chunks”, um bspw. Kennzahlen aus einer Analyse einzufügen `r R Code`.\nSo können wir bspw. Werte in einem Chunk berechnen und dann in den Text einfügen.\n```{r find-avg-mpg, echo=FALSE}\nmedian_mpg <- mean(mtcars$mpg)\n```\n\nIm Median haben die Fahrzeuge einen Verbrauch von `r round(median_mpg, 1)` miles per gallon.\n… führt zu folgendem Ergebnis:\n\nIm Median haben die Fahrzeuge einen Verbrauch von 19.2 miles per gallon."
  },
  {
    "objectID": "15_RMarkdown.html#output-yaml",
    "href": "15_RMarkdown.html#output-yaml",
    "title": "14  RMarkdown",
    "section": "14.7 Output & yaml",
    "text": "14.7 Output & yaml\nAls yaml bezeichnet man die Kopfzeile der RMarkdown-Dokumente. Hier können wir allerhand Voreinstellungen festlegen, insbesondere das Zieldateiformat.\nDas erste unter output aufgeführte Dateiformat ist der, der erzeugt wird, wenn wir auf die Schaltfläche “knit” klicken oder das Tastaturkürzel (⌘⇧K” unter macOS; ” STRG + Umschalt + K” unter Windows) drücken.\nDie Einrückung im YAML-Abschnitts ist von Bedeutung, insbesondere dann, wenn unter den einzelnen Ausgabetypen verschachtelte Einstellungen vorhanden sind. So könnte ein typischer Output-Abschnitt aussehen, unter anderem können wir auch Word-Dokument als Formatierungsvorlage angeben:\n---\ntitle: \"Mein Worddokument\"\nauthor: \"My name\"\ndate: \"13. August 2022\"\noutput: \n  word_document: \n    reference_docx: \"Vorlage.docx\"\n    toc: yes\n    fig_caption: yes\n    fig_height: 4\n    fig_width: 5\n---\nAuch für die anderen Output-Formate gibt es einen YAML-Befehl:\n---\ntitle: \"My document\"\noutput:\n  html_document: default\n  pdf_document: default\n  word_document: default\n---\nEine Übersicht findet zu verschiedenen Optionen findet sich bspw. hier oder hier für Word, HTML, PDF oder Powerpoint\nAlternativ lassen sich auch mit den Zahnrad oben neben dem Knit-Button Einstellungen für den YAML-Header festlegen:"
  },
  {
    "objectID": "15_RMarkdown.html#fortgeschrittene-erstellung-von-word-dokumenten-mit-officedown",
    "href": "15_RMarkdown.html#fortgeschrittene-erstellung-von-word-dokumenten-mit-officedown",
    "title": "14  RMarkdown",
    "section": "14.8 Fortgeschrittene Erstellung von Word-Dokumenten mit {officedown}",
    "text": "14.8 Fortgeschrittene Erstellung von Word-Dokumenten mit {officedown}\nMit {officedown} können wir bspw. Querverweise einbauen:\n\ninstall.packages(\"officedown\")\n\n---\ntitle: \"Mein zweites RMarkdown-Dokument\"\nauthor: \"Dein Name\"\ndate: \"2022-09-11\"\noutput:\n  officedown::rdocx_document\n---\n\n```{r setup, include=FALSE}\nlibrary(tidyverse)\nlibrary(officedown)\netbx <-  haven::read_dta(\"./data/BIBBBAuA_2018_suf1.0.dta\", \n                         n_max = 2000,\n                         col_select = c(\"S1\",\"F518_SUF\",\"m1202\",\"az\",\"zpalter\",\"F1605e\")) %>% \n  filter(F518_SUF < 99998, m1202 %in% 1:4, zpalter < 9999 ) %>% \n  mutate(ausb = factor(m1202, levels = 1:4, labels = c(\"ohne\",\"dual/schul.\",\"Aufst.\",\"FH/Uni\")),\n         S1 = factor(S1,levels = 1:2,labels =c(\"m\",\"w\")))\n```\n\n```{r tab.cap=\"Eine Tabelle\", echo=FALSE,  tab.id='tab2'}\netbx %>% count(ausb)\n```\n\n\nDies ist ein Querverweis auf Tabelle \\@ref(tab:tab2)."
  },
  {
    "objectID": "15_RMarkdown.html#übung",
    "href": "15_RMarkdown.html#übung",
    "title": "14  RMarkdown",
    "section": "14.9 Übung",
    "text": "14.9 Übung\n\nVerwenden Sie das 14_Markdown.Rmd-Datei als Vorlage\nPassen Sie den Verfasser:innen-Namen und Datum an\nPassen Sie ggf. den Pfad zum Datensatz an. Beachten Sie, dass der Pfad relativ zum Datenspeicherort sein muss\nFügen Sie einen chunk mit einer Auszählung von ausb ein\nFügen Sie einen chunk mit einem summarise()-Befehl ein - bspw.: ::: {.cell layout-align=“center”}\n\netbx %>% \n  group_by(S1,ausb) %>% \n  summarise(min =  min(F518_SUF,na.rm = T),\n            mean = mean(F518_SUF,na.rm = T),\n            max =  max(F518_SUF,na.rm = T))\n:::\n\nSetzen Sie include, echo usw. nach Wunsch.\nFügen nach Geschmack auch {flextable}-Befehle ein (Denken Sie an library(flextable) zu laden)\nKnitten Sie das Dokument zu einer Word-Dokument."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Links & Weiterführendes",
    "section": "",
    "text": "In diesem Kurs haben wir die Pipe %>% aus {tidyverse} (streng genommen aus dem Paket {magrittr}) kennen gelernt. Mit dem Update auf R 4.1 wurde in base R ebenfalls eine Pipe |> eingeführt und Hilfeseiten usw. ersetzen langsam, aber sicher %>% durch |>. Für (nahezu) alle Anwendungen, die wir kennengelernt haben, verhalten sich beide Pipes identisch - und nachdem am BIBB R die R-Version 4.0.5 zur Verfügung steht, haben wir uns an ‘alte Variante’ gehalten. Letztlich spricht aber nichts dagegen, nach einem Update auf |> umzusteigen - oder einfach bei %>% zu bleiben.\n\nUnter anderem steht hier mehr zu den Unterschieden zwischen beiden Pipes. Außerdem bietet dieser Blogbeitrag einen guten Überblick zu den Fallstricken beim Umstieg von %>% auf |>."
  },
  {
    "objectID": "references.html#anonymfun",
    "href": "references.html#anonymfun",
    "title": "Links & Weiterführendes",
    "section": "Anonyme Funktionen: .x vs. /(x)",
    "text": "Anonyme Funktionen: .x vs. /(x)\nMit R 4.1.0 wurde in base R eine neue ‘anonymous function short hand’ eingeführt, welche die ‘formula syntax’ Schreibweise ~mean(.x) ablöst, die wir in Kapitel 6 kennen gelernt haben. In der neuen base R wäre das \\(x) mean(x) geschrieben.\nAus der {purrr} release notes für Version 1.0.0 (Dezember 2022): We believe that it’s better to use these new base tools because they work everywhere: the base pipe doesn’t require that you load magrittr and the new function shorthand works everywhere, not just in purrr functions. Additionally, being able to specify the argument name for the anonymous function can often lead to clearer code.\nDementsprechend würde die Anwendung in across() wie folgt aussehen:\n\nsat_small <- haven::read_dta(\"./data/BIBBBAuA_2018_suf1.0.dta\",n_max = 16) %>% \n    select(F1450_04,F1450_05,F1450_06) %>% \n    slice(12:16)\n\n# formula syntax\nsat_small %>% \n  mutate(across(matches(\"F1450\"),~mean(.x)))\n# anonymous function short hand\nsat_small %>% \n  mutate(across(matches(\"F1450\"),\\(x) mean(x) ))\n\nIn diesem Skript habe ich auf die bisherige ‘formula syntax’ Schreibweise zurück gegriffen, da aktuell noch die meisten Hilfeseite mit dieser Syntax arbeiten."
  },
  {
    "objectID": "references.html#quarto",
    "href": "references.html#quarto",
    "title": "Links & Weiterführendes",
    "section": "Quarto",
    "text": "Quarto\nQuarto ist eine Erweiterung/Weiterentwicklung von RMarkdown. Allerdings erfordert Quarto eine separate Installation, mehr Infos."
  },
  {
    "objectID": "references.html#einführungen-in-r",
    "href": "references.html#einführungen-in-r",
    "title": "Links & Weiterführendes",
    "section": "Einführungen in R",
    "text": "Einführungen in R\nEine Sammlung von Lehrskripten und Unterlagen aus verschiedenen Kontexten zum selbst weiter lernen:\nR for Data Science das Standardwerk für Datenanalysen mit {tidyverse} - sehr intuitive Einführung, Fokus auf Data Science\nProblemorientiere Einführungen in spezifische Anwendungen “do more with R”\nTen simple rules for teaching yourself R\nModerne Datenanalyse mit R: Deutschsprachige Einführung in {tidyverse}\nR for the Rest of Us bietet viele Tutorials und freie Kurse an, unter anderem auch viele YouTube Videos.\nStata 2 R richtet sich alle Anwender*innen von Stata, die auf R umsteigen möchten. Allerdings wird hier anstelle des {tidyverse} das Paket {data.table} für die Datenaufbereitung gezeigt. {data.table} ist auf der einen Seite sehr schnell, jedoch von der Syntaxlogik her etwas umständlicher als das {tidyverse}. Für alle, die mit sehr großen Datensätzen arbeiten lohnt es sich aber, {data.table} auszuprobieren."
  },
  {
    "objectID": "references.html#beispiele",
    "href": "references.html#beispiele",
    "title": "Links & Weiterführendes",
    "section": "Beispiele",
    "text": "Beispiele\nPaper zu einem Beispieldatensatz, komplett in R Markdown geschrieben\nHier findet ihr den Source-Code"
  },
  {
    "objectID": "references.html#cheatsheets",
    "href": "references.html#cheatsheets",
    "title": "Links & Weiterführendes",
    "section": "Cheatsheets",
    "text": "Cheatsheets\nEine Sammlung an Cheatsheets für eine breite Palette an Anwendungen gibt es hier.\n\nDatenvisualisierung mit {ggplot2}\nDatensätze bearbeiten mit {dplyr}\nDatensätze erstellen/reshapen mit {tidyr}"
  },
  {
    "objectID": "references.html#ggplot2",
    "href": "references.html#ggplot2",
    "title": "Links & Weiterführendes",
    "section": "{ggplot2}",
    "text": "{ggplot2}\nEine große Stärke von ggplot2 sind die zahlreichen Erweiterungen, welche beispielsweise ermöglichen\n\nmehrere Grafiken zu kombinieren mit {patchwork}\nKarten zu erstellen mit sf, weitere Link\nfortgeschrittene Textformatierungen zu verwenden mit {ggtext}\nGrafiken als Animation zu erstellen {gganimate} - eine Einführung oder hier\nLogos in in {ggplot2} einfügen mit {ggpath}\n\nEine Übersicht zu Erweiterungspakteten für {ggplot2} findet sich hier\nAuch The R Graph Gallery bietet eine hervorragende Übersicht zu Darstellungsmöglichkeiten mit Syntaxbeispielen für {ggplot2}.\n\nTutorial von Cédric Scherer\nSession zu intuitiveren Grafiken von Cara Thompson"
  },
  {
    "objectID": "references.html#purrr",
    "href": "references.html#purrr",
    "title": "Links & Weiterführendes",
    "section": "Fortgeschrittene Anwendung von lapply()/map() mit selbstgeschriebenen Funktionen",
    "text": "Fortgeschrittene Anwendung von lapply()/map() mit selbstgeschriebenen Funktionen\n\nUmfangreiche Einführung in loops mit map() und weiteren Funktionen aus {purrr} Hendrik van Broekhuizen\nModellserien: Blog von Tim Tiefenbach zu eleganten Möglichkeiten"
  },
  {
    "objectID": "references.html#regex",
    "href": "references.html#regex",
    "title": "Links & Weiterführendes",
    "section": "regex",
    "text": "regex\nFür die Arbeit mit Textvariablen sind regular expressions (regex) eine große Hilfe. Damit lassen sich beispielsweise Textabschnitte nach bestimmten Zeichenfolgen durchsuchen, diese ersetzen usw. Der Blog von Joshua C. Fjelstul ist ein guter Einstieg. Darüber hinaus gibt es ein hilfreiches Cheatsheet zu regex in R und das regex -Paket {stringr}"
  },
  {
    "objectID": "references.html#weiteres",
    "href": "references.html#weiteres",
    "title": "Links & Weiterführendes",
    "section": "Weiteres",
    "text": "Weiteres\n{easystats} bietet eine Sammlung von Paketen, welche statische Auswertungen erleichtern und vereinheitlichen. Gleichzeitig geht diese Vereinheitlichung aber mit einer beschränkteren Flexibilität einher - das ist Geschmackssache und kommt auf den Anwendungsfall an. Wir haben aus dem easystats-Universum unter anderem {performance} und {effectsize} kennengelernt.\nEreigniszeitmodelle / Event History Modellung / Survival Analysis"
  },
  {
    "objectID": "12_apply_loop.html#modellserien",
    "href": "12_apply_loop.html#modellserien",
    "title": "12  Schleifen & Funktionen",
    "section": "12.1 Modellserien",
    "text": "12.1 Modellserien\nEin typisches Beispiel ist eine Modellserie. Wir möchten folgende Modelle schätzen:\n\nModell 1 = F518_SUF ~ az\nModell 2 = F518_SUF ~ az + S1\nModell 3 = F518_SUF ~ az + S1 + m1202\nModell 4 = F518_SUF ~ az + S1 + m1202 + zpalter"
  },
  {
    "objectID": "12_apply_loop.html#modelle-in-einer-function",
    "href": "12_apply_loop.html#modelle-in-einer-function",
    "title": "12  Schleifen & Funktionen",
    "section": "12.1 Modelle in einer function()",
    "text": "12.1 Modelle in einer function()\nWir definieren dann eine function(), in der wir angeben, dass das angegebene Argument die Formel für ein lm() sein soll - das Ergebnis dieses lm() `lassen wir uns dann ausgeben.\n\nmod_function <- function(modx){\n  mx <- lm(formula = modx,data = etbx)\n  return(mx)\n}\n\nWenn wir jetzt in mod_function eine Modellformel angeben, wird ein lm() berechnet:\n\nmod_function(\"F518_SUF ~ az\")\n\n\nCall:\nlm(formula = modx, data = etbx)\n\nCoefficients:\n(Intercept)           az  \n     -371.3        102.1"
  },
  {
    "objectID": "12_apply_loop.html#modelleserie-als-function-mit-lapply-erstellen",
    "href": "12_apply_loop.html#modelleserie-als-function-mit-lapply-erstellen",
    "title": "12  Schleifen & Funktionen",
    "section": "12.1 Modelleserie als function() mit lapply() erstellen",
    "text": "12.1 Modelleserie als function() mit lapply() erstellen\nWir definieren dann eine function(), in der wir angeben, dass das angegebene Argument die Formel für ein lm() sein soll - das Ergebnis dieses lm() `lassen wir uns dann ausgeben.\n\nmod_function <- function(modx){\n  mx <- lm(formula = modx,data = etbx)\n  return(mx)\n}\n\nWenn wir jetzt in mod_function eine Modellformel angeben, wird ein lm() berechnet:\n\nmod_function(\"F518_SUF ~ az\")\n\n\nCall:\nlm(formula = modx, data = etbx)\n\nCoefficients:\n(Intercept)           az  \n     -371.3        102.1  \n\n\nIm nächsten Schritt können wir jetzt eine Liste mit verschiedenen Modellvarianten erstellen:\n\nmlst <- list(\n  \"Modell 1\" = \"F518_SUF ~ az\",\n  \"Modell 2\" = \"F518_SUF ~ az + S1\",\n  \"Modell 3\" = \"F518_SUF ~ az + S1 + m1202\",\n  \"Modell 4\" = \"F518_SUF ~ az + S1 + m1202 + zpalter\"\n)\n\nWir können die Elemente einer list() entweder mit [[]] oder (ggf.) über ihren Namen aufrufen. Hier haben wir vor dem = einen Namen angegeben:\n\nmlst[[4]]\n\n[1] \"F518_SUF ~ az + S1 + m1202 + zpalter\"\n\nmlst$`Modell 4`\n\n[1] \"F518_SUF ~ az + S1 + m1202 + zpalter\"\n\n\nMit lapply wenden wir unsere mod_function jetzt auf diese Liste von Modellen an:\n\nmods <- lapply(mlst,mod_function)\nmods$`Modell 1`\n\n\nCall:\nlm(formula = modx, data = etbx)\n\nCoefficients:\n(Intercept)           az  \n     -371.3        102.1  \n\nmods$`Modell 2`\n\n\nCall:\nlm(formula = modx, data = etbx)\n\nCoefficients:\n(Intercept)           az          S1w  \n     359.51        91.73      -683.55  \n\n\nAußerdem können wir uns alle Modelle auch direkt in modelsummary ausgeben lassen:\n\nmodelsummary::modelsummary(mods,stars = T,gof_omit = \"IC|RM|Log\")\n\n\n\n \n  \n      \n    Modell 1 \n     Modell 2 \n     Modell 3 \n     Modell 4 \n  \n \n\n  \n    (Intercept) \n    -371.260*** \n    359.515*** \n    -1526.254*** \n    -2609.682*** \n  \n  \n     \n    (89.299) \n    (106.687) \n    (118.849) \n    (153.625) \n  \n  \n    az \n    102.097*** \n    91.733*** \n    82.716*** \n    83.152*** \n  \n  \n     \n    (2.234) \n    (2.376) \n    (2.321) \n    (2.313) \n  \n  \n    S1w \n     \n    -683.549*** \n    -725.053*** \n    -755.165*** \n  \n  \n     \n     \n    (55.184) \n    (53.540) \n    (53.414) \n  \n  \n    m1202 \n     \n     \n    797.911*** \n    778.380*** \n  \n  \n     \n     \n     \n    (24.734) \n    (24.706) \n  \n  \n    zpalter \n     \n     \n     \n    24.282*** \n  \n  \n     \n     \n     \n     \n    (2.194) \n  \n  \n    Num.Obs. \n    16521 \n    16521 \n    16521 \n    16521 \n  \n  \n    R2 \n    0.112 \n    0.120 \n    0.173 \n    0.179 \n  \n  \n    R2 Adj. \n    0.112 \n    0.120 \n    0.172 \n    0.178 \n  \n  \n    F \n    2089.519 \n    1131.116 \n    1148.445 \n    898.308 \n  \n\n\n + p < 0.1, * p < 0.05, ** p < 0.01, *** p < 0.001"
  },
  {
    "objectID": "04_viz.html#grafiken-speichern-ggsave",
    "href": "04_viz.html#grafiken-speichern-ggsave",
    "title": "4  Visualisierung mit {ggplot2}",
    "section": "4.3 Grafiken speichern: ggsave()",
    "text": "4.3 Grafiken speichern: ggsave()\nUm eine Grafik dann zu speichern, steht uns ggsave() zur Verfügung. Wenn wir nichts anderes angeben, wird automatisch die gerade offene Grafik2 gespeichert. Besser ist es aber explizit zu sein und die gewünschte Grafik als Objekt abzulegen und dann in ggsave() anzugeben:\n\nplot_objekt1 <- ggplot(data = etb18_small, aes(x = zpalter, y = az, \n                               color = factor(S1),\n                               shape = factor(m1202))) + \n  geom_point(size = 2) + \n  scale_color_manual(values = c(\"lightskyblue3\",\"navy\"),\n                    breaks = c(1,2), labels = c(\"Männer\", \"Frauen\") ) +\n  scale_shape_manual(values = c(15:18),breaks = c(1:4), \n                     labels = c(\"ohne Aus\", \"duale Ausb.\",\"Aufstiegsfortb.\",\"FH/Uni\")) +\n  labs(color = \"Geschlecht\",shape = \"Ausbildung\", fill = \"Geschlecht\",\n       y = \"Arbeitszeit/Woche\",x = \"Alter\",\n       title = \"Arbeitszeit und Alter\", subtitle = \"Nach Geschlecht\",caption = \"Quelle: ETB 2018\") \n\n\nggsave(plot = plot_objekt1,filename = \"./results/plot1.png\",\n       dpi = 800, # auflösung\n       # width = 9, height = 7, # falls angepasst werden soll\n       )\n\nDie richtige Kombination aus Auflösung, Textgröße und Gesamtgröße des Plots zu finden hat einige Fallstricke. Hier mehr dazu.\n\n4.3.1 Übung"
  }
]