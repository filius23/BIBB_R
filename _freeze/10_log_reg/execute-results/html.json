{
  "hash": "3cbadd69a9fbc05564c2b295453dc399",
  "result": {
    "markdown": "# Logistische Regressionsmodelle \n\n\n\n\n\n\nIn diesem Kapitel widmen wir uns dem Fall einer binären abhängigen Variable/Dummyvariable. Für solche Fälle sind logistische Regressionsmodelle gebräuchlich, die sich in Ihrer Anwendung etwas von 'normalen', linearen Regressionsmodellen unterscheiden. Kern dieses Unterschieds ist die Link-Funktion, welche die Koeffizienten etwas schwerer interpretierbar macht - daher haben sich sog. marginal effects als Darstellungsform für Ergebnisse logistischer Regressionen etabliert. \nIn R steht uns dafür das Paket [`{marginaleffects}`](https://vincentarelbundock.github.io/marginaleffects/), welches sich in der Anwendung sehr dem `margins`-Befehl in Stata ähnelt.\n\n\nBisher hatten wir immer Regressionsmodelle betrachtet, die eine metrisch skalierte abhängige Variable hatten.[^1]\nAber gerade Individualmerkmale sind nur selten metrisch skaliert, z.B. Erwerbstatus, Familienstand, Geschlecht, Elternstand, ... Ein lineares OLS-Regressionsmodell wie wir es bisher kennen gelernt haben, hilft uns hier nicht weiter. \nSchauen wir uns beispielsweise die Arbeitsplatzsituation der männlichen Befragten in der ETB 2018 an (`F605`)[^3] :\n\n[^1]: Leseempfehlung: [Logistische Regression von Henning Best & Christof Wolf, S. 827-854 in \"Handbuch der sozialwissenschaftlichen Datenanalyse\"](www.doi.org/10.1007/978-3-531-92038-2_31)\n[^3]: Die Einschränkung auf männliche Befragte hat hier den einfachen Grund, dass so der Koeffizient größer ist \n\n\n**Arbeiten Sie mehr als die Hälfte Ihrer Arbeitszeit im Freien?**\n   \nDie 1 steht dabei jeweils für \"ja\", die `2` für \"nein\". Wir verändern die Codierung aber so, dass die \"nein\"-Antworten mit `0` versehen werden. Die neue Variable nennen wir `outside`. Außerdem teilen wir `F518_SUF` durch 100 und legen die so erstellte Variable \"Einkommen in 100EUR\" in `inc100` ab, um die Nachkommastellen des Koeffizienten zu reduzieren:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_etb18 <- haven::read_dta(\"./data/BIBBBAuA_2018_suf1.0.dta\",\n                           col_select = c(\"S1\",\"F605\",\"F518_SUF\",\"m1202\",\"zpalter\",\"Bula\")) %>% \n  filter(F605 < 9, F518_SUF < 99998, zpalter < 100, S1==1) %>% \n  mutate(inc100 = F518_SUF/100,\n         outside = 2-F605)\n\nm_etb18 %>% count(outside,F605)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 3\n  outside F605          n\n    <dbl> <dbl+lbl> <int>\n1       0 2 [nein]   7302\n2       1 1 [ja]     1130\n```\n:::\n\n```{.r .cell-code}\nsummary(m_etb18$inc100)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.01   25.00   35.00   42.38   50.00  720.00 \n```\n:::\n:::\n\n\n## Das logistische Regressionsmodell {#logmod}\n\nSomit sieht unser logistisches Regressionsmodell in der allgemeinen Schreibweise wie folgt aus:\n\n\\begin{equation*}\n\\widehat{Logit(outside=1)} = \\widehat{ln\\left(\\frac{P(outside=1)}{1-P(outside=1)}\\right)} = \\hat\\beta0 + \\hat{\\beta1}\\times \\texttt{inc100}\n\\end{equation*}\n\nIn R können wir ein solches Modell mit `glm()` und der Option `family=\"binomial\"` berechnen:[^log_fam]\n\n\n[^log_fam]: `family=\"binomial\"` ist dabei entscheidend: `glm(outside ~ inc100, data = m_etb18)` oder `glm(outside ~ inc100, family = gaussian(), data = m_etb18)` ist gleichbedeutend mit `lm(outside ~ inc100, data = m_etb18)`: es wird ein lineares OLS-Modell berechnet.\n\n::: {.cell}\n\n```{.r .cell-code}\nm2 <- glm(outside ~ inc100, family = \"binomial\", data = m_etb18)\nsummary(m2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = outside ~ inc100, family = \"binomial\", data = m_etb18)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.9580  -0.6005  -0.4841  -0.3042   5.5160  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -0.54045    0.07285  -7.419 1.18e-13 ***\ninc100      -0.03861    0.00218 -17.716  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 6643.5  on 8431  degrees of freedom\nResidual deviance: 6209.8  on 8430  degrees of freedom\nAIC: 6213.8\n\nNumber of Fisher Scoring iterations: 6\n```\n:::\n:::\n\n\nDie Interpretation der $\\beta$ aus einem logistischen Regressionsmodell bezieht sich also auf die Logits (die logarithmierten Odds):  \n\n::: inter\n\nEs besteht ein am 0,001-Niveau signifikanter Zusammenhang zwischen dem Einkommen und der Wahrscheinlichkeit, im Freien zu arbeiten. Mit einem um 100 Euro höheren Einkommen gehen um 0.038612 niedrigere *Logits* einher, mehr als die Hälfte Ihrer Arbeitszeit im Freien zu arbeiten.\n:::\n\n## average marginal effects\n\nLogits sind aber sehr unhandlich - wie verändert sich jetzt aber die *Wahrscheinlichkeit* für $\\texttt{outside} = 1$ mit `inc100`? Hier haben wir das Problem, dass die Ableitung der \"rücktransformierten Funktion\" nicht so einfach ist wie im Fall der OLS. Verändern wir nämlich auch die [Regressionsgleichung von oben[^2]](#logmod) mit `exp()` und $p=\\frac{Odds}{1+Odds}$, so landen wir bei \n\n\\begin{equation*}\n\\widehat{P(outside=1)} = \\frac{e^{\\hat\\beta0+\\hat\\beta1 \\times \\texttt{inc100}}}{1+e^{\\hat\\beta0+\\hat{\\beta1}\\times \\texttt{inc100}}}\n\\end{equation*}\n\n[^2]: $\\widehat{Logit(outside=1)} = \\widehat{ln\\left(\\frac{P(outside=1)}{1-P(outside=1)}\\right)} = \\hat\\beta0 + \\hat{\\beta1}\\times \\texttt{inc100}$\n\n\nDiesen Ausdruck müssten wir nach `inc100` ableiten, um eine Antwort zu bekommen um wieviel sich die vorhergesagte Wahrscheinlichkeit für $\\texttt{outside} = 1$ mit einem um einen Euro höheren Befragteneinkommen verändert. \nDurch die Tatsache dass `inc` hier im Exponenten der e-Funktion und sowohl im Dividenden als auch Divisor (\"oben und unten\") steht, wird die Ableitung hier aber deutlich komplizierter als das in den bisherigen `lm()`-Modellen der Fall war. \nFür uns ist an dieser Stelle aber nur wichtig, dass wir für die Berechnung der Veränderung der vorhergesagten Wahrscheinlichkeiten die sog. marginalen Effekte aus dem Paket `{marginaleffects}` brauchen. \nDarin findet sich der Befehl `avg_slopes()`, welcher uns erlaubt ein $\\beta$ zwischen dem Einkommen und der _Wahrscheinlichkeit_ für $\\texttt{outside} = 1$ zu berechnen. Dieses wird auch als *average marginal effect* bezeichnet, da sie den *durchschnittlichen marginalen Effekt* der betrachteten unabhängigen Variable auf die abhängige Variable wiedergeben. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"marginaleffects\") # nur einmal nötig\nlibrary(marginaleffects)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\navg_slopes(m2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n   Term Estimate Std. Error     z Pr(>|z|)    2.5 %   97.5 %\n inc100 -0.00426    0.00024 -17.7   <0.001 -0.00473 -0.00379\n\nColumns: term, estimate, std.error, statistic, p.value, conf.low, conf.high \n```\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n::: inter\n\nMit einem um 100 Euro (`inc100` ist in 100 EUR gemessen) höheren Einkommen geht im Durchschnitt eine um 0.00426 (0.42632 Prozentpunkte) geringere Wahrscheinlichkeit einher, mehr als die Hälfte der Arbeitszeit im Freien zu arbeiten.\n\n:::\n\n## Predctions \n\nAlternativ können die Ergebnisse aus log. Regressionen auch als vorhergesagte Werte dargestellt werden.\nVorhergesagte Werte können wir mit `predictions()` aus `{marginaleffects}` erstellen:\n\n::: {.cell}\n\n```{.r .cell-code}\npredictions(m2, \n            newdata = data.frame(inc100  = 1:5), # einzusetzende Werte\n            type = \"response\" # vorhergesagte Wkt als Einheit (statt logits)\n            )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n Estimate Std. Error    z Pr(>|z|) 2.5 % 97.5 % inc100\n    0.359     0.0163 22.0   <0.001 0.327  0.391      1\n    0.350     0.0157 22.3   <0.001 0.320  0.381      2\n    0.342     0.0151 22.6   <0.001 0.312  0.371      3\n    0.333     0.0145 23.0   <0.001 0.305  0.361      4\n    0.324     0.0139 23.4   <0.001 0.297  0.352      5\n\nColumns: rowid, estimate, std.error, statistic, p.value, conf.low, conf.high, inc100, outside \n```\n:::\n:::\n\n\nDas können wir in einem `ggplot()` grafisch darstellen:\n\n::: {.cell}\n\n```{.r .cell-code}\npredictions(m2, newdata = data.frame(inc100  = 1:70), type = \"response\") %>% # vorhergesagte Werte\n  data.frame() %>% \n  ggplot(aes(y = estimate , x = inc100)) + \n  geom_errorbar(aes(ymin = conf.low, ymax= conf.high), color = \"slateblue\",width = .1) + # konfidenzintervalle\n  geom_point(color = \"slateblue\") + # punktschätzer\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](10_log_reg_files/figure-html/unnamed-chunk-5-1.png){width=576}\n:::\n:::\n\n\n\n## [Übung 1](#ame1)\n\n\n## Fixed effects logistische Regression mit `{fixest}` {#feglm}\n\n\nMit `feglm()` lassen sich auch logistische FE-Modelle schätzen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(fixest)\nm_etb18 <-\n  m_etb18 %>%\n  mutate(m1202_fct = factor(m1202,levels = 1:4,\n                            labels = c(\"Ohne\",\"duale\",\"Aufst\",\"FH/Uni\")),\n         m1202_fct = fct_relevel(m1202_fct,\"Ohne\"))\n\nfeglm(outside ~ m1202_fct + zpalter |Bula, data = m_etb18, family = binomial)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNOTE: 9 observations removed because of NA values (RHS: 9).\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nGLM estimation, family = binomial, Dep. Var.: outside\nObservations: 8,423 \nFixed-effects: Bula: 16\nStandard-errors: Clustered (Bula) \n                 Estimate Std. Error    t value   Pr(>|t|)    \nm1202_fctduale  -0.180646   0.115551  -1.563352 1.1797e-01    \nm1202_fctAufst  -0.624511   0.155252  -4.022562 5.7569e-05 ***\nm1202_fctFH/Uni -1.936798   0.121415 -15.951843  < 2.2e-16 ***\nzpalter         -0.000956   0.003654  -0.261795 7.9348e-01    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nLog-Likelihood: -3,018.2   Adj. Pseudo R2: 0.083759\n           BIC:  6,217.2     Squared Cor.: 0.06507 \n```\n:::\n\n```{.r .cell-code}\nfe_log1 <- feglm(outside ~ m1202_fct + zpalter|Bula, data = m_etb18, family = binomial)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNOTE: 9 observations removed because of NA values (RHS: 9).\n```\n:::\n\n```{.r .cell-code}\navg_slopes(fe_log1,by = TRUE, variables = \"m1202_fct\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n      Term      Contrast Estimate Std. Error     z Pr(>|z|)   2.5 %   97.5 %\n m1202_fct Aufst - Ohne   -0.0908     0.0216 -4.21   <0.001 -0.1331 -0.04854\n m1202_fct FH/Uni - Ohne  -0.1876     0.0250 -7.51   <0.001 -0.2365 -0.13865\n m1202_fct duale - Ohne   -0.0299     0.0191 -1.56    0.118 -0.0674  0.00761\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high \n```\n:::\n\n```{.r .cell-code}\navg_slopes(fe_log1,by = TRUE, variables = \"zpalter\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n    Term  Estimate Std. Error      z Pr(>|z|)    2.5 %   97.5 %\n zpalter -0.000103   0.000386 -0.268    0.789 -0.00086 0.000653\n\nColumns: term, estimate, std.error, statistic, p.value, conf.low, conf.high \n```\n:::\n:::\n\n\n\n## Übung {#ame1}\n\n::: {.cell}\n\n```{.r .cell-code}\netb_ue10 <- haven::read_dta(\"./data/BIBBBAuA_2018_suf1.0.dta\",\n                            col_select = c(\"F1605e\",\"m1202\")) %>% \n  filter(F1605e < 4, !is.na(F1605e), m1202 %in% 1:4) %>% \n  mutate(fam_beruf = 2-F1605e,\n         m1202 = factor(m1202))\n```\n:::\n\n\n\n+ Erstellen Sie ein logistisches Regressionsmodell mit `fam_beruf` basierend auf der Frage\n\n**Haben Sie aufgrund ihrer Kinder Abstriche gemacht, um Familie und Beruf zu vereinbaren?**\n\nals abhängiger Variable (1 = ja, 0 = nein.) Verwenden Sie die Ausbildung `m1202` als unabhängige Variable.\n\nBerechnen Sie die AME mit `marginaleffects`.\n\n\n## Anhang: Hintergrund zu log. Regression & average marginal effects\n\nWenn wir uns fragen, ob sich Befragte mit höherem Einkommen seltener im Freien arbeiten, hilft uns die OLS-Vorgehensweise nicht so richtig weiter. Die \"Punktewolke\" zur Optimierung der Abweichung zwischen tatsächlichen und vorhergesagten Werten (Residuen) sieht hier anders aus als bisher:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(m_etb18, aes(x = inc100, y = outside)) +\n  geom_point(color = \"#172869\") +\n  theme(aspect.ratio = .75)\n```\n\n::: {.cell-output-display}\n![](10_log_reg_files/figure-html/unnamed-chunk-7-1.png){fig-align='center' width=336}\n:::\n:::\n\nUm trotzdem ein Regressionsmodell zu berechnen, könnten wir die abhängige Variable uminterpretieren. $\\hat{y}$ wird dann nicht mehr dichotom, sondern als metrische Wahrscheinlichkeit interpretiert, dass der Befragte mehr als die Hälfte der Arbeitszeit im Freien arbeitet (also die Wahrscheinlichkeit für outside = 1). Das können wir dann wie gehabt in eine Regressionsgleichung aufnehmen, zB. mit dem Einkommen als unabhängiger Variable:   \n\n\\begin{equation*}\n\\widehat{y_i} = P(outside\\texttt{\\small{=}}1) = \\hat\\beta0 + \\hat\\beta1 * \\texttt{inc100}_i\n\\end{equation*}\n\nAllerdings führt das zwangsläufig zu Verstößen gegen die Annahmen bzgl. der Residuen - die Fehler werden immer heteroskedastisch und nicht normalverteilt sein. Zudem wird es vorhergesagte Werte geben, die nicht sinnvoll interpretiert werden können, weil es mit 0 und 1 Grenzen gibt, jenseits derer Wahrscheinlichkeiten nicht existieren (zB gibt es keine negativen Wahrscheinlichkeiten).\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(m_etb18, aes(x = inc100, y = outside)) +\n  geom_point(color = \"#172869\", size = .75) +\n  geom_smooth(method = \"lm\", color = lacroix_palette(\"PeachPear\",6)[2],se = F ) + \n  labs(y = \"P(outside = 1)\", x = \"Einkommen (in 100 EUR)\",\n       title = \"lineares Wahrscheinlichkeitsmodell\")\n```\n\n::: {.cell-output-display}\n![](10_log_reg_files/figure-html/unnamed-chunk-9-1.png){fig-align='center' width=480}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggfortify)\nautoplot(m1,which = 1:2) # Homosk. & NV \n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](10_log_reg_files/figure-html/unnamed-chunk-11-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n### Logistische Linkfunktion\nUm diese Probleme zu umgehen, sind für dichotome abhängige Variablen logistische Regressionsmodelle ein sehr verbreitetes Vorgehen. Dafür werden neben dem bereits angesprochenen Schritt der Betrachtung von $\\hat{y}$ als Wahrscheinlichkeit zwei weitere Transformationen der abhängigen Variable vorgenommen:\n\n- *Odds statt Wahrscheinlichkeiten*: Um die obere Grenze des Wertebereichs der abhängigen Variablen auf $+\\infty$ auszudehnen, werden statt Wahrscheinlichkeiten Odds betrachtet. Odds sind definiert als der Quotient aus Wahrscheinlichkeit und der Gegenwahrscheinlichkeit für ein gegebenes Ereignis. In unserem Beispiel sind also die Odds dafür, dass ein*e Befragte*r angibt, sich nachts outside zu fühlen: $$Odds(outside=1) = \\frac{P(outside=1)}{P(outside=0)}= \\frac{P(outside=1)}{1-P(outside=1)} $$ \nDie Odds gehen gegen 0, je unwahrscheinlicher das betrachtete Ereignis ist. Für sehr wahrscheinliche Ereignisse nehmen die Odds Werte an, die gegen $+\\infty$ gehen, das Verhältnis zwischen Dividend (\"Zähler\") und Divisor (\"Nenner\") wird immer größer.\n\n- *Logits statt Odds*: Damit bleibt aber noch das Problem der negativen Werte bestehen: Auch Odds sind nur für [0;$+\\infty$] definiert. Um auch den negativen Wertebereich sinnvoll interpretierbar zu machen, werden die Odds logarithmiert, wir erhalten die sogenannten Logits: $$Logit(outside=1) = log(Odds(outside=1)) = log\\left(\\frac{P(outside=1)}{1-P(outside=1)}\\right)$$ \nDie Logarithmierung führt für Werte zwischen 0 und 1 zu negativen Werten, für Werte größer als 1 zu positiven Werten. \n\nDementsprechend gibt es bei logistischen Regressionen drei Einheiten:\n\n + Wahrscheinlichkeiten $P = \\frac{\\text{Anzahl Treffer}}{\\text{Anzahl aller Möglichkeiten}}$\n \n + $\\text{Odds} = \\frac{P}{1-P} = \\frac{\\text{Anzahl Treffer}}{\\text{Anzahl Nicht-Treffer}}$\n \n + $\\text{log-Odds/Logits} = log(Odds) = log( \\frac{\\text{Anzahl Treffer}}{\\text{Anzahl Nicht-Treffer}})$\n\n  \n  \n<br>  \n\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div id=\"tpulrcvgrn\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>html {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#tpulrcvgrn .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: hidden;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: hidden;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#tpulrcvgrn .gt_heading {\n  background-color: #FFFFFF;\n  text-align: right;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#tpulrcvgrn .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#tpulrcvgrn .gt_title {\n  color: #333333;\n  font-size: small;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#tpulrcvgrn .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#tpulrcvgrn .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#tpulrcvgrn .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#tpulrcvgrn .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#tpulrcvgrn .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#tpulrcvgrn .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#tpulrcvgrn .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#tpulrcvgrn .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#tpulrcvgrn .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#tpulrcvgrn .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#tpulrcvgrn .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#tpulrcvgrn .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#tpulrcvgrn .gt_row {\n  padding-top: 1px;\n  padding-bottom: 1px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#tpulrcvgrn .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#tpulrcvgrn .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#tpulrcvgrn .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#tpulrcvgrn .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#tpulrcvgrn .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#tpulrcvgrn .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#tpulrcvgrn .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#tpulrcvgrn .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#tpulrcvgrn .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#tpulrcvgrn .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#tpulrcvgrn .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#tpulrcvgrn .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#tpulrcvgrn .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-left: 4px;\n  padding-right: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#tpulrcvgrn .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#tpulrcvgrn .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#tpulrcvgrn .gt_left {\n  text-align: left;\n}\n\n#tpulrcvgrn .gt_center {\n  text-align: center;\n}\n\n#tpulrcvgrn .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#tpulrcvgrn .gt_font_normal {\n  font-weight: normal;\n}\n\n#tpulrcvgrn .gt_font_bold {\n  font-weight: bold;\n}\n\n#tpulrcvgrn .gt_font_italic {\n  font-style: italic;\n}\n\n#tpulrcvgrn .gt_super {\n  font-size: 65%;\n}\n\n#tpulrcvgrn .gt_footnote_marks {\n  font-style: italic;\n  font-weight: normal;\n  font-size: 75%;\n  vertical-align: 0.4em;\n}\n\n#tpulrcvgrn .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#tpulrcvgrn .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#tpulrcvgrn .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#tpulrcvgrn .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#tpulrcvgrn .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#tpulrcvgrn .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" style=\"table-layout: fixed;; width: 0px\">\n  <colgroup>\n    <col style=\"width:120px;\"/>\n    <col style=\"width:200px;\"/>\n    <col style=\"width:100px;\"/>\n    <col style=\"width:200px;\"/>\n  </colgroup>\n  \n  <thead class=\"gt_col_headings\">\n    <tr>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"$$P$$\">$$P$$</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"$$Odds = \\frac{P}{1-P}$$\">$$Odds = \\frac{P}{1-P}$$</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"\"></th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"$$Logits = log(Odds)$$\">$$Logits = log(Odds)$$</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"p\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>$$\\frac{1}{2}$$</p>\n</div></td>\n<td headers=\"odds1\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>$$1$$</p>\n</div></td>\n<td headers=\"odds2\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>oder 1:1</p>\n</div></td>\n<td headers=\"logodds\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>0</p>\n</div></td></tr>\n    <tr><td headers=\"p\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>$$\\frac{1}{3}$$</p>\n</div></td>\n<td headers=\"odds1\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>$$0.5$$</p>\n</div></td>\n<td headers=\"odds2\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>oder 1:2</p>\n</div></td>\n<td headers=\"logodds\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>-0.6931</p>\n</div></td></tr>\n    <tr><td headers=\"p\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>$$\\frac{1}{4}$$</p>\n</div></td>\n<td headers=\"odds1\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>$$0.33$$</p>\n</div></td>\n<td headers=\"odds2\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>oder 1:3</p>\n</div></td>\n<td headers=\"logodds\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>-1.0986</p>\n</div></td></tr>\n    <tr><td headers=\"p\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>$$\\frac{1}{5}$$</p>\n</div></td>\n<td headers=\"odds1\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>$$0.25$$</p>\n</div></td>\n<td headers=\"odds2\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>oder 1:5</p>\n</div></td>\n<td headers=\"logodds\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>-1.3863</p>\n</div></td></tr>\n    <tr><td headers=\"p\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>$$\\frac{2}{3}$$</p>\n</div></td>\n<td headers=\"odds1\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>$$2$$</p>\n</div></td>\n<td headers=\"odds2\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>oder 2:1</p>\n</div></td>\n<td headers=\"logodds\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>0.6931</p>\n</div></td></tr>\n    <tr><td headers=\"p\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>$$\\frac{3}{4}$$</p>\n</div></td>\n<td headers=\"odds1\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>$$3$$</p>\n</div></td>\n<td headers=\"odds2\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>oder 3:1</p>\n</div></td>\n<td headers=\"logodds\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>1.0986</p>\n</div></td></tr>\n    <tr><td headers=\"p\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>$$1$$</p>\n</div></td>\n<td headers=\"odds1\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>$$\\frac{1}{0}$$</p>\n</div></td>\n<td headers=\"odds2\" class=\"gt_row gt_right\"><div class='gt_from_md'><p><em>sicher</em></p>\n</div></td>\n<td headers=\"logodds\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>Inf</p>\n</div></td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n:::\n:::\n\n\n\n\n### Vorhergesagte Werte\n\nZunächst stellt sich die Frage, was Logits denn bedeuten. Eigentlich möchten wir ja Wahrscheinlichkeiten im Wertebereich zwischen 0 und 1 (bzw. 0% und 100%) als Interpretationseinheit haben. Die Berechnung eines vorhergesagten Werts für einen Befragten mit einem Einkommen von 1000 Euro (`inc100`=10) ergibt durch einsetzen bzw. `predict()` natürlich auch die Logits:\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(m2)$coefficients\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n               Estimate  Std. Error   z value     Pr(>|z|)\n(Intercept) -0.54045018 0.072851290  -7.41854 1.184188e-13\ninc100      -0.03861198 0.002179513 -17.71588 3.162624e-70\n```\n:::\n\n```{.r .cell-code}\n-0.53856546   + -0.03868975 * 10\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.925463\n```\n:::\n\n```{.r .cell-code}\npredict(m2, data.frame(inc100 = 10))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         1 \n-0.9265699 \n```\n:::\n:::\n\n\n    \n::: inter\n\nBefragte mit einem Einkommen von 1000EUR haben dem Modell zu Folge Logits von -0.92657, mehr als die Hälfte der Arbeitszeit im Freien zu arbeiten.\n\n:::\n\nUm an die Wahrscheinlichkeit für `outside` = 1 zu bekommen, müssen wir die Transformationsschritte sozusagen \"rückabwickeln\"! Dafür müssen wir zunächst mit `exp` den `ln()` vor den Odds heraus rechnen und können dann durch die die Formel $p=\\frac{Odds}{1+Odds}$ die Wahrscheinlichkeit aus den odds berechnen:\n\n::: {.cell}\n\n```{.r .cell-code}\nlogits <- -0.9254629 \nexp(logits) # Odds statt Logits\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3963479\n```\n:::\n\n```{.r .cell-code}\nodds <- exp(logits) \nodds/(1+odds) # Wahrscheinlichkeit statt Odds \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.2838461\n```\n:::\n\n```{.r .cell-code}\nexp(logits)/(1+exp(logits)) # beide Schritte auf einmal\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.2838461\n```\n:::\n:::\n\n\n    \n::: inter\n\nDie Wahrscheinlichkeit, dass ein Befragter mit einem Einkommen von 1000 Euro angibt, mehr als die Hälfte Ihrer Arbeitszeit im Freien zu arbeiten, liegt also unserem Modell zu Folge bei 28.362\\%.   \n\n::: \n\nMit der Option `type=\"response\"` können wir das auch mit `predict()` direkt berechnen:\n\n::: {.cell}\n\n```{.r .cell-code}\npredict(m2, data.frame(inc100 = 10), type=\"response\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        1 \n0.2836211 \n```\n:::\n:::\n\n\n### Die Idee von average marginal effects\n\nWie verändern sich dann die vorhergesagten Werte, wenn wir `inc100` um eine Einheit (also 100€) erhöhen? Die Logits verändern sich pro Einheit `inc100` natürlich genau um $\\hat\\beta1$, also hier -0.03861. Um sich die Steigung an einigen Werten anzusehen, berechnen wir jeweils die Abstände der vorhergesagten Werte für $x-0.5$ und $x+0.5$:\n\n\n*Um die Werte jeweils mit dem eingesetzten Wert zu beschriften, stellen wir den Wert mit * `\"\"=` *voran:*\n\n::: {.cell}\n\n```{.r .cell-code}\npredict(m2, data.frame(inc100=c(\"54.5\"=54.5,\"55.5\"=55.5,\"64.5\"=64.5,\"65.5\"=65.5,\n                                \"74.5\"=74.5,\"75.5\"=75.5)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     54.5      55.5      64.5      65.5      74.5      75.5 \n-2.644803 -2.683415 -3.030923 -3.069535 -3.417042 -3.455654 \n```\n:::\n:::\n\n\nDie Differenzen sind immer gleich - entsprechend der Interpretation gehen mit einem um eine Einheit höheren `inc100` um 0.03861 höhere Logits einher, dass die Befragten mehr als die Hälfte Ihrer Arbeitszeit im Freien arbeiten:\n\n+ Steigung bei `inc100` = 55: -2.68341 $-$ -2.64480 = -0.03861  \\quad\\textsf{\\small{Vorhersage bei 55.5 - Vorhersage bei 54.5}}\n\n+ Steigung bei `inc100` = 65: -3.06953 $-$ -3.03092 = -0.03861  \\quad\\textsf{\\small{Vorhersage bei 56.5 - Vorhersage bei 64.5}}\n\n+ Steigung bei `inc100` = 75: -3.45565 $-$ -3.41704 = -0.03861  \\quad\\textsf{\\small{Vorhersage bei 75.5 - Vorhersage bei 74.5}}\n\nWenn wir uns diese Schritte aber jeweils für die vorhergesagten Wahrscheinlichkeiten ansehen, sieht das aber anders aus:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict(m2, data.frame(inc100=c(\"54.5\"=54.5,\"55.5\"=55.5,\"64.5\"=64.5,\"65.5\"=65.5,\n                                \"74.5\"=74.5,\"75.5\"=75.5)), type = \"response\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      54.5       55.5       64.5       65.5       74.5       75.5 \n0.06631006 0.06395913 0.04604828 0.04438156 0.03176707 0.03060068 \n```\n:::\n:::\n\n\nHier werden die Differenzen mit zunehmendem `inc100` immer kleiner:\n\n+ Steigung bei `inc100` = 55: 0.06396 $-$ 0.06631 = -0.00235  \\quad\\textsf{\\small{Vorhersage bei 55.5 - Vorhersage bei 54.5}}\n\n+ Steigung bei `inc100` = 65: 0.04438 $-$ 0.04605 = -0.00167  \\quad\\textsf{\\small{Vorhersage bei 65.5 - Vorhersage bei 64.5}}\n\n+ Steigung bei `inc100` = 75: 0.03060 $-$ 0.03177 = -0.00117  \\quad\\textsf{\\small{Vorhersage bei 75.5 - Vorhersage bei 74.5}}\n\n\n\n\n\n::: {.cell layout-align=\"center\" fig.caption='true'}\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n```\n:::\n\n::: {.cell-output-display}\n![](10_log_reg_files/figure-html/AME1-1.png){fig-align='center' width=672}\n:::\n:::\n\n::: {.cell layout-align=\"center\" fig.caption='true'}\n::: {.cell-output-display}\n![](10_log_reg_files/figure-html/AME2-1.png){fig-align='center' width=672}\n:::\n:::\n\nDiese Steigungen werden für alle Beobachtungen aus dem zu Grunde liegenden Datensatz aufsummiert und dann der Durchschnitt gebildet ($\\rightarrow$ *average* marginal effects)\n\n\n## Links\n\n+ [Die Seite zu `{marginaleffects}`](https://vincentarelbundock.github.io/marginaleffects/articles/marginaleffects.html) bietet sehr ausführliche und anschauliche Beispiele zu den verschiedenen Varianten marginaler Effekte\n\n+ [Ausführliche Einführung zu marginalen Effekten von Andrew Heiss](https://www.andrewheiss.com/blog/2022/05/20/marginalia/)\n\n\n[Ableitungen grafisch erstellt](https://twitter.com/allison_horst/status/1554921698742468625?s=11&t=Ac_YizlsYkOfUIkuWmaaWQ)\n",
    "supporting": [
      "10_log_reg_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}